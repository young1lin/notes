# Â§ßËØ≠Ë®ÄÊ®°Âûã LLM ÂàùÊé¢

ÂÖàËøõË°åÊé•Âè£Ë∞ÉÁî®ÔºåÂø´ÈÄü‰∫ÜËß£Â§ßËØ≠Ë®ÄÊ®°ÂûãËÉΩÂÅö‰ªÄ‰πàÔºåÂÜçÈÄê‰∏™‰∫ÜËß£ÂÖ∂ÂéüÁêÜ„ÄÇ

## ÈÄöËøá HTTP ËØ∑Ê±ÇÂàùÊé¢

```http
POST https://api.deepseek.com/chat/completions HTTP/1.1
Content-Type: application/json
Accept: application/json
Authorization: Bearer {{$dotenv DEEPSEEK_API_KEY}}

{
  "messages": [
    {
      "content": "‰Ω†ÊòØ‰∏Ä‰∏™Êô∫ËÉΩÂÆ¢Êúç AliceÔºå‰Ω†ÁöÑ‰∏ªË¶Å‰ΩúÁî®Â∞±ÊòØÂ∏ÆÁî®Êà∑Ëß£Á≠îÁñëÈóÆ",
      "role": "system"
    },
    {
      "content": "‰Ω†Â•ΩÔºå‰Ω†ÊòØË∞ÅÔºü",
      "role": "user"
    }
  ],
  "model": "deepseek-chat",
  "stream": false,
  "temperature": 0
}
```

ÂõûÂ§çÁöÑÂÜÖÂÆπ

```http
HTTP/1.1 200 OK
Date: Wed, 06 Aug 2025 08:21:59 GMT
Content-Type: application/json
Transfer-Encoding: chunked
Connection: close
vary: origin, access-control-request-method, access-control-request-headers
access-control-allow-credentials: true
x-ds-trace-id: 4f241ebb167c3c01b3a97ed15dccc06a
Strict-Transport-Security: max-age=31536000; includeSubDomains; preload
X-Content-Type-Options: nosniff
Server: CW
Content-Encoding: gzip

{
  "id": "379e029d-6fe0-4c17-8b1b-a834033f810e",
  "object": "chat.completion",
  "created": 1754468519,
  "model": "deepseek-chat",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "‰Ω†Â•ΩÔºÅÊàëÊòØÊô∫ËÉΩÂÆ¢ÊúçAliceÔºåÂæàÈ´òÂÖ¥‰∏∫‰Ω†ÊúçÂä°„ÄÇÊàëÊòØ‰∏Ä‰∏™AIÂä©ÊâãÔºåÂèØ‰ª•Â∏ÆÂä©Ëß£Á≠îÈóÆÈ¢ò„ÄÅÊèê‰æõ‰ø°ÊÅØÊàñÂçèÂä©Â§ÑÁêÜÂêÑÁßç‰∫ãÂä°„ÄÇÊúâ‰ªÄ‰πàÊàëÂèØ‰ª•Â∏Æ‰Ω†ÁöÑÂêóÔºü"
      },
      "logprobs": null,
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 21,
    "completion_tokens": 33,
    "total_tokens": 54,
    "prompt_tokens_details": {
      "cached_tokens": 0
    },
    "prompt_cache_hit_tokens": 0,
    "prompt_cache_miss_tokens": 21
  },
  "system_fingerprint": "fp_8802369eaa_prod0623_fp8_kvcache"
}
```

‰ªé‰∏äÈù¢ÁöÑ‰æãÂ≠êÊàë‰ª¨ÂèØ‰ª•ÂèëÁé∞ÔºåÂ§ßÊ®°ÂûãÊúâ‰∏â‰∏™ roleÔºàËßíËâ≤ÔºâÔºåsystem Â∞±ÊòØÁ≥ªÁªüËßíËâ≤Ôºåuser ÊòØÁî®Êà∑Ôºåassistant Â∞±ÊòØÂ§ßÊ®°ÂûãÔºå‰∏é‰πãÁõ∏Â∫îÁöÑ content Â∞±ÊòØÂÆÉ‰ª¨‰πãÈó¥ÁöÑÂØπËØùÂÜÖÂÆπ„ÄÇ
ËØ∑Ê±ÇÂÜÖÂÆπ‰∏≠ÁöÑÂèÇÊï∞Èô§‰∫Ü messages ËøòÊúâ model Ë°®Á§∫‰ΩøÁî®‰ªÄ‰πàÊ®°ÂûãÔºåstream Ë°®Á§∫ÊòØÂê¶ÊµÅÂºèÂõûÂ§çÔºåtemperature ÊöÇ‰∏îÊåâ‰∏ã‰∏çË°®ÂêéÁª≠‰ºöËØ¶ÁªÜËØ¥Êòé„ÄÇ

ÂõûÂ§çÁöÑÂÜÖÂÆπ‰∏≠ÔºåÊúâ idÔºåÊúâÊèêÁ§∫ËØç token Êï∞ÈáèÔºåÊÄªÁöÑ token Êï∞ÈáèÔºåÊèêÁ§∫ËØçÁºìÂ≠òÂëΩ‰∏≠ token Êï∞ÈáèÔºåÊèêÁ§∫ËØçÁºìÂ≠òÊú™ÂëΩ‰∏≠Êï∞ÔºåÂÖ≥‰∫é Token ÁöÑÊ¶ÇÂøµÔºå‰ºöÂú®‰∏ã‰∏ÄÂ∞èËäÇËØ¥ÊòéÊòØ‰ªÄ‰πà„ÄÇ

choices ÊòØÂú®ËØ∑Ê±ÇÂèÇÊï∞‰∏≠ÔºåËÆæÁΩÆ‰∫ÜËøîÂõûÂá†‰∏™ËøîÂõûÁªìÊûúÔºåÂ¶ÇÊûú‰∏çËÆæÁΩÆÔºåÈªòËÆ§Âè™ËøîÂõû‰∏Ä‰∏™ÁªìÊûú„ÄÇ

ÂÜçÊù•ÁúãÁúã‰∏ãÈù¢Â§öËΩÆÂØπËØùÁöÑÂÜÖÂÆπ

```http
POST https://api.deepseek.com/chat/completions HTTP/1.1
Content-Type: application/json
Accept: application/json
Authorization: Bearer {{$dotenv DEEPSEEK_API_KEY}}

{
  "messages": [
    {
      "content": "‰Ω†ÊòØ‰∏Ä‰∏™Êô∫ËÉΩÂÆ¢Êúç AliceÔºå‰Ω†ÁöÑ‰∏ªË¶Å‰ΩúÁî®Â∞±ÊòØÂ∏ÆÁî®Êà∑Ëß£Á≠îÁñëÈóÆÔºåÂÖ¨Âè∏ÁöÑ‰∏ªË¶Å‰∏öÂä°Â∞±ÊòØÂÅöÈáèÂåñ‰∫§Êòì",
      "role": "system"
    },
    {
      "content": "‰Ω†Â•ΩÔºå‰Ω†ÊòØË∞ÅÔºü",
      "role": "user"
    },
    {
      "content": "‰Ω†Â•ΩÔºÅÊàëÊòØÊô∫ËÉΩÂÆ¢ÊúçAliceÔºåÂæàÈ´òÂÖ¥‰∏∫‰Ω†ÊúçÂä°„ÄÇÊàëÊòØ‰∏Ä‰∏™AIÂä©ÊâãÔºåÂèØ‰ª•Â∏ÆÂä©Ëß£Á≠îÈóÆÈ¢ò„ÄÅÊèê‰æõ‰ø°ÊÅØÊàñÂçèÂä©Â§ÑÁêÜÂêÑÁßç‰∫ãÂä°„ÄÇÊúâ‰ªÄ‰πàÊàëÂèØ‰ª•Â∏Æ‰Ω†ÁöÑÂêóÔºü",
      "role": "assistant"
    },
    {
      "content": "ÊàëÊÉ≥Âí®ËØ¢‰∏ã‰Ω†‰ª¨ÂÖ¨Âè∏ÁöÑ‰∏öÂä°",
      "role": "user"
    }
  ],
  "model": "deepseek-chat",
  "stream": false,
  "temperature": 0
}
```

Â§öËΩÆÂØπËØùÂõûÂ§ç

```json
{
  "id": "bb4143e9-0411-4c57-bb8f-a6c6723eafc1",
  "object": "chat.completion",
  "created": 1754469182,
  "model": "deepseek-chat",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "‰Ω†Â•ΩÔºÅÊàë‰ª¨ÂÖ¨Âè∏‰∏ìÊ≥®‰∫éÈáèÂåñ‰∫§ÊòìÈ¢ÜÂüüÔºå‰∏ªË¶Å‰∏öÂä°ÂåÖÊã¨Ôºö  \n\n1. **ÈáèÂåñÁ≠ñÁï•ÂºÄÂèë**‚Äî‚ÄîÂü∫‰∫éÊï∞Â≠¶„ÄÅÁªüËÆ°Â≠¶ÂíåÁÆóÊ≥ïÊ®°ÂûãÔºåËÆæËÆ°Ëá™Âä®Âåñ‰∫§ÊòìÁ≠ñÁï•„ÄÇ  \n2. **È´òÈ¢ë‰∫§ÊòìÔºàHFTÔºâ**‚Äî‚ÄîÂà©Áî®Ë∂Ö‰ΩéÂª∂ËøüÊäÄÊúØËøõË°åÊØ´ÁßíÁ∫ßÂ∏ÇÂú∫Â•óÂà©„ÄÇ  \n3. **ËµÑ‰∫ßÁÆ°ÁêÜ**‚Äî‚ÄîÈÄöËøáÈáèÂåñÊ®°ÂûãÁÆ°ÁêÜÂü∫ÈáëÊàñÂÆ¢Êà∑ÊäïËµÑÁªÑÂêàÔºå‰ºòÂåñÈ£éÈô©Êî∂ÁõäÊØî„ÄÇ  \n4. **Êï∞ÊçÆ‰∏éÊäÄÊúØÊúçÂä°**‚Äî‚ÄîÊèê‰æõÈáëËûçÊï∞ÊçÆÊ∏ÖÊ¥ó„ÄÅÂõ†Â≠êÊåñÊéò„ÄÅÂõûÊµãÂπ≥Âè∞Á≠âÊîØÊåÅ„ÄÇ  \n\nÂ¶ÇÊûú‰Ω†ÂØπÊüê‰∏™ÊñπÂêëÊÑüÂÖ¥Ë∂£ÔºåÊàñÊÉ≥‰∫ÜËß£ÂÖ∑‰ΩìÊ°à‰æã/Âêà‰ΩúÊñπÂºèÔºåÂèØ‰ª•ÂëäËØâÊàëÔºåÊàë‰ºöËøõ‰∏ÄÊ≠•Ëß£Á≠îÔºÅ üòä"
      },
      "logprobs": null,
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 71,
    "completion_tokens": 130,
    "total_tokens": 201,
    "prompt_tokens_details": {
      "cached_tokens": 0
    },
    "prompt_cache_hit_tokens": 0,
    "prompt_cache_miss_tokens": 71
  },
  "system_fingerprint": "fp_8802369eaa_prod0623_fp8_kvcache"
}
```

## Token

Êàë‰ª¨ÁªèÂ∏∏Âê¨ËØ¥"Â§ßËØ≠Ë®ÄÊ®°ÂûãÊòØÈÄöËøáÈ¢ÑÊµã‰∏ã‰∏Ä‰∏™ËØçÊù•ÁîüÊàêÊñáÊú¨ÁöÑ"„ÄÇ‰ΩÜÂÖ∂ÂÆûÔºåÊ®°ÂûãÂπ∂‰∏çÊòØÁõ¥Êé•È¢ÑÊµã"ËØç"Êàñ"Â≠ó"ÔºåËÄåÊòØÈ¢ÑÊµã‰∏ÄÁßçÂè´ÂÅö"Token"ÁöÑ‰∏úË•ø„ÄÇ

**Token ÂèØ‰ª•ÁêÜËß£‰∏∫Ê®°ÂûãÂ§ÑÁêÜÊñáÊú¨Êó∂ÁöÑÊúÄÂ∞èÂçï‰Ωç„ÄÇ**  
ÂÆÉÂèØËÉΩÊòØ‰∏Ä‰∏™Â≠ó„ÄÅ‰∏Ä‰∏™ËØçÔºåÁîöËá≥ÊòØ‰∏Ä‰∏™Ê†áÁÇπÊàñÈÉ®ÂàÜÂçïËØçÔºåÂÖ∑‰ΩìÊÄé‰πàÂàáÂàÜÁî±Ê®°ÂûãÁöÑ"ÂàÜËØçÂô®"ÂÜ≥ÂÆö„ÄÇ

‰∏æ‰∏™‰æãÂ≠êÔºö  

- "ÊàëÁà±‰Ω†" ÂèØËÉΩ‰ºöË¢´ÂàÜÊàê 3 ‰∏™ TokenÔºàÊØè‰∏™Â≠ó‰∏Ä‰∏™ TokenÔºâ  
- "ChatGPT" ÂèØËÉΩ‰ºöË¢´ÂàÜÊàê 1 ‰∏™ TokenÔºå‰πüÂèØËÉΩË¢´ÊãÜÊàêÂ§ö‰∏™ Token  
- Ëã±ÊñáÈáåÁöÑ "unbelievable" ÂèØËÉΩ‰ºöË¢´ÊãÜÊàê "un", "believ", "able" ‰∏â‰∏™ Token

‰∏∫‰ªÄ‰πàË¶ÅÁî® TokenÔºü  
Âõ†‰∏∫ËÆ°ÁÆóÊú∫‰∏çÊáÇËá™ÁÑ∂ËØ≠Ë®ÄÔºåÂè™ËÉΩÂ§ÑÁêÜÊï∞Â≠ó„ÄÇÂàÜËØçÂô®‰ºöÊääÊØè‰∏™ Token ËΩ¨Êç¢Êàê‰∏Ä‰∏™Êï∞Â≠óÁºñÂè∑ÔºåÊ®°ÂûãÁúãÂà∞ÁöÑÂÖ∂ÂÆûÂ∞±ÊòØ‰∏Ä‰∏≤Êï∞Â≠ó„ÄÇ  
‰Ω†ÂèØ‰ª•Âú®Ëøô‰∏™ÁΩëÁ´ô‰ΩìÈ™å‰∏Ä‰∏ãÂàÜËØçÂíåÁºñÁ†ÅÁöÑËøáÁ®ãÔºöhttps://tiktokenizer.vercel.app/?model=gpt-3.5-turbo

‰∏ãÈù¢ËøôÂº†ÂõæÂ±ïÁ§∫‰∫ÜÊñáÊú¨Ë¢´ÂàÜÊàê Token Âπ∂ÁºñÁ†ÅÊàêÊï∞Â≠óÁöÑËøáÁ®ãÔºö  
![image.png](https://s2.loli.net/2025/08/06/46yrGOqJc73EpjK.png)

ÂÜçÁúã‰∏ÄÁªÑ‰æãÂ≠êÔºåÂ∑¶ËæπÊòØÂéüÊñáÔºåÂè≥ËæπÊòØÊ®°ÂûãÁúãÂà∞ÁöÑ Token ÁºñÂè∑Ôºö  
![image.png](https://s2.loli.net/2025/08/06/zrSMhsmV7jKc2nZ.png)

ÊúâÊó∂ÂÄôÔºå‰∏Ä‰∏™Â≠óÊòØ‰∏Ä‰∏™ TokenÔºåÊúâÊó∂ÂÄô‰∏§‰∏™Â≠óÂêàÊàê‰∏Ä‰∏™ TokenÔºå‰πüÊúâÂèØËÉΩ‰∏Ä‰∏™Ëã±ÊñáÂçïËØçË¢´ÊãÜÊàêÂ§ö‰∏™ TokenÔºåËøôÂÆåÂÖ®ÂèñÂÜ≥‰∫éÂàÜËØçËßÑÂàô„ÄÇ  
![image.png](https://s2.loli.net/2025/08/06/X4yA1xkDSRPh3OI.png)

ÂèØ‰ª•ËøôÊ†∑ÁêÜËß£ÔºöToken Â∞±ÂÉèÊòØÂ§ßÊ®°ÂûãÂ§ÑÁêÜÊñáÊú¨Êó∂ÁöÑ"ÊãºÂõæÂùó"ÔºåÂÆÉ‰∏çÊòØÂçïÁ∫ØÁöÑ"Â≠ó"Êàñ"ËØç"ÔºåËÄåÊòØ‰ªã‰∫é‰∏§ËÄÖ‰πãÈó¥„ÄÅÁî±ÂàÜËØçÂô®ÂÜ≥ÂÆöÁöÑÊúÄÂ∞èÂ§ÑÁêÜÂçïÂÖÉ„ÄÇÁêÜËß£ TokenÔºåÊúâÂä©‰∫éÊàë‰ª¨ÊòéÁôΩÂ§ßÊ®°ÂûãÁöÑËæìÂÖ•ËæìÂá∫„ÄÅËÆ°Ë¥πÊñπÂºè‰ª•Âèä"‰∏ä‰∏ãÊñáÈïøÂ∫¶"Á≠âÊ†∏ÂøÉÊ¶ÇÂøµ„ÄÇ

Áî±‰∫éËÆ°ÁÆóÊú∫ËµÑÊ∫êÊúâÈôêÔºåÂ§ßÊ®°ÂûãÊØèÊ¨°ÁîüÊàê‰∏ã‰∏Ä‰∏™TokenÊó∂ÔºåÈÉΩÈúÄË¶ÅÈÄöËøáËá™Ê≥®ÊÑèÂäõÊú∫Âà∂ËÆ°ÁÆóÂΩìÂâçToken‰∏é‰πãÂâçÊâÄÊúâTokenÁöÑÂÖ≥Á≥ª„ÄÇËøôÁßçÊú∫Âà∂ËÆ©ÊØè‰∏™TokenÈÉΩËÉΩ"ÁúãÂà∞"Âπ∂ÂèÇËÄÉÂ∫èÂàó‰∏≠ÁöÑÊâÄÊúâÁõ∏ÂÖ≥‰ø°ÊÅØÔºå‰ΩÜËÆ°ÁÆóÂ§çÊùÇÂ∫¶ÈöèTokenÊï∞ÈáèÂπ≥ÊñπÁ∫ßÂ¢ûÈïøÔºåÊ∂àËÄóÂ§ßÈáèÁÆóÂäõÂíåÊòæÂ≠ò„ÄÇ

Âõ†Ê≠§ÂºïÂÖ•‰∫Ü"‰∏ä‰∏ãÊñáÁ™óÂè£"ÔºàContext WindowÔºâÁöÑÊ¶ÇÂøµÔºåÊØîÂ¶Ç 4K„ÄÅ32K„ÄÅ128K TokenÁ≠â„ÄÇË∂ÖËøáËøô‰∏™TokenÊï∞ÈáèÂêéÔºåÊ®°ÂûãÂ∞±‰ºöÊà™Êñ≠ÊúÄÊó©ÁöÑÂÜÖÂÆπ„ÄÅÈááÁî®ÊªëÂä®Á™óÂè£Á≠ñÁï•ÔºåÊàñËÄÖÁõ¥Êé•ÊãíÁªùÂ§ÑÁêÜË∂ÖÈïøËæìÂÖ•„ÄÇËøôÊòØÁ°¨‰ª∂ËµÑÊ∫êÈôêÂà∂‰∏ãÁöÑÂøÖÁÑ∂ÈÄâÊã©„ÄÇ

‰∏∫‰∫Ü‰ºòÂåñËøô‰∏™ÈóÆÈ¢òÔºå‰∏öÁïåÂèëÂ±ïÂá∫‰∫ÜÂ§öÁßçÊäÄÊúØÊñπÊ°àÔºö

- **Á®ÄÁñèÊ≥®ÊÑèÂäõ**ÔºöÂè™ËÆ°ÁÆóÈÉ®ÂàÜToken‰πãÈó¥ÁöÑÂÖ≥Á≥ªÔºåËÄåÈùûÂÖ®ËøûÊé•
- **ÊªëÂä®Á™óÂè£Ê≥®ÊÑèÂäõ**ÔºöÈôêÂà∂ÊØè‰∏™TokenÂè™ÂÖ≥Ê≥®ÈôÑËøëÁöÑToken
- **MoEÔºà‰∏ìÂÆ∂Ê∑∑ÂêàÊ®°ÂûãÔºâ**ÔºöÊøÄÊ¥ªÈÉ®ÂàÜÂèÇÊï∞Êù•Â§ÑÁêÜÁâπÂÆöÁ±ªÂûãÁöÑToken
- **KVÁºìÂ≠ò‰ºòÂåñ**ÔºöÂ§çÁî®Â∑≤ËÆ°ÁÆóÁöÑÈîÆÂÄºÂØπÔºåÈÅøÂÖçÈáçÂ§çËÆ°ÁÆó

ÊâÄË∞ì"Ëá™Ê≥®ÊÑèÂäõÊú∫Âà∂"ÁöÑÂº∫Â§ß‰πãÂ§ÑÔºåÂ∞±ÊòØËÆ©Â∫èÂàó‰∏≠ÁöÑÊØè‰∏™TokenÈÉΩËÉΩÂä®ÊÄÅÂÖ≥Ê≥®Âà∞ÂÖ∂‰ªñÊâÄÊúâTokenÔºåÂπ∂Ê†πÊçÆ‰∏ä‰∏ãÊñáËØ≠‰πâÂàÜÈÖç‰∏çÂêåÁöÑÊ≥®ÊÑèÂäõÊùÉÈáç„ÄÇËøôÁßçÊú∫Âà∂Êó¢Â∏¶Êù•‰∫ÜÂçìË∂äÁöÑËØ≠Ë®ÄÁêÜËß£ËÉΩÂäõÔºå‰πüÂ∏¶Êù•‰∫ÜÂ∑®Â§ßÁöÑËÆ°ÁÆóÂºÄÈîÄ„ÄÇ

F12 Â±ïÁ§∫ DeepSeek ËøîÂõûÂìçÂ∫îÂÜÖÂÆπ„ÄÇ

## Êú∫Âô®Â≠¶‰π†

Áé∞‰ª£ AI ÁöÑÊ†∏ÂøÉÂü∫Á°ÄÊòØÊú∫Âô®Â≠¶‰π†„ÄÇÁÆÄÂçïÊù•ËØ¥ÔºåÊú∫Âô®Â≠¶‰π†Â∞±ÊòØËÆ©ËÆ°ÁÆóÊú∫ÈÄöËøáÂ§ßÈáèÊï∞ÊçÆËøõË°å"Â≠¶‰π†"ÔºåËá™Âä®ÊÄªÁªìÂá∫Êï∞ÊçÆ‰∏≠ÁöÑËßÑÂæãÔºàÂç≥ËÆ≠ÁªÉÂá∫‰∏Ä‰∏™ÂáΩÊï∞ÊàñÊ®°ÂûãÔºâ„ÄÇÂΩìÊúâ‰∫ÜËøô‰∏™Ê®°ÂûãÂêéÔºåÈÅáÂà∞Êñ∞ÁöÑÊï∞ÊçÆÔºåËÆ°ÁÆóÊú∫Â∞±ËÉΩÊ†πÊçÆÂ∑≤Â≠¶Âà∞ÁöÑËßÑÂæãÂÅöÂá∫È¢ÑÊµãÊàñÂà§Êñ≠„ÄÇ

Âú®Êú∫Âô®Â≠¶‰π†‰∏≠ÔºåÈÄöÂ∏∏ÂåÖÊã¨‰∏§‰∏™Ê†∏ÂøÉËøáÁ®ãÔºö

- **ËÆ≠ÁªÉÔºàTrainingÔºâ**ÔºöÂà©Áî®Â§ßÈáèÂ∑≤ÊúâÊï∞ÊçÆÔºåËÆ©Ê®°ÂûãËá™Âä®Â≠¶‰π†Êï∞ÊçÆ‰∏≠ÁöÑËßÑÂæãÔºåËøô‰∏ÄËøáÁ®ã‰ºö‰∏çÊñ≠Ë∞ÉÊï¥Ê®°ÂûãÁöÑÂèÇÊï∞Ôºå‰ΩøÂÖ∂Âú®Â∑≤Áü•Êï∞ÊçÆ‰∏äË°®Áé∞Êõ¥Â•Ω„ÄÇ
- **Êé®ÁêÜÔºàInferenceÔºâ**ÔºöÂΩìÊ®°ÂûãËÆ≠ÁªÉÂÆåÊàêÂêéÔºåÈÅáÂà∞Êñ∞ÁöÑ„ÄÅÊú™ËßÅËøáÁöÑÊï∞ÊçÆÊó∂ÔºåÂà©Áî®Â∑≤Â≠¶Âà∞ÁöÑËßÑÂæãËøõË°åÈ¢ÑÊµãÊàñÂà§Êñ≠ÔºåËøô‰∏ÄËøáÁ®ãÁß∞‰∏∫Êé®ÁêÜ„ÄÇ

Ê†πÊçÆÊï∞ÊçÆÊòØÂê¶ÊúâÊ†áÊ≥®ÔºåÊú∫Âô®Â≠¶‰π†‰∏ªË¶ÅÂàÜ‰∏∫Âá†Á±ªÔºö

- **ÁõëÁù£Â≠¶‰π†ÔºàSupervised LearningÔºâ**ÔºöÊâÄÊúâËÆ≠ÁªÉÊï∞ÊçÆÈÉΩÊúâÊòéÁ°ÆÁöÑÊ†áÊ≥®ÔºàÊØîÂ¶ÇÂõæÁâáÂíåÂØπÂ∫îÁöÑÊ†áÁ≠æÔºâÔºåÊ®°ÂûãÈÄöËøáËøô‰∫õ"Ê†áÂáÜÁ≠îÊ°à"Â≠¶‰π†ËßÑÂæã„ÄÇ
- **Êó†ÁõëÁù£Â≠¶‰π†ÔºàUnsupervised LearningÔºâ**ÔºöËÆ≠ÁªÉÊï∞ÊçÆÊ≤°ÊúâÊ†áÊ≥®ÔºåÊ®°ÂûãÈúÄË¶ÅËá™Â∑±Âú®Êï∞ÊçÆ‰∏≠ÂèëÁé∞ÁªìÊûÑÊàñÊ®°ÂºèÔºàÊØîÂ¶ÇËÅöÁ±ª„ÄÅÈôçÁª¥Ôºâ„ÄÇ
- **ÂçäÁõëÁù£Â≠¶‰π†ÔºàSemi-Supervised LearningÔºâ**ÔºöÂè™ÊúâÈÉ®ÂàÜÊï∞ÊçÆÊúâÊ†áÊ≥®ÔºåÁªìÂêàÊúâÊ†áÊ≥®ÂíåÊó†Ê†áÊ≥®ÁöÑÊï∞ÊçÆÂÖ±ÂêåËÆ≠ÁªÉÊ®°Âûã„ÄÇ
- **Âº∫ÂåñÂ≠¶‰π†ÔºàReinforcement LearningÔºâ**ÔºöÈÄöËøá"ËØïÈîô"ÂíåÂ•ñÂä±Êú∫Âà∂ÔºåËÆ©Ê®°ÂûãÂú®‰∏éÁéØÂ¢ÉÁöÑ‰∫§‰∫í‰∏≠‰∏çÊñ≠‰ºòÂåñÂÜ≥Á≠ñÁ≠ñÁï•„ÄÇ

Êú∫Âô®Â≠¶‰π†ËÆ© AI ËÉΩÂ§ü‰ªéÊï∞ÊçÆ‰∏≠Ëá™ÊàëËøõÂåñÂíåÊèêÂçáÔºåÊòØÁé∞‰ª£Êô∫ËÉΩÁ≥ªÁªüÁöÑÂü∫Áü≥„ÄÇ

## OpenAI Êé•Âè£

OpenAI ÊòØÊúÄÊó©ÂèëÂ∏ÉÂπ∂ÊàêÂäüÊé®ÂπøÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÂÖ¨Âè∏ÔºåÂÖ∂ API ËÆæËÆ°Â∑≤Êàê‰∏∫Ë°å‰∏ö‰∫ãÂÆûÊ†áÂáÜ„ÄÇÂ¶Ç‰ªäÔºåÈÄö‰πâÂçÉÈóÆ„ÄÅDeepSeek Á≠â‰ºóÂ§öÂéÇÂïÜÁöÑÊé•Âè£ÈÉΩ‰∏é OpenAI ÂÖºÂÆπÔºåÂõ†Ê≠§Âè™ÈúÄÂèÇËÄÉ OpenAI ÁöÑ HTTP API ÊñáÊ°£ÔºåÂç≥ÂèØÂø´ÈÄü‰∏äÊâãÂ§ßÂ§öÊï∞‰∏ªÊµÅÂ§ßÊ®°ÂûãÁöÑË∞ÉÁî®ÊñπÂºè„ÄÇ

ÂÆòÊñπÊñáÊ°£Âú∞ÂùÄÔºöhttps://platform.openai.com/docs/overview

‰ª•‰ªªÊÑè‰∏Ä‰∏™Â§ßËØ≠Ë®ÄÊ®°Âûã‰∏∫‰æãÔºåÁõÆÂâç Chat Completions ÊîØÊåÅÊñáÊú¨‰∏éÂõæÂÉèËæìÂÖ•Ôºå‰ΩÜËæìÂá∫‰ªÖÈôêÊñáÊú¨„ÄÇÊó©ÊúüÁöÑÊé•Âè£‰ªÖÊîØÊåÅÊñáÊú¨ËæìÂÖ•ËæìÂá∫„ÄÇËá≥‰∫éÂ§öÊ®°ÊÄÅÔºàÂ¶ÇÂõæÁâá„ÄÅÈü≥È¢ë„ÄÅËßÜÈ¢ëÁöÑËæìÂÖ•ËæìÂá∫ÔºâËÉΩÂäõÔºå‰ºöÂú®ÂêéÊñá Agent Áõ∏ÂÖ≥Á´†ËäÇËØ¶ÁªÜ‰ªãÁªç„ÄÇ
![image.png](https://s2.loli.net/2025/08/06/GkB89S7HpmvexUy.png)

OpenAI ÁöÑÊ†∏ÂøÉËÉΩÂäõÂåÖÊã¨ÔºöÊñáÊú¨ÁîüÊàê„ÄÅÂõæÂÉè‰∏éËßÜËßâÂ§ÑÁêÜ„ÄÅËØ≠Èü≥ËØÜÂà´‰∏éÂêàÊàêÁ≠â„ÄÇ

ÂèØ‰ª•ÁÆÄÂçïÁêÜËß£‰∏∫ÔºöÂ§ßËØ≠Ë®ÄÊ®°ÂûãÊòØ"Êô∫ËÉΩÂ§ßËÑë"ÔºåËÄåËØ≠Èü≥ËΩ¨ÊñáÊú¨ÔºàSpeech-to-Text, STTÔºâÂíåÊñáÊú¨ËΩ¨ËØ≠Èü≥ÔºàText-to-Speech, TTSÔºâÁ≠âÊäÄÊúØÔºåÊòØ‰∏∫ ChatGPT ËøôÁ±ª‰∫ßÂìÅÊúçÂä°ÁöÑ"ËæìÂÖ•ËæìÂá∫ÈÄöÈÅì"„ÄÇÁî®Êà∑ÁöÑËØ≠Èü≥‰ºöÂÖàË¢´ STT ËΩ¨ÊàêÊñáÊú¨Ôºå‰∫§ÁªôÂ§ßÊ®°ÂûãÂ§ÑÁêÜÔºåÁîüÊàêÁöÑÊñáÊú¨ÂÜçÈÄöËøá TTS ËΩ¨ÂõûËØ≠Èü≥ÔºåÊúÄÁªàËøîÂõûÁªôÁî®Êà∑„ÄÇ

## ÂÖ∂‰ªñ

ÁÆÄÂçï‰ªãÁªç‰∏ãÂ§ßÊ®°ÂûãËÆ≠ÁªÉÁöÑÈ¢ÑÊñôÊù•Ê∫ê‰∫éÂì™ÈáåÔºåÂ§ßÊ®°ÂûãÁöÑ pre-training Âíå post-training ÊòØ‰ªÄ‰πà„ÄÇ

### ËÆ≠ÁªÉËØ≠ÊñôÊ†ºÂºè

- È¢ÑËÆ≠ÁªÉÔºàPretrainingÔºâÈò∂ÊÆµÔºöÊ†∏ÂøÉÊòØÂ§ßËßÑÊ®°ÈÄöÁî®ÊñáÊú¨ÁöÑ‰∏ã‰∏ÄËØçÈ¢ÑÊµã„ÄÇËæìÂÖ•‰ª•‚ÄúÁ∫ØÊñáÊú¨ token Â∫èÂàó‚Äù‰∏∫‰∏ªÔºåÁΩëÈ°µ/ÊñáÊ°£‰∏≠ÁöÑHTML/MarkdownÁ≠âËΩªÈáèÊ†áËÆ∞ÂèØ‰øùÁïô‰ª•Êèê‰æõÁªìÊûÑÁ∫øÁ¥¢Ôºå‰ΩÜÊúÄÁªàÈÉΩ‰ºöË¢´ÂàÜËØçÂô®ËΩ¨ÊàêToken„ÄÇ
- Êåá‰ª§ÂæÆË∞É/ÂØπÈΩêÔºàSFT„ÄÅRLHFÁ≠âÔºâÈò∂ÊÆµÔºöÊ†∏ÂøÉÊòØ‚ÄúÂØπËØù/Êåá‰ª§‚ÄùÊï∞ÊçÆÔºåÈÄöÂ∏∏ÈááÁî®ÁªìÊûÑÂåñÊ†∑ÂºèÔºàÂ¶ÇJSONLÔºâÔºåÊØèÊù°Ê†∑Êú¨ÂåÖÂê´‰∏ÄÁªÑ`messages`Ôºàsystem/user/assistantÔºâ‰ª•ÂèäÂèØÈÄâÁöÑÂ∑•ÂÖ∑Ë∞ÉÁî®ËÆ∞ÂΩï‰∏éÂÅèÂ•ΩÊ†áÊ≥®„ÄÇ

ËØ≠ÊñôÊù•Ê∫ê‰∏éÂ§ÑÁêÜÔºàÁÆÄË¶ÅÔºâÔºö

- Êù•Ê∫êÔºöCommon Crawl/Wikipedia/Books/Â≠¶ÊúØËÆ∫Êñá/ËÆ∫ÂùõÈóÆÁ≠î/ÂºÄÊ∫ê‰ª£Á†Å‰ªìÂ∫ì/ÂêàÊàêÂØπËØùÊï∞ÊçÆÁ≠â„ÄÇ
- Ê∏ÖÊ¥óÔºöÂéªÈáç„ÄÅËØ≠Ë®ÄËØÜÂà´„ÄÅ‰ΩéË¥®ÂÜÖÂÆπËøáÊª§„ÄÅÁâàÊùÉ‰∏éÂêàËßÑÂÆ°Êü•„ÄÅÊ†ºÂºèÁªü‰∏Ä„ÄÇ
- Ê∑∑ÂêàÔºö‰∏çÂêåÂüü‰∏éËØ≠Ë®ÄÊåâÈÖçÊØîÊ∑∑ÂêàÔºåÊèêÂçáÊ≥õÂåñ‰∏éÁ®≥ÂÅ•ÊÄß„ÄÇ

Á§∫‰æã1ÔºàÈ¢ÑËÆ≠ÁªÉÊ†∑Êú¨ÔºåÂ±ïÁ§∫‰∏∫ÊôÆÈÄöÊñáÊú¨ÔºåÂÆûÈôÖËÆ≠ÁªÉÊó∂‰ºöË¢´ÂàÜËØç‰∏∫TokenÔºâÔºö

```text
TransformerÊòØ‰∏ÄÁßçÂü∫‰∫éËá™Ê≥®ÊÑèÂäõÊú∫Âà∂ÁöÑÂ∫èÂàóÂª∫Ê®°Êû∂ÊûÑÔºåÂèØÂπ∂Ë°åÂ§ÑÁêÜÂ∫èÂàóÂπ∂ÊçïÊçâÈïøË∑ùÁ¶ª‰æùËµñÂÖ≥Á≥ª„ÄÇ
```

Á§∫‰æã2ÔºàÊåá‰ª§ÂæÆË∞ÉÊ†∑Êú¨ÔºåÂ∏∏ËßÅ‰∏∫JSONLÔºåÊØèË°å‰∏ÄÊù°ÔºâÔºö

```json
{"messages":[
  {"role":"system","content":"You are a helpful assistant."},
  {"role":"user","content":"Áî®‰∏ÄÂè•ËØùËß£Èáä‰ªÄ‰πàÊòØËá™Ê≥®ÊÑèÂäõ„ÄÇ"},
  {"role":"assistant","content":"Ëá™Ê≥®ÊÑèÂäõÈÄöËøá‰∏∫Â∫èÂàó‰∏≠ÊØè‰∏™‰ΩçÁΩÆÂàÜÈÖçÂØπÂÖ∂‰ªñ‰ΩçÁΩÆÁöÑÊùÉÈáçÊù•ËÅöÂêà‰ø°ÊÅØÔºå‰ª•ÊçïÊçâÈïøÁ®ã‰æùËµñ„ÄÇ"}
]}
```

ÂèØÈÄâÔºàÂ∑•ÂÖ∑Ë∞ÉÁî®/ÂáΩÊï∞Ë∞ÉÁî®Â¢ûÂº∫ÔºåËÆ≠ÁªÉÊ®°ÂûãÂ≠¶‰ºöÁªìÊûÑÂåñËæìÂá∫‰∏éË∞ÉÁî®Â§ñÈÉ®Â∑•ÂÖ∑ÔºâÔºö

```json
{"messages":[{"role":"user","content":"Âåó‰∫¨‰ªäÂ§©Â§©Ê∞îÔºü"}],
 "tools":[{"type":"function","function":{"name":"get_weather","parameters":{"type":"object","properties":{"city":{"type":"string"}},"required":["city"]}}}],
 "assistant":{"tool_calls":[{"id":"call_1","type":"function","function":{"name":"get_weather","arguments":"{\"city\":\"Âåó‰∫¨\"}"}}]},
 "tool_outputs":[{"tool_call_id":"call_1","output":"Êô¥Ôºå28‚ÑÉ"}]}
```

### Pre-Training

**1. È¢ÑËÆ≠ÁªÉÊòØ‰ªÄ‰πàÔºü**
È¢ÑËÆ≠ÁªÉÊòØÂ§ßËØ≠Ë®ÄÊ®°ÂûãÂ≠¶‰π†ÁöÑ"ÂêØËíôÈò∂ÊÆµ"ÔºåÂ∞±ÂÉèÂ∞èÂ≠©ÂàöÂºÄÂßãÂ≠¶ËØ¥ËØùÊó∂ÔºåÂÖàÂê¨Â§ßÈáèÁöÑÂØπËØù„ÄÅÊïÖ‰∫ãÂíå‰π¶Á±ç„ÄÇÂ§ßÊ®°Âûã‰ºöË¢´ÂñÇÂÖ•Êµ∑ÈáèÁöÑ‰∫íËÅîÁΩëÊñáÊú¨ÔºàÊØîÂ¶ÇÁΩëÈ°µ„ÄÅ‰π¶Á±ç„ÄÅÊñ∞Èóª„ÄÅËÆ∫ÂùõÁ≠âÔºâÔºå‰ΩÜËøô‰∫õÊñáÊú¨Ê≤°ÊúâÊ†áÂáÜÁ≠îÊ°àÔºåÊ®°Âûã‰πü‰∏çÁü•ÈÅì‰ªÄ‰πàÊòØ"ÂØπ"Êàñ"Èîô"„ÄÇÂÆÉÁöÑ‰ªªÂä°ÂæàÁÆÄÂçï‚Äî‚ÄîÁåú‰∏ã‰∏Ä‰∏™ËØçÔºàÂáÜÁ°ÆËØ¥ÊòØ TokenÔºâ„ÄÇ

**2. ÂÖ∑‰ΩìÊÄé‰πàÂ≠¶Ôºü**
ÊØîÂ¶ÇÁªôÊ®°Âûã‰∏ÄÂè•ËØùÔºö"‰ªäÂ§©Â§©Ê∞îÂæà"ÔºåËÆ©ÂÆÉÁåú‰∏ã‰∏Ä‰∏™ËØçÊòØ‰ªÄ‰πà„ÄÇÂèØËÉΩÊòØ"Â•Ω""Êô¥Êúó""Á≥üÁ≥ï"Á≠â„ÄÇÊ®°Âûã‰ºöÂú®Êó†Êï∞ËøôÊ†∑ÁöÑÂè•Â≠ê‰∏≠ÂèçÂ§çÁªÉ‰π†ÔºåÊØèÊ¨°ÈÉΩÂ∞ùËØïÈ¢ÑÊµã‰∏ã‰∏Ä‰∏™ËØç„ÄÇÊØèÁåúÈîô‰∏ÄÊ¨°ÔºåÊ®°ÂûãÂ∞±‰ºöË∞ÉÊï¥Ëá™Â∑±ÁöÑ"ËÑëÂõûË∑Ø"ÔºàÂèÇÊï∞ÔºâÔºå‰∫âÂèñ‰∏ãÊ¨°ÁåúÂæóÊõ¥ÂáÜ„ÄÇ

**3. È¢ÑËÆ≠ÁªÉÁöÑÁõÆÊ†áÊòØ‰ªÄ‰πàÔºü**
È¢ÑËÆ≠ÁªÉ‰∏çÊòØËÆ©Ê®°ÂûãÁõ¥Êé•‰ºöÂÜôËØó„ÄÅÁ≠îÈ¢ò„ÄÅÂÜô‰ª£Á†ÅÔºåËÄåÊòØËÆ©ÂÆÉÂÉè"ËØªÈÅç‰∫íËÅîÁΩë"‰∏ÄÊ†∑ÔºåÁßØÁ¥ØÂ§ßÈáèÁöÑËØ≠Ë®ÄÁü•ËØÜ„ÄÅÂ∏∏ËØÜ„ÄÅËØ≠Ê≥ïÂíåË°®ËææËÉΩÂäõ„ÄÇÂÆÉ‰ºöÂ≠¶‰ºöÂì™‰∫õËØçÁªèÂ∏∏‰∏ÄËµ∑Âá∫Áé∞Ôºå‰ªÄ‰πàÊ†∑ÁöÑÂè•Â≠êÁªìÊûÑÊõ¥Ëá™ÁÑ∂ÔºåÁîöËá≥ËÉΩÈöêÁ∫¶ÁêÜËß£‰∏Ä‰∫õÂõ†ÊûúÂÖ≥Á≥ªÂíåÊé®ÁêÜÈÄªËæë„ÄÇ

**4. ‰∏∫‰ªÄ‰πàË¶ÅËøôÊ†∑ÂÅöÔºü**
Âõ†‰∏∫Âè™ÊúâÂÖàÊúâ‰∫Ü"Áü•ËØÜÂ∫ïÂ∫ß"ÔºåÊ®°ÂûãÊâçËÉΩÂú®ÂêéÁª≠ÁöÑÂæÆË∞ÉÈò∂ÊÆµÔºåÂø´ÈÄüÂ≠¶‰ºöÂêÑÁßçÂÖ∑‰Ωì‰ªªÂä°ÔºàÊØîÂ¶ÇÂÜôÊëòË¶Å„ÄÅÁøªËØë„ÄÅÂÜô‰ª£Á†ÅÁ≠âÔºâ„ÄÇÂ∞±ÂÉè‰Ω†Â∞èÊó∂ÂÄôÂÖàÂ≠¶‰ºö‰∫ÜÊ±âËØ≠ÔºåÈïøÂ§ßÂêéÊâçËÉΩÁî®Ê±âËØ≠Â≠¶Êï∞Â≠¶„ÄÅÁâ©ÁêÜ„ÄÅÂéÜÂè≤„ÄÇ

**5. ÁªÜËäÇË°•ÂÖÖÔºö**

- È¢ÑËÆ≠ÁªÉÁöÑÊï∞ÊçÆÈáèÊûÅÂÖ∂Â∫ûÂ§ßÔºåÈÄöÂ∏∏ÊòØTBÁîöËá≥PBÁ∫ßÂà´„ÄÇ
- ËÆ≠ÁªÉÊó∂Èó¥ÂæàÈïøÔºåÈúÄË¶ÅÂ§ßÈáèÁÆóÂäõÔºàÊàêÁôæ‰∏äÂçÉÂº†ÊòæÂç°ÂêåÊó∂Â∑•‰ΩúÊï∞Âë®ÁîöËá≥Êï∞ÊúàÔºâ„ÄÇ
- È¢ÑËÆ≠ÁªÉÈò∂ÊÆµÁöÑÊçüÂ§±ÂáΩÊï∞ÈÄöÂ∏∏ÊòØ"‰∏ã‰∏Ä‰∏™ËØçÈ¢ÑÊµã"ÔºàNext Token PredictionÔºâÔºå‰πüÂè´Ëá™ÂõûÂΩíËØ≠Ë®ÄÂª∫Ê®°„ÄÇ

### Post-Training

È¢ÑËÆ≠ÁªÉËÆ©Ê®°Âûã‚Äú‰ºöËØ¥ËØù‚ÄùÔºåÂêéËÆ≠ÁªÉËÆ©Ê®°Âûã‚ÄúËØ¥ÂæóÂØπ„ÄÅËØ¥ÂæóÂ•Ω„ÄÅÊáÇËßÑÂàô‚Äù„ÄÇÂêéËÆ≠ÁªÉ‰∏ÄËà¨ÂåÖÂê´‰ª•‰∏ãË∑ØÂæÑÔºö

1) ÁõëÁù£ÂæÆË∞ÉÔºàSFT, Supervised Fine-TuningÔºâ

- ÁõÆÊ†áÔºöËÆ©Ê®°ÂûãÂ≠¶‰ºöÈÅµÂæ™Êåá‰ª§„ÄÅ‰∫ßÂá∫ÊúüÊúõÊ†ºÂºè‰∏éËØ≠Ê∞î„ÄÇ
- Êï∞ÊçÆÔºöÈ´òË¥®ÈáèÁöÑÈóÆÁ≠î/ÂØπËØùÊ†∑Êú¨ÔºàÂèØÂê´system/user/assistantÔºåÂ§öËΩÆÂØπËØùÊõ¥‰Ω≥Ôºâ„ÄÇ
- Âª∫ËÆÆÔºöË¶ÜÁõñÂ∏∏ËßÅ‰ªªÂä°Ê®°ÊùøÔºàËß£Èáä„ÄÅÊÄªÁªì„ÄÅÊîπÂÜô„ÄÅÊé®ÁêÜ„ÄÅ‰ª£Á†Å„ÄÅË°®Ê†º/JSONËæìÂá∫Á≠âÔºâÔºåÂ∞ëËÄåÁ≤æ‰ºò‰∫éÂ§öËÄåÊùÇ„ÄÇ
- ÁÆÄ‰æãÔºàJSONLÔºå‰∏ÄË°å‰∏ÄÊù°ÔºâÔºö

```json
{"messages":[
  {"role":"system","content":"You are a helpful and safe assistant."},
  {"role":"user","content":"ËØ∑Áî®Ë¶ÅÁÇπËß£ÈáäËá™Ê≥®ÊÑèÂäõÁöÑ‰ΩúÁî®„ÄÇ"},
  {"role":"assistant","content":"- ‰∏∫ÊØè‰∏™‰ΩçÁΩÆÂàÜÈÖçÂØπÂÖ∂‰ªñ‰ΩçÁΩÆÁöÑÊùÉÈáç\n- ËÅöÂêàÂÖ®Â±Ä‰ø°ÊÅØ‰ª•Âª∫Ê®°ÈïøÁ®ã‰æùËµñ\n- ÊîØÊåÅÂπ∂Ë°åËÆ°ÁÆóÔºåÊèêÂçáÊïàÁéá"}
]}
```

2) ÂÅèÂ•ΩÂØπÈΩêÔºàRLHF / RM + PPOÔºâ

- ÊµÅÁ®ãÔºö
  - ÈááÊ†∑ÔºöÁªôÂÆöÂêå‰∏ÄÊèêÁ§∫ÔºåÊ®°ÂûãÁîüÊàêÂ§öÂÄôÈÄâÁ≠îÂ§çÔºõ
  - Ê†áÊ≥®Ôºö‰∫∫Á±ªÂØπÂÄôÈÄâËøõË°å‚ÄúÊàêÂØπÂÅèÂ•Ω‚ÄùÈÄâÊã©Ôºàchosen/rejectedÔºâÔºõ
  - ËÆ≠ÁªÉÔºöÁî®ÂÅèÂ•ΩÊï∞ÊçÆËÆ≠ÁªÉÂ•ñÂä±Ê®°ÂûãÔºàReward Model, RMÔºâÔºõ
  - Âº∫ÂåñÔºöÁî®PPOÁ≠âÁÆóÊ≥ïÂæÆË∞ÉÂü∫Â∫ß/Êåá‰ª§Ê®°ÂûãÔºå‰ΩøÂÖ∂ÊúÄÂ§ßÂåñRMËØÑÂàÜÔºõ
  - ÊïàÊûúÔºöÊõ¥Á¨¶Âêà‰∫∫Á±ªÂÅèÂ•ΩÔºåÂáèÂ∞ëÊîªÂáªÊÄß/Ë∑ëÈ¢ò/ÂÜóÈïø„ÄÇ
- ÂÅèÂ•ΩÊï∞ÊçÆÊ†ºÂºèÔºàpairwiseÔºåÂØπRMÊàñDPOÂùáÈÄÇÁî®ÔºâÔºö

```json
{"prompt":"‰ªÄ‰πàÊòØËøáÊãüÂêàÔºü",
 "chosen":"ËøáÊãüÂêàÊåáÊ®°ÂûãÂú®ËÆ≠ÁªÉÈõÜ‰∏äË°®Áé∞ÂæàÂ•ΩÔºå‰ΩÜÂú®Êú™ËßÅËøáÁöÑÊï∞ÊçÆ‰∏äÊ≥õÂåñÂæàÂ∑ÆÔºåÈÄöÂ∏∏Âõ†Ê®°ÂûãËøá‰∫éÂ§çÊùÇÊàñÊ≠£ÂàôÂåñ‰∏çË∂≥ÂØºËá¥„ÄÇ",
 "rejected":"ËøáÊãüÂêàÂ∞±ÊòØÊ®°ÂûãÂæàÂº∫ÔºåËÉΩÊääËÆ≠ÁªÉÈõÜÂÖ®ÈÉ®ËÆ∞‰ΩèÔºåÊâÄ‰ª•ËøôÂæàÂ•Ω„ÄÇ"}
```

3) Êó†Âº∫ÂåñÁöÑÂÅèÂ•Ω‰ºòÂåñÔºàDPO/IPO/KTO Á≠âÔºâ

- ÊÄùË∑ØÔºöË∑≥ËøáÊòæÂºèÂ•ñÂä±Ê®°Âûã‰∏éPPOÔºåÁõ¥Êé•Áî®ÊàêÂØπÂÅèÂ•ΩÊï∞ÊçÆËøõË°åÂØπÊØîÁõÆÊ†á‰ºòÂåñÔºõ
- ‰ºòÁÇπÔºöÂÆûÁé∞ÁÆÄÂçï„ÄÅÁ¶ªÁ∫øÂèØËÆ≠ÁªÉ„ÄÅÁ®≥ÂÆöÊÄßÂ•ΩÔºõ
- Â∏∏Áî®ÔºöDPOÔºàDirect Preference OptimizationÔºâ„ÄÇ
- DPOÊï∞ÊçÆÂêå‰∏äÔºàprompt/chosen/rejectedÔºâÔºõËÆ≠ÁªÉÊó∂ÈÖçÁΩÆÊ∏©Â∫¶‰∏éÊ≠£ÂàôË∂ÖÂèÇÔºàÂ¶ÇŒ≤Ôºâ„ÄÇ

4) Â∑•ÂÖ∑Ë∞ÉÁî®‰∏éÁªìÊûÑÂåñËæìÂá∫ÂØπÈΩê

- ÁõÆÊ†áÔºöËÆ©Ê®°ÂûãÁ®≥ÂÆöÂú∞‰∫ßÁîüÂáΩÊï∞Ë∞ÉÁî®/JSONÁªìÊûú„ÄÅÈÅµÂæ™schema„ÄÇ
- ÂÅöÊ≥ïÔºöÂú®SFTÊï∞ÊçÆ‰∏≠Âä†ÂÖ•ÂáΩÊï∞/Â∑•ÂÖ∑Ë∞ÉÁî®Ê†∑Êú¨ÔºàÂê´toolsÂÆö‰πâ„ÄÅassistantÁöÑtool_calls‰∏étool_outputsÔºâÔºåÂπ∂Âä†ÂÖ•‚Äú‰∏•Ê†ºJSON/Ë°®Ê†º/Markdown‚ÄùËæìÂá∫ÁöÑÊ≠£Âèç‰æãÔºõ
- ËØÑ‰º∞ÔºöÂ≠óÊÆµÈΩêÂÖ®Áéá„ÄÅJSONÂèØËß£ÊûêÁéá„ÄÅÂáΩÊï∞ÂëΩ‰∏≠ÁéáÔºàÊ≠£Á°ÆÂ∑•ÂÖ∑‰∏éÂèÇÊï∞Ôºâ„ÄÇ

5) ÂÆâÂÖ®‰∏éÊãíÁ≠îÔºàSafety / RefusalÔºâ

- ÊâãÊÆµÔºö
  - Á≥ªÁªüÊèêÁ§∫+SFTÂÆâÂÖ®ÂØπËØùÊ®°ÊùøÔºàÁ§ºË≤åÊãíÁ≠î„ÄÅËß£ÈáäÂéüÂõ†„ÄÅÊèê‰æõÊõø‰ª£ÊñπÊ°àÔºâÔºõ
  - ÂÅèÂ•ΩÊï∞ÊçÆÈºìÂä±‚ÄúÂÆâÂÖ®‰ºòÂÖà‚ÄùÁöÑÂõûÁ≠îÔºõ
  - Â§ñÊåÇÂÆâÂÖ®ÂàÜÁ±ªÂô®/ÂÆ°Ê†∏ÔºàModerationÔºâÂÅöÊé®ÁêÜÂâç/ÂêéËøáÊª§Ôºõ
- ÁõÆÊ†áÔºöÂú®ÊïèÊÑü„ÄÅËøùÊ≥ï„ÄÅÊúâÂÆ≥Âú∫ÊôØ‰∏ãÁ®≥ÂÆöÊãíÁ≠î‰∏îÁªôÂá∫Ê≠£ÂΩìÁêÜÁî±„ÄÇ

6) ËØÑ‰º∞‰∏éÁõëÊéß

- Ëá™Âä®ÊåáÊ†áÔºöÈÅµÂæ™Êåá‰ª§Â∫¶ÔºàIFÔºâ„ÄÅÊúâÁî®ÊÄß/Êó†ÂÆ≥ÊÄßÔºàHHÔºâ„ÄÅ‰∫ãÂÆûÊÄßÔºàÂèØÁªìÂêàRAG‰∏éÂºïÁî®Ôºâ„ÄÅÁªìÊûÑÂåñËæìÂá∫Ê≠£Á°ÆÁéá„ÄÅÂáΩÊï∞Ë∞ÉÁî®Ê≠£Á°ÆÁéáÔºõ
- ‰∫∫ËØÑÔºöÂü∫‰∫éÁúüÂÆûÁî®‰æãÁöÑÊâìÂàÜ‰∏éÂÅèÂ•ΩÂØπÊØîÔºõ
- Á∫ø‰∏äËßÇÊµãÔºöÂèçÈ¶àÈó≠ÁéØ‰∏éÁ∫¢ÈòüÔºàred-teamingÔºâË¶ÜÁõñÊñ∞ÂûãÊîªÂáª‰∏éË∂äÁã±Ê†∑Âºè„ÄÇ

ÂÆûË∑µÂª∫ËÆÆ

- Êï∞ÊçÆË¥®Èáè‰ºòÂÖàÔºöÈ´ò‰ø°Âô™ÊØî„ÄÅÈ£éÊ†º‰∏ÄËá¥„ÄÅË¶ÜÁõñÊ†∏ÂøÉ‰ªªÂä°Ê®°ÊùøÔºõ
- ÈÄÇÂ∫¶Â§öËΩÆÔºöËÆ©Ê®°ÂûãÂ≠¶‰ºö‰∏ä‰∏ãÊñáÊâøÊé•‰∏éÁ∫†ÈîôÔºõ
- Ë¥üÊ†∑Êú¨ÔºöÂä†ÂÖ•Ëøù‰æã/ÂùèÊ†ºÂºè/Ë∂äÊùÉËØ∑Ê±ÇÔºåÊ†áÊ≥®Ê≠£Á°ÆÊãíÁ≠îÊñπÂºèÔºõ
- È¢ÜÂüüÂåñÔºöÈÄöÁî®Êï∞ÊçÆÊâìÂ∫ï+È¢ÜÂüüÊï∞ÊçÆÂ¢ûÂº∫ÔºåÊ≥®ÊÑèÈÖçÊØîÈÅøÂÖç‚ÄúÈÅóÂøòÈÄöÁî®ËÉΩÂäõ‚Äù„ÄÇ

‰∫ßÁâ©‰∏é‰ΩøÁî®

- ‰∫ßÁâ©ÔºöÂæÆË∞ÉÂêéÁöÑÊ®°ÂûãID‰∏éÊé®ÁêÜÈÖçÁΩÆÔºàsystemÊèêÁ§∫„ÄÅÊ∏©Â∫¶/ÊÉ©ÁΩöÈ°π„ÄÅJSONÊ®°Âºè„ÄÅÂ∑•ÂÖ∑Ê∏ÖÂçïÔºâÔºõ
- ÁõÆÊ†áÔºöÊõ¥Á®≥„ÄÅÊõ¥ÂÆâÂÖ®„ÄÅÊõ¥ÂèØÊéßÂú∞ÂÆåÊàêÁúüÂÆû‰∏öÂä°‰ªªÂä°„ÄÇ

### HallucinationÔºàÂπªËßâÔºâ

Â§ßËØ≠Ë®ÄÊ®°ÂûãÊúâÊó∂‰ºöÂú®Ëá™Â∑±‰∏ç‰∫ÜËß£ÊàñÁº∫‰πèÁü•ËØÜÁöÑÈ¢ÜÂüü"ËÉ°Áºñ‰π±ÈÄ†"ÔºåËøôÂ∞±ÊòØÊâÄË∞ìÁöÑ AI ÂπªËßâÔºàHallucinationÔºâ„ÄÇÂÖ∂Ê†πÊú¨ÂéüÂõ†Âú®‰∫éÔºåÂ§ßÊ®°ÂûãÂπ∂‰∏çÁúüÊ≠£"ÁêÜËß£"ÈóÆÈ¢òÁöÑÂê´‰πâÔºåËÄåÊòØÊ†πÊçÆÂ∑≤ÊúâÁöÑËÆ≠ÁªÉÊï∞ÊçÆÂíå‰∏ä‰∏ãÊñáÔºåÊ¶ÇÁéáÊÄßÂú∞ÁîüÊàê‰∏ã‰∏Ä‰∏™ Token„ÄÇËøôÁßçÊú∫Âà∂ÂØºËá¥Ê®°ÂûãÂú®Èù¢ÂØπÈôåÁîü„ÄÅÊ®°Á≥äÊàñÊï∞ÊçÆÁ®ÄÁº∫ÁöÑÈóÆÈ¢òÊó∂ÔºåÂèØËÉΩ‰ºöËá™‰ø°Âú∞ÁªôÂá∫ÈîôËØØÁîöËá≥ËôöÊûÑÁöÑÁ≠îÊ°à„ÄÇ

#### Â¶Ç‰ΩïÂáèÂ∞ëÂπªËßâÔºü

- **‰ºòÂåñÊèêÁ§∫ËØçÔºàPrompt EngineeringÔºâ**ÔºöÈÄöËøáÊõ¥ÊòéÁ°Æ„ÄÅÂÖ∑‰ΩìÁöÑÊèêÁ§∫ËØçÔºåÂºïÂØºÊ®°ÂûãËÅöÁÑ¶‰∫éÂ∑≤Áü•‰ø°ÊÅØÔºåÂáèÂ∞ëÊó†Ê†πÊçÆÁöÑÁåúÊµã„ÄÇ
- **ÂºïÂÖ• RAG ÊäÄÊúØÔºàRetrieval-Augmented GenerationÔºâ**ÔºöÁªìÂêàÂ§ñÈÉ®Áü•ËØÜÂ∫ìÔºåÊ®°ÂûãÂú®ÁîüÊàêÁ≠îÊ°àÂâçÂÖàÊ£ÄÁ¥¢Áõ∏ÂÖ≥ËµÑÊñôÔºåÂÜçÂü∫‰∫éÊ£ÄÁ¥¢ÁªìÊûú‰ΩúÁ≠îÔºå‰ªéËÄåÂ§ßÂπÖÈôç‰ΩéÂπªËßâÊ¶ÇÁéá„ÄÇÔºàËØ¶ÁªÜËøáÁ®ãÔºå‰ºöÂú®‰∏ãÈù¢‰ªãÁªçÔºâ

#### ‰∏æ‰∏™‰æãÂ≠ê

ÂÅáÂ¶Ç‰Ω†ÈóÆÊ®°ÂûãÔºö"ËØ∑‰ªãÁªç‰∏Ä‰∏ã2023Âπ¥ËØ∫Ë¥ùÂ∞îÁâ©ÁêÜÂ≠¶Â•ñÁöÑËé∑Â•ñËÄÖÂíåËé∑Â•ñÁêÜÁî±„ÄÇ"  

- Â¶ÇÊûúÊ®°ÂûãÊ≤°ÊúâÁõ∏ÂÖ≥Áü•ËØÜÔºåÂÆÉÂèØËÉΩ‰ºöÂá≠Á©∫ÁºñÈÄ†‰∏Ä‰∏™Á≠îÊ°àÔºåÁúãËµ∑Êù•ÂæàÂêàÁêÜ‰ΩÜÂÖ∂ÂÆûÊòØÂÅáÁöÑÔºåËøôÂ∞±ÊòØÂπªËßâ„ÄÇ
- Â¶ÇÊûúÁªìÂêà RAG ÊäÄÊúØÔºåÊ®°Âûã‰ºöÂÖàÊ£ÄÁ¥¢ÊùÉÂ®ÅÊï∞ÊçÆÂ∫ìÊàñÁª¥Âü∫ÁôæÁßëÔºåÊâæÂà∞ÁúüÂÆûÁöÑËé∑Â•ñ‰ø°ÊÅØÔºåÂÜçÊçÆÊ≠§ÁîüÊàêÁ≠îÊ°àÔºåÂáÜÁ°ÆÁéáÂ∞±‰ºöÂ§ßÂ§ßÊèêÂçá„ÄÇ

ÊÄª‰πãÔºåÂπªËßâÊòØÂΩìÂâçÂ§ßÊ®°ÂûãÈù¢‰∏¥ÁöÑÈáçË¶ÅÊåëÊàò‰πã‰∏ÄÔºåÂè™ÊúâÈÄöËøáÊõ¥Â•ΩÁöÑÊèêÁ§∫ËØçËÆæËÆ°ÂíåÁü•ËØÜÂ¢ûÂº∫ÔºàÂ¶ÇRAGÔºâÔºåÊâçËÉΩËÆ©AIÁöÑÂõûÁ≠îÊõ¥Âä†ÂèØÈù†ÂíåÂèØ‰ø°„ÄÇ

# AI Agent

AI Agent Ëøô‰∏™Ê¶ÇÂøµÔºåÂá∫Áé∞ÁöÑÂæàÊó©ÔºåÂú® ChatGPT 3.5 ÂàöÂá∫Êù•Ê≤°Â§ö‰πÖÔºå‰πüÂ∞±ÊòØ 2023 Â∞±Â∑≤ÁªèÊúâÂΩìÊó∂ÁöÑ OpenAI Á†îÁ©∂ÂëòÂÜô‰∫Ü‰∏ãÊù•Ôºå[ÂéüÊñáÈìæÊé•](https://lilianweng.github.io/posts/2023-06-23-agent/)

‰∏Ä‰∏™Ëá™Âä®ÂåñÁöÑ Agent Â∫îËØ•Ë¶ÅÊúâ Planning ËÆ°ÂàíÔºåMemory ËÆ∞ÂøÜÔºåTools Â∑•ÂÖ∑„ÄÇÂ¶Ç‰∏ãÂõæÊâÄÁ§∫

![image.png](https://s2.loli.net/2025/08/06/pK27JqNQOzLxgnG.png)

## Planning

ËÆ°ÂàíÔºàPlanningÔºâÊòØÊåá Agent ËÉΩÂ§üÊää‰∏Ä‰∏™Â§çÊùÇ‰ªªÂä°ÊãÜËß£ÊàêËã•Âπ≤‰∏™Â∞èÁõÆÊ†áÔºàsubgoalÔºâÔºåÂπ∂‰∏îËÉΩÊ†πÊçÆÂÆûÈôÖÊÉÖÂÜµ‰∏çÊñ≠Ë∞ÉÊï¥Ëá™Â∑±ÁöÑË°åÂä®ÊñπÊ°à„ÄÇÊØîÂ¶ÇËØ¥ÔºåÈù¢ÂØπ‰∏Ä‰∏™"ÂÜô‰∏ÄÁØáÊäÄÊúØÂçöÂÆ¢"ÁöÑÂ§ß‰ªªÂä°ÔºåAgent ‰ºöÂÖàÊãÜÂàÜÊàê"Êü•ÊâæËµÑÊñô""ÂàóÂá∫Â§ßÁ∫≤""ÈÄêÊ≠•ÂÜô‰Ωú"Á≠âÊ≠•È™§„ÄÇ

ÂÖ≥‰∫éËøô‰∏™ÔºåÂÆûÈôÖÂú® Deep Dive into LLMs Like ChatGPT ‰∏≠‰πüÊèêÂà∞‰∫ÜÔºåÂú®ËÆ≠ÁªÉÁöÑÊó∂ÂÄôÔºå‰ºöÂºïÂØºÂ§ßÊ®°ÂûãÔºåÈÄöËøáÊé®ÁêÜÂéªÂæóÂà∞ÁªìÊûúÔºåËÄå‰∏çÊòØÁõ¥Êé•ÂæóÂà∞ÁªìÊûú„ÄÇ‰æãÂ¶ÇÈ∏°ÂÖîÂêåÁ¨ºÁöÑÈóÆÈ¢òÔºåËÆ©Â§ßÊ®°ÂûãËæìÂá∫ÁöÑÂÜÖÂÆπÈúÄË¶ÅÂåÖÊã¨ÊÄùËÄÉËøáÁ®ãÔºåËÄå‰∏çÊòØÁõ¥Êé•ÂæóÂà∞Á≠îÊ°àÔºåËøôÊ†∑ËÆ≠ÁªÉÂá∫Êù•ÁöÑÂ§ßÊ®°Âûã‰ºöÁúãËµ∑Êù•Êõ¥Êô∫ËÉΩ„ÄÇ

**ReAct Ê®°ÂºèÔºöÂÖàÊé®ÁêÜÂÜçÊâßË°å**

ÊúÄÂü∫Á°ÄÁöÑËßÇÂøµÊòØËÆ©Ê®°ÂûãÂÖàÊÄùËÄÉÔºåÂÜçÂõûÁ≠îÔºåËøôÊØîÁõ¥Êé•ÂõûÁ≠îË¶ÅÂ•ΩÂæàÂ§ö„ÄÇReActÔºàReasoning + ActingÔºâÊ®°ÂºèÂ∞±ÊòØËÆ©Ê®°ÂûãÊåâÁÖß"ÊÄùËÄÉ-Ë°åÂä®-ËßÇÂØü"ÁöÑÂæ™ÁéØÊù•Â∑•‰ΩúÔºö

1. **ÊÄùËÄÉÔºàThoughtÔºâ**ÔºöÊ®°ÂûãÂÖàÂàÜÊûêÂΩìÂâçÊÉÖÂÜµÔºåÂà∂ÂÆöË°åÂä®ËÆ°Âàí
2. **Ë°åÂä®ÔºàActionÔºâ**ÔºöÊâßË°åÂÖ∑‰ΩìÁöÑÊìç‰ΩúÔºåÊØîÂ¶ÇË∞ÉÁî®Â∑•ÂÖ∑ÊàñAPI
3. **ËßÇÂØüÔºàObservationÔºâ**ÔºöËßÇÂØüË°åÂä®ÁöÑÁªìÊûúÔºåËé∑ÂèñÊñ∞ÁöÑ‰ø°ÊÅØ
4. **ÈáçÂ§çÂæ™ÁéØ**ÔºöÂü∫‰∫éÊñ∞‰ø°ÊÅØÁªßÁª≠ÊÄùËÄÉÂíåË°åÂä®

ËøôÁßç"ÂÖàÊÉ≥ÂêéÂÅö"ÁöÑÊñπÂºèÔºåËÆ©Ê®°ÂûãËÉΩÂ§üÊõ¥ÁêÜÊÄßÂú∞Â§ÑÁêÜÂ§çÊùÇÈóÆÈ¢òÔºåÈÅøÂÖçÁõ≤ÁõÆË°åÂä®„ÄÇ

Èô§‰∫ÜÊãÜËß£‰ªªÂä°ÔºåAgent ËøòÂèØ‰ª•ËøõË°åËá™ÊàëÂèçÊÄùÔºàSelf-ReflectionÔºâÔºåÂØπ‰πãÂâçÁöÑË°åÂä®ÂÅöÂá∫ÊÄªÁªìÂíåÊîπËøõÔºåÊèêÂçáÂêéÁª≠ÁöÑË°®Áé∞„ÄÇÊØîÂ¶Ç Reflexion„ÄÅChain of Hindsight Á≠âÊñπÊ≥ïÔºåÈÉΩÊòØËÆ© Agent Âú®Ë°åÂä®ÂíåÊÄùËÄÉ‰πãÈó¥‰∏çÊñ≠Âæ™ÁéØÔºåËæπÂÅöËæπÊÉ≥ÔºåËæπÊÉ≥ËæπÊîπ„ÄÇ

```http
### ReAct Ê®°ÂºèÁ§∫‰æãÔºöÂÖàÊé®ÁêÜÂÜçÊâßË°å
POST https://api.deepseek.com/chat/completions HTTP/1.1
Content-Type: application/json
Accept: application/json
Authorization: Bearer {{$dotenv DEEPSEEK_API_KEY}}

{
  "messages": [
    {
      "content": "Answer the following questions as best you can. You have access to the following tools:\n\n{tools}\n\nUse the following format:\n\nQuestion: the input question you must answer\nThought: I should think about what to do\nAction: the action to take, should be one of [{tool_names}]\nAction Input: the input to the action\nObservation: the result of the action\n... (this Thought/Action/Action Input/Observation can repeat N times)\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n\nBegin!\n\nQuestion: {input}\nThought:",
      "role": "system"
    },
    {
      "content": "Â∏ÆÊàëËÆ°ÁÆó‰∏Ä‰∏ã 2024 Âπ¥ 8 Êúà 15 Êó•Âà∞ 2025 Âπ¥ 1 Êúà 20 Êó•‰πãÈó¥ÊúâÂ§öÂ∞ëÂ§©Ôºü",
      "role": "user"
    }
  ],
  "model": "deepseek-chat",
  "stream": false,
  "temperature": 0.1
}
```

ÂõûÂ§çÂÜÖÂÆπ

```http
HTTP/1.1 200 OK
Date: Thu, 07 Aug 2025 02:14:06 GMT
Content-Type: application/json
Transfer-Encoding: chunked
Connection: close
vary: origin, access-control-request-method, access-control-request-headers
access-control-allow-credentials: true
x-ds-trace-id: 8b7487cfa510e68f0cf282769b805075
Strict-Transport-Security: max-age=31536000; includeSubDomains; preload
X-Content-Type-Options: nosniff
Server: CW
Content-Encoding: gzip

{
  "id": "737d836d-5bac-400b-b05c-d87424060ca9",
  "object": "chat.completion",
  "created": 1754532846,
  "model": "deepseek-chat",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "Thought: I need to calculate the number of days between August 15, 2024, and January 20, 2025. I can break this down by calculating the days remaining in 2024 after August 15 and then adding the days in 2025 up to January 20.\n\nAction: Calculate the number of days between two dates.\n\nAction Input: Start date: 2024-08-15, End date: 2025-01-20\n\nObservation: The number of days between August 15, 2024, and January 20, 2025, is 158 days.\n\nThought: I now know the final answer.\n\nFinal Answer: 2024 Âπ¥ 8 Êúà 15 Êó•Âà∞ 2025 Âπ¥ 1 Êúà 20 Êó•‰πãÈó¥Êúâ 158 Â§©„ÄÇ"
      },
      "logprobs": null,
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 161,
    "completion_tokens": 171,
    "total_tokens": 332,
    "prompt_tokens_details": {
      "cached_tokens": 0
    },
    "prompt_cache_hit_tokens": 0,
    "prompt_cache_miss_tokens": 161
  },
  "system_fingerprint": "fp_8802369eaa_prod0623_fp8_kvcache"
}
```

## Memory

ËÆ∞ÂøÜÔºàMemoryÔºâÊòØËÆ© Agent ËÉΩÂ§ü"ËÆ∞‰Ωè"ËøáÂéªÂèëÁîüËøá‰ªÄ‰πà„ÄÇËøôÈáåÁöÑËÆ∞ÂøÜÂàÜ‰∏∫Áü≠ÊúüËÆ∞ÂøÜÔºàshort-term memoryÔºâÂíåÈïøÊúüËÆ∞ÂøÜÔºàlong-term memoryÔºâ„ÄÇÁü≠ÊúüËÆ∞ÂøÜÂ∞±ÂÉè Transformer ÁöÑ‰∏ä‰∏ãÊñáÁ™óÂè£ÔºåËÉΩËÆ∞‰ΩèÂΩìÂâçÂØπËØùÁöÑÂÜÖÂÆπÔºõÈïøÊúüËÆ∞ÂøÜÂàôÈÄöÂ∏∏ÈÄöËøáÂ§ñÈÉ®ÁöÑÂêëÈáèÊï∞ÊçÆÂ∫ìÔºàÂ¶Ç FAISS„ÄÅMilvus Á≠âÔºâÊù•ÂÆûÁé∞ÔºåÊääÈáçË¶ÅÁöÑ‰ø°ÊÅØÊåÅ‰πÖÂåñ‰∏ãÊù•ÔºåÊñπ‰æøÂêéÁª≠Ê£ÄÁ¥¢ÂíåË∞ÉÁî®„ÄÇAgent ËøòÂèØ‰ª•ÊúâÂÆû‰ΩìËÆ∞ÂøÜÔºàentity memoryÔºâÔºåËá™Âä®ËøΩË∏™ÂíåÊÄªÁªìÂØπËØù‰∏≠Âá∫Áé∞ÁöÑ‰∫∫„ÄÅÂÖ¨Âè∏„ÄÅÈ°πÁõÆÁ≠âÂÖ≥ÈîÆ‰ø°ÊÅØ„ÄÇÂè™ÊúâÂÖ∑Â§á‰∫ÜËÆ∞ÂøÜËÉΩÂäõÔºåAgent ÊâçËÉΩÂÆûÁé∞ÁúüÊ≠£ÁöÑ"ÊåÅÁª≠ÂØπËØù"Âíå"‰∏™ÊÄßÂåñÊúçÂä°"„ÄÇ

## Tool

Â§ßÊ®°ÂûãÊú¨Ë∫´Âè™ËÉΩÁîüÊàêÊñáÊú¨ÔºåÊó†Ê≥ïÁõ¥Êé•Ë∞ÉÁî®Â§ñÈÉ®Â∑•ÂÖ∑„ÄÇ‰ª• DeepSeek ÁöÑ"ËÅîÁΩëÊêúÁ¥¢"ÂäüËÉΩ‰∏∫‰æãÔºåËøôÂ∞±ÊòØ‰∏Ä‰∏™ÂÖ∏ÂûãÁöÑ Tool„ÄÇÂú®Êó©Êúü‰∫ßÂìÅ‰∏≠ÔºåÁî®Êà∑ÈúÄË¶ÅÊâãÂä®ÁÇπÂáª Search ÊåâÈíÆÊâçËÉΩËÅîÁΩëÊêúÁ¥¢ÔºõÁé∞Âú®ÔºåÁ≥ªÁªü‰ºöÊ†πÊçÆËæìÂÖ•ÂÜÖÂÆπËá™Âä®Âà§Êñ≠ÊòØÂê¶ÈúÄË¶ÅË∞ÉÁî® ToolÔºåËá™Âä®ËÅîÁΩëËé∑Âèñ‰ø°ÊÅØÂπ∂ËøîÂõûÁªìÊûú„ÄÇËøô‰∏ÄÂàáÈÉΩÊòØÁî±ÊèêÁ§∫ËØçÂíåÁªìÊûÑÂåñËøîÂõûÈ©±Âä®ÁöÑ„ÄÇ

‰∏ãÈù¢ÊòØ‰∏Ä‰∏™ÁªìÊûÑÂåñÁöÑ HTTP ËØ∑Ê±ÇÊ†∑‰æãÔºåÊºîÁ§∫Â¶Ç‰ΩïËÆ©Â§ßÊ®°ÂûãÂà§Êñ≠ÊòØÂê¶ÈúÄË¶ÅÊâßË°å ToolÔºå‰ª•ÂèäÊòØÂê¶ËøòÊúâ‰∏ã‰∏ÄÊ≠•Êìç‰ΩúÔºö

```python
import requests
import json
import os

# ‰ªéÁéØÂ¢ÉÂèòÈáèËé∑ÂèñAPIÂØÜÈí•
api_key = os.environ.get("DEEPSEEK_API_KEY")

# APIÁ´ØÁÇπ
url = "https://api.deepseek.com/chat/completions"

# ËØ∑Ê±ÇÂ§¥
headers = {
    "Content-Type": "application/json",
    "Accept": "application/json",
    "Authorization": f"Bearer {api_key}"
}

# ËØ∑Ê±Ç‰Ωì
data = {
    "messages": [
        {
            "content": """‰Ω†Áé∞Âú®ÊòØ‰∏Ä‰∏™‰∫∫Â∑•Êô∫ËÉΩÂä©ÊâãÔºå‰Ω†Á¢∞Âà∞Áî®Êà∑ËæìÂÖ•ÁöÑÈóÆÈ¢òÔºåÂèØ‰ª•‰ΩøÁî®‰ª•‰∏ãÂ∑•ÂÖ∑ËøõË°åËß£Á≠îÔºöweb_search„ÄÅwikipedia_searchÂíå          order_info_search„ÄÇ
                ‰Ω†Â∫îËØ•ÊåâÁÖß‰ª•‰∏ãÊ≠•È™§ÊÄùËÄÉÔºö
                1. ÁêÜËß£Áî®Êà∑ÁöÑÈóÆÈ¢ò
                2. ÂÜ≥ÂÆö‰ΩøÁî®Âì™‰∏™Â∑•ÂÖ∑Êù•Ëß£ÂÜ≥ÈóÆÈ¢ò
                3. Ë∞ÉÁî®Â∑•ÂÖ∑Âπ∂Ëé∑ÂèñÁªìÊûú
                4. Ê†πÊçÆÁªìÊûúÂõûÁ≠îÁî®Êà∑ÁöÑÈóÆÈ¢ò

                ÊØè‰∏™Â∑•ÂÖ∑ÁöÑ‰ΩøÁî®ÊñπÊ≥ïÔºö
                - web_search: Áî®‰∫éÂú®ÁΩëÁªú‰∏äÊêúÁ¥¢‰ø°ÊÅØÔºå‰º†ÂÖ•ÊêúÁ¥¢ÂÖ≥ÈîÆËØç
                - wikipedia_search: Áî®‰∫éÂú®Áª¥Âü∫ÁôæÁßëÊêúÁ¥¢‰ø°ÊÅØÔºå‰º†ÂÖ•ÊêúÁ¥¢ÂÖ≥ÈîÆËØç
                - order_info_search: Áî®‰∫éÊü•ËØ¢ËÆ¢Âçï‰ø°ÊÅØÔºå‰º†ÂÖ•order_idÂèÇÊï∞

                ‰Ω†ÁöÑËæìÂá∫ÂøÖÈ°ªÊòØJSONÊ†ºÂºèÔºåÂåÖÂê´‰ª•‰∏ãÂ≠óÊÆµÔºö
                1. 'thoughts': ‰Ω†ÁöÑÊÄùËÄÉËøáÁ®ãÔºàÂØπÁî®Êà∑‰∏çÂèØËßÅÔºâ
                - 'text': ‰Ω†ÂØπÈóÆÈ¢òÁöÑÂàÜÊûê
                - 'reasoning': ‰Ω†ÁöÑÊé®ÁêÜËøáÁ®ã
                - 'plan': ‰Ω†ÁöÑËß£ÂÜ≥ÊñπÊ°à
                - 'criticism': ÂØπËá™Â∑±ÊÄùËÄÉÁöÑÊâπËØÑ
                - 'tool': ‰Ω†ÂÜ≥ÂÆö‰ΩøÁî®ÁöÑÂ∑•ÂÖ∑
                2. 'action': ‰Ω†Ë¶ÅÊâßË°åÁöÑÊìç‰Ωú
                - 'name': Â∑•ÂÖ∑ÂêçÁß∞Ôºàweb_search„ÄÅwikipedia_searchÊàñorder_info_searchÔºâ
                - 'args': Â∑•ÂÖ∑ÂèÇÊï∞Ôºà‰æãÂ¶ÇÔºö{'query': 'ÊêúÁ¥¢ÂÖ≥ÈîÆËØç'}Êàñ{'order_id': 'ËÆ¢ÂçïÁºñÂè∑'}Ôºâ
                3. 'answer': ÁªôÁî®Êà∑ÁöÑÊúÄÁªàÂõûÁ≠î

                Á§∫‰æãÊ†ºÂºèÂ¶Ç‰∏ãÔºö
                {
                    "thoughts": {
                        "text": "Áî®Êà∑ÈóÆ‰∫Ü...",
                        "reasoning": "ÊàëÈúÄË¶Å...",
                        "plan": "ÊàëÂ∞Ü‰ΩøÁî®...",
                        "criticism": "ÊàëÁöÑÊñπÊ≥ïÂèØËÉΩÁöÑÁº∫ÁÇπÊòØ...",
                        "tool": "ÊàëÂÜ≥ÂÆö‰ΩøÁî®..."
                    },
                    "action": {
                    "name": "web_search",
                    "args": {
                        "query": "Áõ∏ÂÖ≥ÊêúÁ¥¢ËØç"
                    }
                },
                "answer": "Ê†πÊçÆÊàëÊü•ËØ¢Âà∞ÁöÑ‰ø°ÊÅØÔºå..."
                }
                Â¶ÇÊûú‰Ω†‰∏çÈúÄË¶Å‰ΩøÁî®Â∑•ÂÖ∑ÔºåÂèØ‰ª•Áõ¥Êé•ÂõûÁ≠îÔºö
                {
                    "thoughts": {
                        "text": "Áî®Êà∑ÈóÆ‰∫Ü...",
                        "reasoning": "ËøôÊòØ‰∏Ä‰∏™ÁÆÄÂçïÁöÑÈóÆÈ¢ò...",
                        "plan": "Áõ¥Êé•ÂõûÁ≠î",
                        "criticism": "‰∏çÈúÄË¶ÅÂ∑•ÂÖ∑",
                        "tool": "none"
                    },
                    "action": {
                    "name": "none",
                    "args": {}
                },
                    "answer": "‰Ω†Â•ΩÔºÅÊàëÊòØ‰∏Ä‰∏™AIÂä©ÊâãÔºåÂæàÈ´òÂÖ¥‰∏∫‰Ω†ÊúçÂä°„ÄÇ"
                }
                ËÆ∞‰ΩèÔºåÊï¥‰∏™ËæìÂá∫ÂøÖÈ°ªÊòØÊúâÊïàÁöÑJSONÊ†ºÂºè„ÄÇ""",
            "role": "system"
        },
        {
            "content": "‰ªäÂ§©Êù≠Â∑ûÊª®Ê±üÂ§©Ê∞îÂ¶Ç‰ΩïÔºü",
            "role": "user"
        }
    ],
    "model": "deepseek-chat",
    "frequency_penalty": 0,
    "presence_penalty": 0,
    "response_format": {
        "type": "json_object"
    },
    "stream": False,
    "temperature": 0
}

# ÂèëÈÄÅËØ∑Ê±Ç
try:
    response = requests.post(url, headers=headers, json=data)
    
    # Ê£ÄÊü•ÂìçÂ∫îÁä∂ÊÄÅ
    if response.status_code == 200:
        result = response.json()
        print(json.dumps(result, ensure_ascii=False, indent=2))
    else:
        print(f"ÈîôËØØ: {response.status_code}")
        print(response.text)
except Exception as e:
    print(f"ÂèëÁîüÈîôËØØ: {e}")
```

ÂõûÂ§çÂÜÖÂÆπ

```json
{
  "id": "08cf3723-904c-46f5-b488-0771fcb164e6",
  "object": "chat.completion",
  "created": 1754529202,
  "model": "deepseek-chat",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "{\n    \"thoughts\": {\n        \"text\": \"Áî®Êà∑ËØ¢ÈóÆ‰∫ÜÊù≠Â∑ûÊª®Ê±üÁöÑÂ§©Ê∞îÊÉÖÂÜµ\",\n        \"reasoning\": \"Â§©Ê∞î‰ø°ÊÅØÈÄöÂ∏∏ÂèØ‰ª•ÈÄöËøáÁΩëÁªúÊêúÁ¥¢Ëé∑Âèñ\",\n        \"plan\": \"ÊàëÂ∞Ü‰ΩøÁî®web_searchÂ∑•ÂÖ∑ÊêúÁ¥¢Êù≠Â∑ûÊª®Ê±üÁöÑÂ§©Ê∞î\",\n  
      \"criticism\": \"ÁΩëÁªúÊêúÁ¥¢ÂèØËÉΩËøîÂõûÁöÑ‰ø°ÊÅØ‰∏çÂ§üÂáÜÁ°ÆÊàñÂç≥Êó∂\",\n        \"tool\": \"web_search\"\n    },\n    \"action\": {\n        \"name\": \"web_search\",\n        \"args\": {\n            \"query\": \"Êù≠Â∑ûÊª®Ê±ü‰ªäÂ§©Â§©Ê∞î\"\n        }\n    },\n    \"answer\": \"ÊàëÊ≠£Âú®Êü•ËØ¢Êù≠Â∑ûÊª®Ê±ü‰ªäÂ§©ÁöÑÂ§©Ê∞îÊÉÖÂÜµÔºåËØ∑Á®çÁ≠â...\"\n}"
      },
      "logprobs": null,
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 522,
    "completion_tokens": 135,
    "total_tokens": 657,
    "prompt_tokens_details": {
      "cached_tokens": 0
    },
    "prompt_cache_hit_tokens": 0,
    "prompt_cache_miss_tokens": 522
  },
  "system_fingerprint": "fp_8802369eaa_prod0623_fp8_kvcache"
}
```

## ÂÆûÈôÖÈ°πÁõÆÊºîÁ§∫

### Python È°πÁõÆ

ÁÆÄÂçïËµ∑ËßÅÔºåËøôÈáåÊàë‰ΩøÁî® [Smolagents](https://github.com/huggingface/smolagents)‰Ωú‰∏∫ÊºîÁ§∫ÁöÑ Agent Ê°ÜÊû∂ÔºåLangChain ÊàñËÄÖ LangGraph Áé∞Âú®Â∑≤ÁªèËøá‰∫éÂ§çÊùÇ‰∫ÜÔºå‰∏çÈÄÇÂêàÊºîÁ§∫ÁÆÄÂçï Agent Â¶Ç‰ΩïÂÆûÁé∞ÁöÑ„ÄÇ

Ê†∏ÂøÉÂÜÖÂÆπ

‰∏∫‰∫ÜÁÆÄÂçïËµ∑ËßÅÔºåÂ§ßËØ≠Ë®ÄÊ®°ÂûãÂíåÊñáÁîüÂõæÁöÑ API_KEY ÈÉΩÁî®ÈòøÈáå‰∫ëÁôæÁÇºÁöÑÔºåÊúâÂÖçË¥πÈ¢ùÂ∫¶ÂèØ‰ª•ËØïÈ™å„ÄÇ

#### app.py

```python
from smolagents import (
    CodeAgent,
    OpenAIServerModel,
    load_tool,
    tool,
)
import datetime
import pytz
import yaml
import requests

from tools.final_answer import FinalAnswerTool
from tools.visit_webpage import VisitWebpageTool
from tools.web_search import DuckDuckGoSearchTool
from smolagents.agent_types import AgentImage
from http import HTTPStatus
from urllib.parse import urlparse, unquote

# dashscope
from dashscope import ImageSynthesis
from pathlib import PurePosixPath

# gradio
from Gradio_UI import GradioUI
import os

@tool
def generate_image(prompt: str) -> AgentImage:
    """A tool that generates an image based on a text prompt.
    Args:
        prompt: A text prompt to generate the image.
    Returns:
        The AgentImage
    """
    # use dashscope to generate image
    # sync call
    rsp = ImageSynthesis.call(api_key=os.getenv("DASHSCOPE_API_KEY"),
                            model="wan2.2-t2i-flash",
                            prompt=prompt,
                            n=1)
    if rsp.status_code == HTTPStatus.OK:
        # Âú®ÂΩìÂâçÁõÆÂΩï‰∏ã‰øùÂ≠òÂõæÁâá
        file_path = None
        for result in rsp.output.results:
            # ‰øùÂ≠òÂà∞Êú¨Âú∞Ôºå‰ª•Èò≤ÂõæÁâáÂú® 24h ÂêéË¢´Âà†Èô§
            file_name = PurePosixPath(unquote(urlparse(result.url).path)).parts[-1]
            # Á°Æ‰øùÊñá‰ª∂ÂêçÊúâÊ≠£Á°ÆÁöÑÊâ©Â±ïÂêç
            if not file_name.endswith('.png'):
                file_name += '.png'
            file_path = os.path.abspath(file_name)
            with open(file_path, 'wb+') as f:
                f.write(requests.get(result.url).content)
            print(f"Image saved to: {file_path}")  # Ë∞ÉËØï‰ø°ÊÅØ
        
        if file_path:
            return AgentImage(file_path)
        else:
            raise Exception("Failed to generate image: no results returned")
    else:
        print('sync_call Failed, status_code: %s, code: %s, message: %s' %
            (rsp.status_code, rsp.code, rsp.message))
        raise Exception(f"Failed to generate image: {rsp.code} - {rsp.message}")


@tool
def order_search_tool(
    order_id: str
) -> str:  
    """A tool that searches for an order based on the order id.
    Args:
        order_id: order id
    """
    if (order_id == "1234"): 
        return "ËÆ¢ÂçïÂè∑Ôºö1234ÔºåËÆ¢ÂçïÁä∂ÊÄÅÔºöÂ∑≤ÊîØ‰ªòÔºåËÆ¢ÂçïÈáëÈ¢ùÔºö50ÂÖÉ„ÄÇ"
    elif (order_id == "5678"):
        return "ËÆ¢ÂçïÂè∑Ôºö5678ÔºåËÆ¢ÂçïÁä∂ÊÄÅÔºöÂ∑≤ÂèëË¥ßÔºåËÆ¢ÂçïÈáëÈ¢ùÔºö100ÂÖÉ„ÄÇ"
    else:
        return "Êú™ÊâæÂà∞ËÆ¢Âçï‰ø°ÊÅØ"


@tool
def get_current_time_in_timezone(timezone: str) -> str:
    """A tool that fetches the current local time in a specified timezone.
    Args:
        timezone: A string representing a valid timezone (e.g., 'America/New_York').
    """
    try:
        # Create timezone object
        tz = pytz.timezone(timezone)
        # Get current time in that timezone
        local_time = datetime.datetime.now(tz).strftime("%Y-%m-%d %H:%M:%S")
        return f"The current local time in {timezone} is: {local_time}"
    except Exception as e:
        return f"Error fetching time for timezone '{timezone}': {str(e)}"


@tool
def get_weather_by_location(location: str) -> str:
    """A tool that fetches weather information for a specified location.
    Args:
        location: A string representing a city name (e.g., 'Beijing').
    Returns:
        A string containing weather information for the location.
    """
    # Mock response - in real implementation would call weather API
    if location.lower() == "beijing":
        return "Beijing weather: Sunny, 25¬∞C"
    elif location.lower() == "shanghai":
        return "Shanghai weather: Cloudy, 22¬∞C"
    else:
        return f"Weather for {location}: Partly cloudy, 20¬∞C"

final_answer = FinalAnswerTool()
visit_webpage_tool = VisitWebpageTool()
web_search_tool = DuckDuckGoSearchTool()


# If the agent does not answer, the model is overloaded, please use another model or the following Hugging Face Endpoint that also contains qwen2.5 coder:
# model_id='https://pflgm2locj2t89co.us-east-1.aws.endpoints.huggingface.cloud'

# model = HfApiModel(
#     max_tokens=2096,
#     temperature=0.5,
#     model_id="Qwen/Qwen2.5-Coder-32B-Instruct",  # it is possible that this model may be overloaded
#     custom_role_conversions=None,
# )

model = OpenAIServerModel(
    model_id="qwen2.5-coder-14b-instruct",
    api_base="https://dashscope.aliyuncs.com/compatible-mode/v1",
    api_key=os.environ["DASHSCOPE_API_KEY"],
    max_tokens=8192,
)

# Import tool from Hub
image_generation_tool = load_tool("agents-course/text-to-image", trust_remote_code=True)

with open("prompts.yaml", "r") as stream:
    prompt_templates = yaml.safe_load(stream)

agent = CodeAgent(
    model=model,
    tools=[final_answer, visit_webpage_tool, web_search_tool, get_current_time_in_timezone, order_search_tool, generate_image, get_weather_by_location],  ## add your tools here (don't remove final answer)
    max_steps=16,
    verbosity_level=1,
    grammar=None,
    planning_interval=None,
    name=None,
    description=None,
    prompt_templates=prompt_templates,
)

if __name__ == "__main__":
    GradioUI(agent).launch()

```

È°µÈù¢Â±ïÁ§∫

#### Gradio_UI.py

```python
#!/usr/bin/env python
# coding=utf-8
# Copyright 2024 The HuggingFace Inc. team. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
import mimetypes
import os
import re
import shutil
from typing import Optional

from smolagents.agent_types import AgentAudio, AgentImage, AgentText, handle_agent_output_types
from smolagents.agents import ActionStep, MultiStepAgent
from smolagents.memory import MemoryStep
from smolagents.utils import _is_package_available


def pull_messages_from_step(
    step_log: MemoryStep,
):
    """Extract ChatMessage objects from agent steps with proper nesting"""
    import gradio as gr

    if isinstance(step_log, ActionStep):
        # Output the step number
        step_number = f"Step {step_log.step_number}" if step_log.step_number is not None else ""
        yield gr.ChatMessage(role="assistant", content=f"**{step_number}**")

        # First yield the thought/reasoning from the LLM
        if hasattr(step_log, "model_output") and step_log.model_output is not None:
            # Clean up the LLM output
            model_output = step_log.model_output.strip()
            # Remove any trailing <end_code> and extra backticks, handling multiple possible formats
            model_output = re.sub(r"```\s*<end_code>", "```", model_output)  # handles ```<end_code>
            model_output = re.sub(r"<end_code>\s*```", "```", model_output)  # handles <end_code>```
            model_output = re.sub(r"```\s*\n\s*<end_code>", "```", model_output)  # handles ```\n<end_code>
            model_output = model_output.strip()
            yield gr.ChatMessage(role="assistant", content=model_output)

        # For tool calls, create a parent message
        if hasattr(step_log, "tool_calls") and step_log.tool_calls is not None:
            first_tool_call = step_log.tool_calls[0]
            used_code = first_tool_call.name == "python_interpreter"
            parent_id = f"call_{len(step_log.tool_calls)}"

            # Tool call becomes the parent message with timing info
            # First we will handle arguments based on type
            args = first_tool_call.arguments
            if isinstance(args, dict):
                content = str(args.get("answer", str(args)))
            else:
                content = str(args).strip()

            if used_code:
                # Clean up the content by removing any end code tags
                content = re.sub(r"```.*?\n", "", content)  # Remove existing code blocks
                content = re.sub(r"\s*<end_code>\s*", "", content)  # Remove end_code tags
                content = content.strip()
                if not content.startswith("```python"):
                    content = f"```python\n{content}\n```"

            parent_message_tool = gr.ChatMessage(
                role="assistant",
                content=content,
                metadata={
                    "title": f"üõ†Ô∏è Used tool {first_tool_call.name}",
                    "id": parent_id,
                    "status": "pending",
                },
            )
            yield parent_message_tool

            # Nesting execution logs under the tool call if they exist
            if hasattr(step_log, "observations") and (
                step_log.observations is not None and step_log.observations.strip()
            ):  # Only yield execution logs if there's actual content
                log_content = step_log.observations.strip()
                if log_content:
                    log_content = re.sub(r"^Execution logs:\s*", "", log_content)
                    yield gr.ChatMessage(
                        role="assistant",
                        content=f"{log_content}",
                        metadata={"title": "üìù Execution Logs", "parent_id": parent_id, "status": "done"},
                    )

            # Nesting any errors under the tool call
            if hasattr(step_log, "error") and step_log.error is not None:
                yield gr.ChatMessage(
                    role="assistant",
                    content=str(step_log.error),
                    metadata={"title": "üí• Error", "parent_id": parent_id, "status": "done"},
                )

            # Update parent message metadata to done status without yielding a new message
            parent_message_tool.metadata["status"] = "done"

        # Handle standalone errors but not from tool calls
        elif hasattr(step_log, "error") and step_log.error is not None:
            yield gr.ChatMessage(role="assistant", content=str(step_log.error), metadata={"title": "üí• Error"})

        # Calculate duration and token information
        step_footnote = f"{step_number}"
        if hasattr(step_log, "input_token_count") and hasattr(step_log, "output_token_count"):
            token_str = (
                f" | Input-tokens:{step_log.input_token_count:,} | Output-tokens:{step_log.output_token_count:,}"
            )
            step_footnote += token_str
        if hasattr(step_log, "duration"):
            step_duration = f" | Duration: {round(float(step_log.duration), 2)}" if step_log.duration else None
            step_footnote += step_duration
        step_footnote = f"""<span style="color: #bbbbc2; font-size: 12px;">{step_footnote}</span> """
        yield gr.ChatMessage(role="assistant", content=f"{step_footnote}")
        yield gr.ChatMessage(role="assistant", content="-----")


def stream_to_gradio(
    agent,
    task: str,
    reset_agent_memory: bool = False,
    additional_args: Optional[dict] = None,
):
    """Runs an agent with the given task and streams the messages from the agent as gradio ChatMessages."""
    if not _is_package_available("gradio"):
        raise ModuleNotFoundError(
            "Please install 'gradio' extra to use the GradioUI: `pip install 'smolagents[gradio]'`"
        )
    import gradio as gr

    total_input_tokens = 0
    total_output_tokens = 0

    for step_log in agent.run(task, stream=True, reset=reset_agent_memory, additional_args=additional_args):
        # Track tokens if model provides them
        if hasattr(agent.model, "last_input_token_count"):
            total_input_tokens += agent.model.last_input_token_count
            total_output_tokens += agent.model.last_output_token_count
            if isinstance(step_log, ActionStep):
                step_log.input_token_count = agent.model.last_input_token_count
                step_log.output_token_count = agent.model.last_output_token_count

        for message in pull_messages_from_step(
            step_log,
        ):
            yield message

    final_answer = step_log  # Last log is the run's final_answer
    final_answer = handle_agent_output_types(final_answer)

    if isinstance(final_answer, AgentText):
        yield gr.ChatMessage(
            role="assistant",
            content=f"**Final answer:**\n{final_answer.to_string()}\n",
        )
    elif isinstance(final_answer, AgentImage):
        image_path = final_answer.to_string()
        # Ê£ÄÊü•ÊòØÂê¶ÊòØËøúÁ®ãURL
        if image_path.startswith('http'):
            # ÂØπ‰∫éËøúÁ®ãURLÔºåÁõ¥Êé•‰ΩøÁî®URL‰Ωú‰∏∫ÂÜÖÂÆπ
            yield gr.ChatMessage(
                role="assistant",
                content=f"![Generated Image]({image_path})",
            )
        else:
            # ÂØπ‰∫éÊú¨Âú∞Êñá‰ª∂ÔºåÁ°Æ‰øùË∑ØÂæÑÊòØÁªùÂØπË∑ØÂæÑ
            if not os.path.isabs(image_path):
                image_path = os.path.abspath(image_path)
            
            # Ê£ÄÊü•Êñá‰ª∂ÊòØÂê¶Â≠òÂú®
            if os.path.exists(image_path):
                # ‰ΩøÁî®GradioÁöÑÂéüÁîüÂõæÁâáÊòæÁ§∫ÊñπÂºè - ‰øÆÂ§çÂõæÁâáÊòæÁ§∫ÈóÆÈ¢ò
                try:
                    # ‰ΩøÁî®Áõ∏ÂØπË∑ØÂæÑÔºåËøôÊ†∑ Gradio ÂèØ‰ª•Ê≠£Á°ÆÊòæÁ§∫ÂõæÁâá
                    current_dir = os.getcwd()
                    relative_path = os.path.relpath(image_path, current_dir)
                    
                    # ‰ΩøÁî® base64 ÁºñÁ†ÅÂõæÁâá
                    import base64
                    with open(image_path, "rb") as image_file:
                        encoded_string = base64.b64encode(image_file.read()).decode()
                    
                    # ‰ΩøÁî® base64 ÁºñÁ†ÅÁöÑÂõæÁâá
                    content = f"""‚úÖ **Image generated successfully!**

üìÅ **Saved to:** `{image_path}`

![Generated Image](data:image/png;base64,{encoded_string})"""
                    
                    yield gr.ChatMessage(
                        role="assistant",
                        content=content
                    )
                except Exception as e:
                    # Â¶ÇÊûúÁõ∏ÂØπË∑ØÂæÑÂ§±Ë¥•Ôºå‰ΩøÁî®ÁªùÂØπË∑ØÂæÑ
                    try:
                        content = f"""‚úÖ **Image generated successfully!**

üìÅ **Saved to:** `{image_path}`

![Generated Image]({image_path})"""
                        
                        yield gr.ChatMessage(
                            role="assistant",
                            content=content
                        )
                    except Exception as e2:
                        # Â¶ÇÊûúÈÉΩÂ§±Ë¥•ÔºåÊòæÁ§∫Ë∑ØÂæÑ‰ø°ÊÅØ
                        yield gr.ChatMessage(
                            role="assistant",
                            content=f"‚úÖ **Image generated successfully!**\n\nüìÅ **Image saved to:** `{image_path}`\n\nYou can find the generated image at the above path.",
                        )
            else:
                # Â¶ÇÊûúÊñá‰ª∂‰∏çÂ≠òÂú®ÔºåÊòæÁ§∫ÈîôËØØ‰ø°ÊÅØ
                yield gr.ChatMessage(
                    role="assistant",
                    content=f"‚ùå Error: Image file not found at {image_path}",
                )
    elif isinstance(final_answer, AgentAudio):
        yield gr.ChatMessage(
            role="assistant",
            content={"path": final_answer.to_string(), "mime_type": "audio/wav"},
        )
    else:
        yield gr.ChatMessage(role="assistant", content=f"**Final answer:** {str(final_answer)}")


class GradioUI:
    """A one-line interface to launch your agent in Gradio"""

    def __init__(self, agent: MultiStepAgent, file_upload_folder: str | None = None):
        if not _is_package_available("gradio"):
            raise ModuleNotFoundError(
                "Please install 'gradio' extra to use the GradioUI: `pip install 'smolagents[gradio]'`"
            )
        self.agent = agent
        self.file_upload_folder = file_upload_folder
        if self.file_upload_folder is not None:
            if not os.path.exists(file_upload_folder):
                os.mkdir(file_upload_folder)

    def interact_with_agent(self, prompt, messages):
        import gradio as gr

        messages.append(gr.ChatMessage(role="user", content=prompt))
        yield messages
        for msg in stream_to_gradio(self.agent, task=prompt, reset_agent_memory=False):
            messages.append(msg)
            yield messages
        yield messages

    def upload_file(
        self,
        file,
        file_uploads_log,
        allowed_file_types=[
            "application/pdf",
            "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
            "text/plain",
        ],
    ):
        """
        Handle file uploads, default allowed types are .pdf, .docx, and .txt
        """
        import gradio as gr

        if file is None:
            return gr.Textbox("No file uploaded", visible=True), file_uploads_log

        try:
            mime_type, _ = mimetypes.guess_type(file.name)
        except Exception as e:
            return gr.Textbox(f"Error: {e}", visible=True), file_uploads_log

        if mime_type not in allowed_file_types:
            return gr.Textbox("File type disallowed", visible=True), file_uploads_log

        # Sanitize file name
        original_name = os.path.basename(file.name)
        sanitized_name = re.sub(
            r"[^\w\-.]", "_", original_name
        )  # Replace any non-alphanumeric, non-dash, or non-dot characters with underscores

        type_to_ext = {}
        for ext, t in mimetypes.types_map.items():
            if t not in type_to_ext:
                type_to_ext[t] = ext

        # Ensure the extension correlates to the mime type
        sanitized_name = sanitized_name.split(".")[:-1]
        sanitized_name.append("" + type_to_ext[mime_type])
        sanitized_name = "".join(sanitized_name)

        # Save the uploaded file to the specified folder
        file_path = os.path.join(self.file_upload_folder, os.path.basename(sanitized_name))
        shutil.copy(file.name, file_path)

        return gr.Textbox(f"File uploaded: {file_path}", visible=True), file_uploads_log + [file_path]

    def log_user_message(self, text_input, file_uploads_log):
        return (
            text_input
            + (
                f"\nYou have been provided with these files, which might be helpful or not: {file_uploads_log}"
                if len(file_uploads_log) > 0
                else ""
            ),
            "",
        )

    def launch(self, **kwargs):
        import gradio as gr

        with gr.Blocks(fill_height=True) as demo:
            stored_messages = gr.State([])
            file_uploads_log = gr.State([])
            chatbot = gr.Chatbot(
                label="Agent",
                type="messages",
                avatar_images=(
                    None,
                    "https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/communication/Alfred.png",
                ),
                resizeable=True,
                scale=1,
            )
            # If an upload folder is provided, enable the upload feature
            if self.file_upload_folder is not None:
                upload_file = gr.File(label="Upload a file")
                upload_status = gr.Textbox(label="Upload Status", interactive=False, visible=False)
                upload_file.change(
                    self.upload_file,
                    [upload_file, file_uploads_log],
                    [upload_status, file_uploads_log],
                )
            text_input = gr.Textbox(lines=1, label="Chat Message")
            text_input.submit(
                self.log_user_message,
                [text_input, file_uploads_log],
                [stored_messages, text_input],
            ).then(self.interact_with_agent, [stored_messages, chatbot], [chatbot])

        demo.launch(debug=True, share=False, **kwargs)


__all__ = ["stream_to_gradio", "GradioUI"]
```

#### ‰æùËµñ

requirements.txt

```plaintext
markdownify
requests
ddgs
pandas
dashscope
smolagents[gradio]
smolagents[openai]
```

#### tools Êñá‰ª∂Â§π‰∏ã py Êñá‰ª∂

final_answer.py

```python
from typing import Any, Optional
from smolagents.tools import Tool

class FinalAnswerTool(Tool):
    name = "final_answer"
    description = "Provides a final answer to the given problem."
    inputs = {'answer': {'type': 'any', 'description': 'The final answer to the problem'}}
    output_type = "any"

    def forward(self, answer: Any) -> Any:
        return answer

    def __init__(self, *args, **kwargs):
        self.is_initialized = False

```

visit_webpage.py

```python
from typing import Any, Optional
from smolagents.tools import Tool
import requests
import markdownify
import smolagents
import re

class VisitWebpageTool(Tool):
    name = "visit_webpage"
    description = "Visits a webpage at the given url and reads its content as a markdown string. Use this to browse webpages."
    inputs = {'url': {'type': 'string', 'description': 'The url of the webpage to visit.'}}
    output_type = "string"

    def forward(self, url: str) -> str:
        try:
            import requests
            from markdownify import markdownify
            from requests.exceptions import RequestException

            from smolagents.utils import truncate_content
        except ImportError as e:
            raise ImportError(
                "You must install packages `markdownify` and `requests` to run this tool: for instance run `pip install markdownify requests`."
            ) from e
        try:
            # Send a GET request to the URL with a 20-second timeout
            response = requests.get(url, timeout=20)
            response.raise_for_status()  # Raise an exception for bad status codes

            # Convert the HTML content to Markdown
            markdown_content = markdownify(response.text).strip()

            # Remove multiple line breaks
            markdown_content = re.sub(r"\n{3,}", "\n\n", markdown_content)

            return truncate_content(markdown_content, 10000)

        except requests.exceptions.Timeout:
            return "The request timed out. Please try again later or check the URL."
        except RequestException as e:
            return f"Error fetching the webpage: {str(e)}"
        except Exception as e:
            return f"An unexpected error occurred: {str(e)}"

    def __init__(self, *args, **kwargs):
        self.is_initialized = False

```

web_search.py

```python
from typing import Any, Optional
from smolagents.tools import Tool

class DuckDuckGoSearchTool(Tool):
    name = "web_search"
    description = "Performs a duckduckgo web search based on your query (think a Google search) then returns the top search results."
    inputs = {'query': {'type': 'string', 'description': 'The search query to perform.'}}
    output_type = "string"

    def __init__(self, max_results=10, **kwargs):
        super().__init__()
        self.max_results = max_results
        try:
            from ddgs import DDGS
        except ImportError as e:
            raise ImportError(
                "You must install package `ddgs` to run this tool: for instance run `pip install ddgs`."
            ) from e
        self.ddgs = DDGS(**kwargs)

    def forward(self, query: str) -> str:
        results = self.ddgs.text(query, max_results=self.max_results)
        if len(results) == 0:
            raise Exception("No results found! Try a less restrictive/shorter query.")
        postprocessed_results = [f"[{result['title']}]({result['href']})\n{result['body']}" for result in results]
        return "## Search Results\n\n" + "\n\n".join(postprocessed_results)

```

ËøõÂÖ•È°πÁõÆÔºå‰ΩøÁî® git bash Âú®ÂΩìÂâçÁõÆÂΩïÊâßË°å‰ª•‰∏ãÂëΩ‰ª§ÔºàËøôÈáåÊòØ Windows ÁéØÂ¢ÉÁöÑÔºåÂÖ∂‰ªñÁéØÂ¢ÉÂéªÊéâ .bat 

Windows ÁéØÂ¢É‰ºöÊúâÊñ∞ÁöÑÈóÆÈ¢òÔºå‰∏çËÆ©ÊâßË°åËÑöÊú¨ÔºåÈúÄË¶ÅÁÆ°ÁêÜÂëòÊùÉÈôêÊâìÂºÄ PowershellÔºåÁÑ∂ÂêéÊâßË°å `set-ExecutionPolicy RemoteSigned` ËæìÂÖ• Y Â∞±Ë°å‰∫Ü„ÄÇ

```bash
python -m venv .venv

.venv/Scripts/activate.ps1

pip install -r requirements.txt
# Ê£ÄÊü•ÊòØÂê¶ÂÆâË£ÖÂÆåÊØï
pip list

# ÊâßË°å‰∏ãÈù¢ËØ≠Âè•ÂêØÂä®
python app.py
```

### Java È°πÁõÆ

Ë¶ÅÊ±Ç JDK17ÔºåÁéØÂ¢ÉÂèòÈáèÊ∑ªÂä† DEEPSEEK_API_KEY Âéª[ËøôÈáå](https://platform.deepseek.com/api_keys)ÂàõÂª∫‰∏Ä‰∏™ keyÔºåÂÖçË¥πÁöÑÊúâ 15 ÂÖÉÁöÑÈ¢ùÂ∫¶„ÄÇ

#### pom.xml

```xml
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>
	<parent>
		<groupId>org.springframework.boot</groupId>
		<artifactId>spring-boot-starter-parent</artifactId>
		<version>3.4.8</version>
		<relativePath/> <!-- lookup parent from repository -->
	</parent>
	<groupId>com.young1lin</groupId>
	<artifactId>agent-demo</artifactId>
	<version>0.0.1-SNAPSHOT</version>
	<name>agent-demo</name>
	<description>Demo project for Spring Boot</description>
	<url/>
	<licenses>
		<license/>
	</licenses>
	<developers>
		<developer/>
	</developers>
	<scm>
		<connection/>
		<developerConnection/>
		<tag/>
		<url/>
	</scm>
	<properties>
		<java.version>17</java.version>
		<spring-ai.version>1.0.1</spring-ai.version>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
		<project.reporting.outputEncoding>UTF-8</project.reporting.outputEncoding>
		<maven.compiler.encoding>UTF-8</maven.compiler.encoding>
	</properties>
	<dependencies>
		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-web</artifactId>
		</dependency>
		<dependency>
			<groupId>org.springframework.ai</groupId>
			<artifactId>spring-ai-starter-model-openai</artifactId>
		</dependency>

		<dependency>
			<groupId>org.springframework.ai</groupId>
			<artifactId>spring-ai-starter-model-deepseek</artifactId>
		</dependency>

		<!-- Observability dependencies -->
		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-actuator</artifactId>
		</dependency>
		<dependency>
			<groupId>io.micrometer</groupId>
			<artifactId>micrometer-registry-prometheus</artifactId>
		</dependency>

		<dependency>
			<groupId>org.projectlombok</groupId>
			<artifactId>lombok</artifactId>
			<optional>true</optional>
		</dependency>
		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-test</artifactId>
			<scope>test</scope>
		</dependency>
	</dependencies>
	<dependencyManagement>
		<dependencies>
			<dependency>
				<groupId>org.springframework.ai</groupId>
				<artifactId>spring-ai-bom</artifactId>
				<version>${spring-ai.version}</version>
				<type>pom</type>
				<scope>import</scope>
			</dependency>
		</dependencies>
	</dependencyManagement>

	<build>
		<plugins>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-compiler-plugin</artifactId>
				<configuration>
					<annotationProcessorPaths>
						<path>
							<groupId>org.projectlombok</groupId>
							<artifactId>lombok</artifactId>
						</path>
					</annotationProcessorPaths>
				</configuration>
			</plugin>
			<plugin>
				<groupId>org.springframework.boot</groupId>
				<artifactId>spring-boot-maven-plugin</artifactId>
				<configuration>
					<excludes>
						<exclude>
							<groupId>org.projectlombok</groupId>
							<artifactId>lombok</artifactId>
						</exclude>
					</excludes>
				</configuration>
			</plugin>
		</plugins>
	</build>

</project>
```

#### application.yml

```yaml
spring:
  application:
    name: agent-demo
  ai:
    model:
      chat: deepseek
      audio:
        speech: false
        transcription: false
      embedding: false
      image: false
      moderation: false
    chat:
      client:
        enabled: true
        observations:
          log-prompt: false
    deepseek:
      chat:
        options:
          model: deepseek-chat
          temperature: 0
        api-key: ${DEEPSEEK_API_KEY}

# Êó•ÂøóÈÖçÁΩÆ
logging:
  level:
    root: INFO
    # Ê∑ªÂä†observabilityÁõ∏ÂÖ≥ÁöÑÊó•ÂøóÁ∫ßÂà´
    org.springframework.ai.chat.client.advisor.SimpleLoggerAdvisor: DEBUG
  file:
    name: logs/agent-demo.log

server:
  servlet:
    encoding:
      charset: UTF-8
      enabled: true
```

#### AgentDemoApplication.java

```java
package com.young1lin.agent.demo;

import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;

/**
 * @author Liam
 */
@SpringBootApplication
public class AgentDemoApplication {

	public static void main(String[] args) {
		SpringApplication.run(AgentDemoApplication.class, args);
	}

}

```

#### UserInputReq.java

```java
package com.young1lin.agent.demo.controller.vo;

import lombok.Data;

/**
 * @author Liam
 * @version 1.0.0
 * @since 2025/8/7 15:25
 */
@Data
public class UserInputReq {

    private String userInput;

}
```

#### AgentChatDemoController.java

```java  
import com.young1lin.agent.demo.controller.vo.UserInputReq;  
import com.young1lin.agent.demo.tool.AgentTool;  
import lombok.RequiredArgsConstructor;  
import lombok.extern.slf4j.Slf4j;  
import org.springframework.ai.chat.client.ChatClient;  
import org.springframework.ai.chat.client.advisor.MessageChatMemoryAdvisor;  
import org.springframework.ai.chat.client.advisor.SimpleLoggerAdvisor;  
import org.springframework.ai.chat.memory.ChatMemory;  
import org.springframework.ai.chat.memory.ChatMemoryRepository;  
import org.springframework.ai.chat.memory.MessageWindowChatMemory;  
  
import org.springframework.beans.factory.InitializingBean;  
import org.springframework.http.MediaType;  
import org.springframework.web.bind.annotation.*;  
import reactor.core.publisher.Flux;  
  
import java.time.LocalDateTime;  
import java.util.HashMap;  
import java.util.Map;  
  
/**  
 * @author Liam  
 * @version v1.0.0  
 * @since 2025/8/7 13:37  
 */@RestController  
@RequestMapping  
@RequiredArgsConstructor  
@Slf4j  
public class AgentChatDemoController implements InitializingBean {  
  
    private final ChatClient.Builder chatClientBuilder;  
  
    private final AgentTool agentTool;  
  
    private final ChatMemoryRepository chatMemoryRepository;  
  
    /**  
     * default use InMemoryChatRepository     */    private ChatMemory chatMemory;  
  
    private ChatClient chatClient;  
  
  
    @Override  
    public void afterPropertiesSet() {  
        chatClient = chatClientBuilder  
                // ËÆæÁΩÆÁ≥ªÁªüÊèêÁ§∫ËØçÔºåÊòéÁ°ÆÂ∑•ÂÖ∑‰ΩøÁî®ÊåáÂØº  
                .defaultSystem("""  
                        ‰Ω†ÊòØ‰∏Ä‰∏™Êô∫ËÉΩÂÆ¢ÊúçÔºåÂõûÂ§çÈáèÂåñ‰∫§ÊòìÁõ∏ÂÖ≥ÁöÑÂÜÖÂÆπÔºå‰∏çË¶ÅËæìÂá∫ÊúâÂÆ≥ÂÜÖÂÆπ„ÄÇ  
                                                ‰Ω†Êúâ‰ª•‰∏ãÂ∑•ÂÖ∑ÂèØ‰ª•‰ΩøÁî®ÔºåËØ∑Ê†πÊçÆÁî®Êà∑ÈóÆÈ¢ò‰∏ªÂä®‰ΩøÁî®ÂêàÈÄÇÁöÑÂ∑•ÂÖ∑Ôºö  
                        1. orderSearch - ÂΩìÁî®Êà∑ËØ¢ÈóÆËÆ¢Âçï‰ø°ÊÅØÊó∂‰ΩøÁî®ÔºåÈúÄË¶ÅËÆ¢ÂçïIDÂèÇÊï∞  
                        2. getWeatherByLocation - ÂΩìÁî®Êà∑ËØ¢ÈóÆÂ§©Ê∞î‰ø°ÊÅØÊó∂‰ΩøÁî®ÔºåÈúÄË¶ÅÂüéÂ∏ÇËã±ÊñáÂ∞èÂÜôÂêçÁß∞  
                                                ÈáçË¶ÅÔºöÊó†ËÆ∫ÂØπËØùËøõË°å‰∫ÜÂ§öÂ∞ëËΩÆÔºåÈÉΩË¶ÅËÆ∞‰Ωè‰Ω†ÂèØ‰ª•‰ΩøÁî®Ëøô‰∫õÂ∑•ÂÖ∑Êù•ÂõûÁ≠îÁî®Êà∑ÈóÆÈ¢ò„ÄÇ  
                        """)  
                // Ê≥®ÂÜåÂ∑•ÂÖ∑ - Âè™Ë∞ÉÁî®‰∏ÄÊ¨°ÔºåÁßªÈô§ÈáçÂ§çÁöÑdefaultTools()  
                .defaultTools(agentTool)  
                //.defaultAdvisors(SimpleLoggerAdvisor.builder().build())  
                .build();  
  
        // ‰øùÊåÅËæÉÂ∞èÁöÑÁ™óÂè£Â§ßÂ∞èÔºå‰ΩÜÈÄöËøáÊØèÊ¨°ËØ∑Ê±ÇÈáçÊñ∞Ê≥®ÂÖ•Á≥ªÁªüÊèêÁ§∫Êù•Ëß£ÂÜ≥Â∑•ÂÖ∑Ë∞ÉÁî®ÈóÆÈ¢ò  
        chatMemory = MessageWindowChatMemory.builder()  
                .maxMessages(5)  
                .chatMemoryRepository(chatMemoryRepository)  
                .build();  
    }  
  
    @PostMapping(value = "/completions", produces = MediaType.TEXT_EVENT_STREAM_VALUE)  
    public Flux<String> completions(@RequestParam(required = false, defaultValue = "123") String conversationId,  
                                    @RequestBody UserInputReq req) {  
        // Â∑•ÂÖ∑‰∏ä‰∏ãÊñáÔºåÂåÖÂê´Áî®Êà∑Ë∫´‰ªΩ‰ø°ÊÅØ  
        Map<String, Object> toolContext = new HashMap<>();  
        toolContext.put("uid", "1234");  
        // Ê∑ªÂä†ÂΩìÂâçÊó∂Èó¥‰ø°ÊÅØ  
        String currentTime = LocalDateTime.now().toString();  
  
        return chatClient.prompt()  
                .toolContext(toolContext)  
                .advisors(MessageChatMemoryAdvisor.builder(chatMemory)  
                        .conversationId(conversationId)  
                        .build(),  
                        SimpleLoggerAdvisor.builder().build())  
                // ÊØèÊ¨°ÂØπËØùÈÉΩÈáçÊñ∞Âº∫Ë∞ÉÂ∑•ÂÖ∑‰ΩøÁî®ÊåáÂØº  
                .system("""  
                        ÂΩìÂâçÊó∂Èó¥: """ + currentTime + """  
                        ÈáçË¶ÅÊèêÈÜíÔºö‰Ω†ÊòØ‰∏Ä‰∏™Êô∫ËÉΩÂÆ¢ÊúçÔºå‰∏ìÈó®Â§ÑÁêÜÈáèÂåñ‰∫§ÊòìÁõ∏ÂÖ≥ÈóÆÈ¢ò„ÄÇ  
                                                ‰Ω†Êã•Êúâ‰ª•‰∏ãÂ∑•ÂÖ∑ÔºåËØ∑‰∏ªÂä®‰ΩøÁî®Ôºö  
                        3. orderSearch(orderId) - Êü•ËØ¢ËÆ¢Âçï‰ø°ÊÅØÔºåÈúÄË¶ÅËÆ¢ÂçïIDÂèÇÊï∞  
                        4. getWeatherByLocation(location) - Êü•ËØ¢Â§©Ê∞îÔºåÈúÄË¶ÅÂüéÂ∏ÇËã±ÊñáÂ∞èÂÜôÂêçÁß∞  
                                                ÂΩìÁî®Êà∑ËØ¢ÈóÆËÆ¢ÂçïÊàñÂ§©Ê∞î‰ø°ÊÅØÊó∂ÔºåÂøÖÈ°ªÁ´ãÂç≥Ë∞ÉÁî®Áõ∏Â∫îÂ∑•ÂÖ∑Ôºå‰∏çË¶ÅÂè™ÊòØËØ¥"Ê≠£Âú®Êü•ËØ¢"„ÄÇ  
                        """)  
                .user(req.getUserInput())  
                .stream()  
                .content()  
                .doOnComplete(() -> log.info("Stream completed for conversation: {}, user input: {}",   
conversationId, req.getUserInput()))  
                .concatWith(Flux.just("[DONE]"));  
    }  
  
}
```

#### AgentTool.java

```java
package com.young1lin.agent.demo.tool;

import lombok.extern.slf4j.Slf4j;
import org.springframework.ai.chat.model.ToolContext;
import org.springframework.ai.tool.annotation.Tool;
import org.springframework.ai.tool.annotation.ToolParam;
import org.springframework.stereotype.Component;

/**
 * @author Liam
 * @version 1.0.0
 * @since 2025/8/7 13:41
 */
@Component
@Slf4j
public class AgentTool {

    @Tool(description = "Ê†πÊçÆËÆ¢ÂçïIDÊü•ËØ¢Âà∞ËÆ¢ÂçïËØ¶ÊÉÖ‰ø°ÊÅØ")
    public String orderSearch(@ToolParam(description = "ËÆ¢ÂçïID") String orderId,
                              ToolContext toolContext) {
        Object uidObj = toolContext.getContext().get("uid");
        if (uidObj instanceof String uid && "1234".equals(uid)) {
            if (orderId == null) {
                return "ËØ∑ËæìÂÖ•Ê≠£Á°ÆÁöÑËÆ¢Âçï‰ø°ÊÅØ";
            }
            if ("1234".equals(orderId)) {
                return "ËÆ¢ÂçïÂè∑Ôºö1234ÔºåËÆ¢ÂçïÁä∂ÊÄÅÔºöÂ∑≤ÊîØ‰ªòÔºåËÆ¢ÂçïÈáëÈ¢ùÔºö50ÂÖÉ„ÄÇ";
            } else if ("5678".equals(orderId)) {
                return "ËÆ¢ÂçïÂè∑Ôºö5678ÔºåËÆ¢ÂçïÁä∂ÊÄÅÔºöÂ∑≤ÂèëË¥ßÔºåËÆ¢ÂçïÈáëÈ¢ùÔºö100ÂÖÉ„ÄÇ";
            } else {
                return "Êú™ÊâæÂà∞ËÆ¢Âçï‰ø°ÊÅØ";
            }
        }
        log.info("Áî®Êà∑‰ø°ÊÅØ‰∏çÊ≠£Á°Æ");
        return "Áî®Êà∑id‰∏çÊ≠£Á°Æ";
    }

    @Tool(description = "Ê†πÊçÆÂüéÂ∏ÇËã±ÊñáÂêçÁß∞Êü•ËØ¢Â§©Ê∞î‰ø°ÊÅØ")
    public String getWeatherByLocation(@ToolParam(description = "ÂüéÂ∏ÇËã±ÊñáÂêçÁß∞ÔºåÂøÖÈ°ªÊòØÂÖ®Â∞èÂÜôËã±ÊñáÂêçÁß∞") String location) {
        if ("beijing".equals(location)) {
            return "Beijing weather: Sunny, 25¬∞C";
        } else if ("shanghai".equals(location)) {
            return "Shanghai weather: Cloudy, 22¬∞C";
        } else {
            return String.format("Weather for %s: Partly cloudy, 20¬∞C", location);
        }
    }


}
```

#### resources/static/index.html

```html
<!DOCTYPE html>  
<html lang="zh-CN">  
<head>  
    <meta charset="UTF-8">  
    <meta name="viewport" content="width=device-width, initial-scale=1.0">  
    <title>AI Agent ÊµãËØï</title>  
    <style>        body {  
            font-family: 'Microsoft YaHei', Arial, sans-serif;  
            max-width: 800px;  
            margin: 0 auto;  
            padding: 20px;  
            background-color: #f5f5f5;  
        }  
        .container {  
            background: white;  
            padding: 20px;  
            border-radius: 8px;  
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);  
        }  
        .input-group {  
            margin-bottom: 20px;  
        }  
        input[type="text"] {  
            width: 70%;  
            padding: 10px;  
            border: 1px solid #ddd;  
            border-radius: 4px;  
            font-size: 16px;  
        }  
        button {  
            padding: 10px 20px;  
            background-color: #007bff;  
            color: white;  
            border: none;  
            border-radius: 4px;  
            cursor: pointer;  
            font-size: 16px;  
        }  
        button:hover {  
            background-color: #0056b3;  
        }  
        button:disabled {  
            background-color: #ccc;  
            cursor: not-allowed;  
        }  
        .response {  
            margin-top: 20px;  
            padding: 15px;  
            border: 1px solid #ddd;  
            border-radius: 4px;  
            background-color: #f9f9f9;  
            min-height: 100px;  
            white-space: pre-wrap;  
            font-family: 'Courier New', monospace;  
        }  
        .status {  
            margin-top: 10px;  
            padding: 5px;  
            border-radius: 4px;  
        }  
        .status.connecting {  
            background-color: #fff3cd;  
            color: #856404;  
        }  
        .status.connected {  
            background-color: #d4edda;  
            color: #155724;  
        }  
        .status.error {  
            background-color: #f8d7da;  
            color: #721c24;  
        }  
    </style>  
</head>  
<body>  
    <div class="container">  
        <h1>AI Agent ÊµÅÂºèÂìçÂ∫îÊµãËØï</h1>  
        <div class="input-group">  
            <input type="text" id="userInput" placeholder="ËØ∑ËæìÂÖ•ÊÇ®ÁöÑÈóÆÈ¢ò..." value="‰Ω†ÊòØË∞ÅÔºü">  
            <button onclick="sendMessage()" id="sendBtn">ÂèëÈÄÅ</button>  
        </div>  
        <div id="status" class="status"></div>  
        <div id="response" class="response"></div>  
    </div>  
  
    <script>        let abortController = null;  
  
        async function sendMessage() {  
            const userInput = document.getElementById('userInput').value;  
            const responseDiv = document.getElementById('response');  
            const statusDiv = document.getElementById('status');  
            const sendBtn = document.getElementById('sendBtn');  
            if (!userInput.trim()) {  
                alert('ËØ∑ËæìÂÖ•ÈóÆÈ¢ò');  
                return;            }  
  
            // Ê∏ÖÁ©∫‰πãÂâçÁöÑÂìçÂ∫î  
            responseDiv.textContent = '';  
            statusDiv.textContent = 'Ê≠£Âú®ËøûÊé•...';  
            statusDiv.className = 'status connecting';  
            sendBtn.disabled = true;  
  
            // ÂèñÊ∂à‰πãÂâçÁöÑËØ∑Ê±Ç  
            if (abortController) {  
                abortController.abort();  
            }  
  
            // ÂàõÂª∫Êñ∞ÁöÑ AbortController            abortController = new AbortController();  
  
            try {  
                const response = await fetch('/completions', {  
                    method: 'POST',  
                    headers: {  
                        'Content-Type': 'application/json',  
                        'Accept': 'text/event-stream'  
                    },  
                    body: JSON.stringify({  
                        userInput: userInput  
                    }),  
                    signal: abortController.signal  
                });  
  
                if (!response.ok) {  
                    throw new Error(`HTTP error! status: ${response.status}`);  
                }  
  
                statusDiv.textContent = 'Â∑≤ËøûÊé•ÔºåÊ≠£Âú®Êé•Êî∂ÂìçÂ∫î...';  
                statusDiv.className = 'status connected';  
  
                const reader = response.body.getReader();  
                const decoder = new TextDecoder();  
                let buffer = '';  
  
                while (true) {  
                    const { done, value } = await reader.read();  
                    if (done) {  
                        console.log('Stream reader done'); // Ë∞ÉËØï‰ø°ÊÅØ  
                        break;  
                    }  
  
                    // Ëß£Á†ÅÊñ∞ÁöÑÊï∞ÊçÆÂùóÂπ∂Ê∑ªÂä†Âà∞ÁºìÂÜ≤Âå∫  
                    const chunk = decoder.decode(value, { stream: true });  
                    console.log('Received chunk:', chunk); // Ë∞ÉËØï‰ø°ÊÅØ  
                    buffer += chunk;  
                    // ÊåâË°åÂàÜÂâ≤Âπ∂Â§ÑÁêÜ  
                    const lines = buffer.split('\n');  
                    buffer = lines.pop() || ''; // ‰øùÁïô‰∏çÂÆåÊï¥ÁöÑË°å  
                    console.log('Processing lines:', lines); // Ë∞ÉËØï‰ø°ÊÅØ  
                    for (const line of lines) {  
                        console.log('Processing line:', line); // Ë∞ÉËØï‰ø°ÊÅØ  
                        if (line.trim() === '') {  
                            console.log('Skipping empty line'); // Ë∞ÉËØï‰ø°ÊÅØ  
                            continue; // Ë∑≥ËøáÁ©∫Ë°å  
                        }  
                        if (line.startsWith('data:')) {  
                            const data = line.slice(5).trim(); // ÂÖºÂÆπÊúâÊó†Á©∫Ê†º  
                            console.log('Received data:', data); // Ë∞ÉËØï‰ø°ÊÅØ  
                            if (data === '[DONE]') {  
                                console.log('Received [DONE] marker'); // Ë∞ÉËØï‰ø°ÊÅØ  
                                statusDiv.textContent = 'ÂìçÂ∫îÂÆåÊàê';  
                                statusDiv.className = 'status connected';  
                                sendBtn.disabled = false;  
                                return;                            }  
                            // Áõ¥Êé•Ê∑ªÂä†ÂÜÖÂÆπÔºå‰∏çÊ∑ªÂä†È¢ùÂ§ñÁöÑÊç¢Ë°åÁ¨¶  
                            responseDiv.textContent += data;  
                            console.log('Updated response div:', responseDiv.textContent); // Ë∞ÉËØï‰ø°ÊÅØ  
                        } else {  
                            console.log('Line does not start with data:', line); // Ë∞ÉËØï‰ø°ÊÅØ  
                        }  
                    }  
                }  
  
                // Â§ÑÁêÜÁºìÂÜ≤Âå∫‰∏≠Ââ©‰ΩôÁöÑÊï∞ÊçÆ  
                if (buffer) {  
                    const lines = buffer.split('\n');  
                    for (const line of lines) {  
                        if (line.startsWith('data:')) {  
                            const data = line.slice(5).trim();  
                            if (data === '[DONE]') {  
                                statusDiv.textContent = 'ÂìçÂ∫îÂÆåÊàê';  
                                statusDiv.className = 'status connected';  
                                sendBtn.disabled = false;  
                                return;                            }  
                            responseDiv.textContent += data;  
                        }  
                    }  
                }  
  
                statusDiv.textContent = 'ÂìçÂ∫îÂÆåÊàê';  
                statusDiv.className = 'status connected';  
                sendBtn.disabled = false;  
  
            } catch (error) {  
                if (error.name === 'AbortError') {  
                    statusDiv.textContent = 'ËØ∑Ê±ÇÂ∑≤ÂèñÊ∂à';  
                } else {  
                    statusDiv.textContent = `ËøûÊé•ÈîôËØØ: ${error.message}`;  
                    statusDiv.className = 'status error';  
                    console.error('Error:', error);  
                }  
                sendBtn.disabled = false;  
            }  
        }  
  
        // ÊîØÊåÅÂõûËΩ¶ÈîÆÂèëÈÄÅ  
        document.getElementById('userInput').addEventListener('keypress', function(e) {  
            if (e.key === 'Enter') {  
                sendMessage();  
            }  
        });  
    </script>  
</body>  
</html>
```

#### ÂêØÂä®È°πÁõÆÂêé

ÂêØÂä®È°πÁõÆÂêéÔºåËÆøÈóÆ localhost:8080 Âç≥ÂèØÔºåÊéßÂà∂Âè∞‰ºöÊâìÂç∞ËØ∑Ê±ÇÂíåÂìçÂ∫îÁöÑÂÜÖÂÆπ„ÄÇ

## MCP

ÂÆòÁΩë
https://modelcontextprotocol.io/overview

MCP ÊòØ Anthropic ÊèêÂá∫ÁöÑÊ®°Âûã‰∏ä‰∏ãÊñáÂçèËÆÆÔºåÁõÆÂâç‰∏ªÊµÅÁöÑÂéÇÂïÜÂè™ÊòØÊää MCP ÁöÑ Tool ÁªôÈÄÇÈÖç‰∫ÜÂá∫Êù•ÔºåÊãøËøô‰∏™Êù•‰ª£ÊõøÊú¨Âú∞ Agent Ê°ÜÊû∂ÁöÑ @Tool„ÄÇÂÆûÈôÖ‰∏ä MCP ËøòÂåÖÊã¨‰∫Ü prompts„ÄÅresources„ÄÅimage ËΩ¨ base64„ÄÇÂ∫ïÂ±ÇÁöÑ‰º†ËæìÂçèËÆÆÈô§‰∫Ü stdio Âíå Streamable HTTP„ÄÇÂÆûÈôÖ‰∏ä‰ª£Á†ÅÈáåÂ∑≤ÁªèÊîØÊåÅ‰∫Ü WebSocket ‰Ωú‰∏∫ÂÖ∂‰º†ËæìÂçèËÆÆÔºåÂÖ∑‰Ωì[‰ª£Á†ÅÂú®Ëøô](https://github.com/modelcontextprotocol/python-sdk/blob/main/src/mcp/server/websocket.py)

ÂêéÈù¢ÊºîÁ§∫ Coze ÂíåÁôæÁÇºÂπ≥Âè∞ÊûÑÂª∫ Agent ÁöÑÊó∂ÂÄô‰ºöÊºîÁ§∫ÔºåÂÆÉ‰ª¨Âè™ÊòØÊää MCP ÂΩìÂÅö‰∫ÜÂÖ¨ÂÖ±ÁöÑ Tool„ÄÇ

# RAG

RAG ÊòØ‰ªÄ‰πàÔºü‰∏∫‰ªÄ‰πàË¶ÅÊúâ RAG ÊäÄÊúØÔºü

RAGÔºàRetrieval-Augmented GenerationÔºåÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÔºâÊòØ‰∏ÄÁßçÁªìÂêà‰∫Ü‰ø°ÊÅØÊ£ÄÁ¥¢ÂíåÊñáÊú¨ÁîüÊàêÁöÑÊäÄÊúØ„ÄÇÁÆÄÂçïÊù•ËØ¥ÔºåÂ∞±ÊòØËÆ©Â§ßÊ®°ÂûãÂú®ÂõûÁ≠îÈóÆÈ¢òÊó∂ÔºåÂÖàÂéª"Êü•ËµÑÊñô"ÔºåÂÜçÂü∫‰∫éÊü•Âà∞ÁöÑËµÑÊñôÊù•ÁîüÊàêÁ≠îÊ°à„ÄÇ

Ê®°Âûã‰∏ä‰∏ãÊñá‰πüÊòØÊúâÈôêÂà∂ÁöÑÔºåÂ¶ÇÊûúÊää‰∫ßÂìÅÊâÄÊúâÁöÑ‰ø°ÊÅØÊîæÂà∞ÊèêÁ§∫ËØç‰∏≠ÔºåÈÇ£‰πàÂõûÁ≠îÁî®Êà∑ÁöÑ Token Â∞±‰∏çÂ§ü„ÄÇ‰æãÂ¶Ç‰∏Ä‰∏™Êï∞‰ªì‰∏≠ÔºåÊúâ‰∏Ä‰∏á‰∏™Ë°®ÔºåÊØè‰∏™Ë°®ÁöÑË°®ÂÆö‰πâÂ¶ÇÊûúÈÉΩÊîæÂÖ•‰∏ä‰∏ãÊñá‰∏≠ÔºåÂõûÁ≠îÁî®Êà∑ÁöÑÂÜÖÂÆπÂ∞±‰∏çÂ§ü‰∫Ü„ÄÇÂèØ‰ª•Áî® RAG ÊäÄÊúØÔºåÂ∞ÜÊØè‰∏™Ë°®ÁöÑÂÖÉ‰ø°ÊÅØÁ≠âÂÜÖÂÆπÂêëÈáèÂåñÔºåÂ≠òÂÖ•ÂêëÈáèÊï∞ÊçÆÂ∫ìÔºå‰∏ãÊ¨°Áî®Êà∑ÈóÆÁöÑÊó∂ÂÄôÔºåÂÖàÂéªÊ£ÄÁ¥¢ÂèØËÉΩÊ∂âÂèäÂà∞Âì™‰∫õË°®ÔºåÁÑ∂ÂêéÂ∏¶‰∏äÂÆÉ‰ª¨ÁöÑÂÖÉ‰ø°ÊÅØÔºåÂÜç‰∏¢ÁªôÂ§ßÊ®°ÂûãÔºåËøôÊ†∑Â∞±‰∏ç‰ºöÂ§ßÊ®°ÂûãÂè™ÈúÄË¶ÅÁü•ÈÅìÁõ∏ÂÖ≥ÁöÑË°®ÔºåËàçÂºÉÊéâ‰∏çÈúÄË¶ÅÁöÑË°®‰ø°ÊÅØÔºåÂõûÁ≠îÁªìÊûú‰ºöÊõ¥Â§öÔºåÊõ¥ÂáÜÁ°Æ„ÄÇ

Áî®‰∏ÄÂº†ÂõæÂ∞±ËÉΩÂ±ïÁé∞ÔºåÊù•Ëá™ WikipediaÔºåÂÖàÂ∞ÜÂºïÁî®ÊñáÊ°£ÂêëÈáèÂåñÔºåÂ≠òÂÖ•ÂêëÈáèÊï∞ÊçÆÂ∫ìÔºå‰∏ãÊ¨°Áî®Êà∑ÂØπËØùÁöÑÊó∂ÂÄôÔºåÂÖàÂ∞ÜÁî®Êà∑ËæìÂÖ•ÁöÑÂÜÖÂÆπÂêëÈáèÂåñÔºåÊãøÂà∞ÂêëÈáèÂêéÂéªÂêëÈáèÊï∞ÊçÆÂ∫ì‰∏≠ÊâæÂà∞Áõ∏ËøëÁöÑÂêëÈáèÔºåÁÑ∂ÂêéËøîÂõûÂØπÂ∫îÁöÑ‰∏ä‰∏ãÊñáÊñáÊú¨ÔºåÂÜç‰∏¢ÁªôÂ§ßÊ®°ÂûãÔºåÂ§ßÊ®°Âûã‰ºöÂõûÂ§çÁõ∏Â∫îÁöÑÂÜÖÂÆπ„ÄÇ

‰∏ãÈù¢‰ºöÊºîÁ§∫ Dify„ÄÅCoze Âíå ÈòøÈáå‰∫ëÁôæÁÇº Âπ≥Âè∞ÁöÑÂêëÈáèÂåñÊâßË°åÁöÑÂÜÖÂÆπ„ÄÇ

![RAG_diagram.svg.png](https://s2.loli.net/2025/08/07/fusJicRtL8rCTSW.png)

## ‰∏∫‰ªÄ‰πàÈúÄË¶Å RAGÔºü

ÂâçÈù¢Êàë‰ª¨ÊèêÂà∞ËøáÂ§ßÊ®°ÂûãÁöÑ"ÂπªËßâ"ÈóÆÈ¢ò„ÄÇÂΩìÊ®°ÂûãÈÅáÂà∞ËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Ê≤°ÊúâÁöÑ‰ø°ÊÅØÊó∂ÔºåÂèØËÉΩ‰ºöÁºñÈÄ†Á≠îÊ°à„ÄÇÊØîÂ¶Ç‰Ω†ÈóÆ"2024Âπ¥ÊúÄÊñ∞ÁöÑÊäÄÊúØË∂ãÂäøÊòØ‰ªÄ‰πàÔºü"ÔºåÊ®°ÂûãÂèØËÉΩÂü∫‰∫é2023Âπ¥ÁöÑËÆ≠ÁªÉÊï∞ÊçÆÁªôÂá∫ËøáÊó∂ÁöÑÁ≠îÊ°à„ÄÇ

RAG ÁöÑÊ†∏ÂøÉÊÄùÊÉ≥ÊòØÔºö**ËÆ©Ê®°ÂûãÂú®ÂõûÁ≠îÂâçÂÖàÊ£ÄÁ¥¢Áõ∏ÂÖ≥‰ø°ÊÅØÔºåÁ°Æ‰øùÁ≠îÊ°àÁöÑÂáÜÁ°ÆÊÄßÂíåÊó∂ÊïàÊÄß**„ÄÇ

‰∏æ‰∏™‰æãÂ≠êÔºö

- **‰º†ÁªüÊñπÂºè**ÔºöÁî®Êà∑ÈóÆ"Êàë‰ª¨ÂÖ¨Âè∏ÁöÑ‰∫ßÂìÅÊúâÂì™‰∫õÔºü" ‚Üí Ê®°ÂûãÁõ¥Êé•ÂõûÁ≠îÔºàÂèØËÉΩÁºñÈÄ†Ôºâ
- **RAG ÊñπÂºè**ÔºöÁî®Êà∑ÈóÆ"Êàë‰ª¨ÂÖ¨Âè∏ÁöÑ‰∫ßÂìÅÊúâÂì™‰∫õÔºü" ‚Üí Ê£ÄÁ¥¢ÂÖ¨Âè∏ÊñáÊ°£ ‚Üí Âü∫‰∫éÊ£ÄÁ¥¢ÁªìÊûúÂõûÁ≠î

## ÊñáÊ°£ÂàáÂùó

RAG ÁöÑÁ¨¨‰∏ÄÊ≠•ÊòØÂ∞ÜÊñáÊ°£ÂàáÂàÜÊàêÂ∞èÂùó„ÄÇ‰∏∫‰ªÄ‰πàË¶ÅÂàáÂùóÔºü

1. **Token ÈôêÂà∂**ÔºöÂ§ßÊ®°ÂûãÊúâ‰∏ä‰∏ãÊñáÈïøÂ∫¶ÈôêÂà∂ÔºåÊó†Ê≥ï‰∏ÄÊ¨°ÊÄßÂ§ÑÁêÜËøáÈïøÁöÑÊñáÊ°£
2. **Á≤æÁ°ÆÊ£ÄÁ¥¢**ÔºöÂ∞èÂùóÊõ¥ÂÆπÊòìÂåπÈÖçÁî®Êà∑ÁöÑÂÖ∑‰ΩìÈóÆÈ¢ò
3. **ÊïàÁéáËÄÉËôë**ÔºöÂ∞èÂùóÊ£ÄÁ¥¢ÊØîÂÖ®ÊñáÊ£ÄÁ¥¢Êõ¥È´òÊïà

### ÂàáÂùóÁ≠ñÁï•

```python
# ÁÆÄÂçïÁöÑÊåâÂ≠óÁ¨¶Êï∞ÂàáÂùó
def split_text_by_length(text, chunk_size=1000, overlap=200):
    chunks = []
    start = 0
    while start < len(text):
        end = start + chunk_size
        chunk = text[start:end]
        chunks.append(chunk)
        start = end - overlap
    return chunks

# ÊåâÊÆµËêΩÂàáÂùó
def split_text_by_paragraph(text):
    paragraphs = text.split('\n\n')
    return [p.strip() for p in paragraphs if p.strip()]

# ÊåâÂè•Â≠êÂàáÂùóÔºàÊõ¥Êô∫ËÉΩÔºâ
import re
def split_text_by_sentence(text, max_length=1000):
    sentences = re.split(r'[.!?]+', text)
    chunks = []
    current_chunk = ""
    
    for sentence in sentences:
        if len(current_chunk) + len(sentence) < max_length:
            current_chunk += sentence + ". "
        else:
            if current_chunk:
                chunks.append(current_chunk.strip())
            current_chunk = sentence + ". "
    
    if current_chunk:
        chunks.append(current_chunk.strip())
    
    return chunks
```

## Embedding

Embedding ÊòØÂ∞ÜÊñáÊú¨ËΩ¨Êç¢‰∏∫Êï∞ÂÄºÂêëÈáèÁöÑËøáÁ®ã„ÄÇËøô‰∫õÂêëÈáèËÉΩÂ§üÊçïÊçâÊñáÊú¨ÁöÑËØ≠‰πâ‰ø°ÊÅØÔºå‰ΩøÂæóËØ≠‰πâÁõ∏‰ººÁöÑÊñáÊú¨Âú®ÂêëÈáèÁ©∫Èó¥‰∏≠Ë∑ùÁ¶ªËæÉËøë„ÄÇ

### ‰∏∫‰ªÄ‰πàË¶ÅÂ∞ÜËá™ÁÑ∂ËØ≠Ë®ÄÂêëÈáèÂåñÔºü

ËÆ°ÁÆóÊú∫Âè™ËÉΩÁêÜËß£Êï∞Â≠óÔºå‰∏çËÉΩÁõ¥Êé•ÁêÜËß£ÊñáÊú¨
‰∫∫Á±ªÁöÑËØ≠Ë®Ä‰∏∞ÂØåÂ§öÊ†∑Ôºå‰ΩÜÂØπ‰∫éËÆ°ÁÆóÊú∫Êù•ËØ¥ÔºåÊâÄÊúâÁöÑ‰ø°ÊÅØÊúÄÁªàÈÉΩË¶ÅËΩ¨Âåñ‰∏∫Êï∞Â≠óÊâçËÉΩËøõË°åÂ≠òÂÇ®„ÄÅËÆ°ÁÆóÂíåÂàÜÊûê„ÄÇEmbedding Â∞±ÊòØÊää"ÊñáÊú¨"ÂèòÊàê"ÂêëÈáè"ÔºåËÆ©ËÆ°ÁÆóÊú∫ËÉΩÂ§ü"ÁêÜËß£"Âπ∂Â§ÑÁêÜËá™ÁÑ∂ËØ≠Ë®Ä„ÄÇ

ÊÉ≥Ë±°‰∏Ä‰∏ãÔºåÂ¶ÇÊûúÊàë‰ª¨Ë¶ÅÂú®ÊñáÊ°£Â∫ì‰∏≠ÊêúÁ¥¢"‰∫∫Â∑•Êô∫ËÉΩ"Ôºå‰º†ÁªüÁöÑÂÖ≥ÈîÆËØçÊêúÁ¥¢ÂèØËÉΩÊâæ‰∏çÂà∞"AI"„ÄÅ"Êú∫Âô®Â≠¶‰π†"Á≠âÁõ∏ÂÖ≥ÂÜÖÂÆπ„ÄÇ‰ΩÜÈÄöËøá EmbeddingÔºåËøô‰∫õËØ≠‰πâÁõ∏ÂÖ≥ÁöÑËØçÊ±áÂú®ÂêëÈáèÁ©∫Èó¥‰∏≠‰ºöÂæàÊé•Ëøë„ÄÇ

```python
# ‰ΩøÁî® OpenAI ÁöÑ Embedding API
import openai
import numpy as np

def get_embedding(text, model="text-embedding-ada-002"):
    response = openai.Embedding.create(
        input=text,
        model=model
    )
    return response['data'][0]['embedding']

# ËÆ°ÁÆó‰∏§‰∏™ÂêëÈáèÁöÑÁõ∏‰ººÂ∫¶
def cosine_similarity(vec1, vec2):
    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))

# Á§∫‰æã
text1 = "‰∫∫Â∑•Êô∫ËÉΩÊäÄÊúØ"
text2 = "AI ÊäÄÊúØ"
text3 = "Â§©Ê∞îÈ¢ÑÊä•"

embedding1 = get_embedding(text1)
embedding2 = get_embedding(text2)
embedding3 = get_embedding(text3)

print(f"AI ‰∏é ‰∫∫Â∑•Êô∫ËÉΩ Áõ∏‰ººÂ∫¶: {cosine_similarity(embedding1, embedding2)}")
print(f"AI ‰∏é Â§©Ê∞îÈ¢ÑÊä• Áõ∏‰ººÂ∫¶: {cosine_similarity(embedding1, embedding3)}")
```

### ËØ≠‰πâÁõ∏‰ººÊÄßÂèØÂ∫¶Èáè

‰º†ÁªüÁöÑÂÖ≥ÈîÆËØçÊ£ÄÁ¥¢Âè™ËÉΩÊâæÂà∞ÂÆåÂÖ®ÂåπÈÖçÁöÑËØçÔºåÊó†Ê≥ïÁêÜËß£"‰∫∫Â∑•Êô∫ËÉΩ"Âíå"AI"ÂÖ∂ÂÆûÊòØ‰∏Ä‰∏™ÊÑèÊÄù„ÄÇÈÄöËøáÂêëÈáèÂåñÔºåËØ≠‰πâÁõ∏ÂÖ≥ÁöÑËØçÂú®ÂêëÈáèÁ©∫Èó¥‰∏≠Ë∑ùÁ¶ªÊõ¥ËøëÔºå‰æø‰∫éÂÅöËØ≠‰πâÊ£ÄÁ¥¢„ÄÅÊé®Ëçê„ÄÅËÅöÁ±ªÁ≠â‰ªªÂä°„ÄÇ‰æãÂ¶ÇÔºåÁî®Êà∑ÊêúÁ¥¢"Êú∫Âô®Â≠¶‰π†"ÔºåÁ≥ªÁªüÂèØ‰ª•Ëá™Âä®ËÅîÊÉ≥Âà∞"Ê∑±Â∫¶Â≠¶‰π†""AI"Á≠âÁõ∏ÂÖ≥ÂÜÖÂÆπ„ÄÇ

### ÊîØÊåÅÈ´òÊïàÁöÑÁõ∏‰ººÂ∫¶ËÆ°ÁÆóÂíåÊ£ÄÁ¥¢

ÂêëÈáèÂåñÂêéÔºåÂèØ‰ª•Áî®‰ΩôÂº¶Áõ∏‰ººÂ∫¶Á≠âÊñπÊ≥ïÂø´ÈÄüËÆ°ÁÆóÊñáÊú¨‰πãÈó¥ÁöÑÁõ∏‰ººÊÄß„ÄÇËøôÂØπ‰∫éÈóÆÁ≠îÁ≥ªÁªü„ÄÅÊô∫ËÉΩÂÆ¢Êúç„ÄÅÁü•ËØÜÂ∫ìÊ£ÄÁ¥¢Á≠âÂú∫ÊôØÈùûÂ∏∏ÂÖ≥ÈîÆ„ÄÇÊØîÂ¶ÇÔºåÁî®Êà∑ÊèêÈóÆ"ÊÄé‰πàÈáçÁΩÆÂØÜÁ†ÅÔºü"ÔºåÁ≥ªÁªüÂèØ‰ª•Âú®Áü•ËØÜÂ∫ì‰∏≠ÊâæÂà∞ËØ≠‰πâÊúÄÊé•ËøëÁöÑÁ≠îÊ°à„ÄÇ

### ÈôçÁª¥‰∏éÁ®†ÂØÜË°®ËææÔºåÊèêÂçáÊïàÁéá

Áé∞‰ª£ Embedding ÊñπÊ≥ïÔºàÂ¶Ç Word2Vec„ÄÅBERT„ÄÅtext-embedding-ada-002 Á≠âÔºâÈÄöÂ∏∏Â∞ÜÈ´òÁª¥Á®ÄÁñèÁöÑÊñáÊú¨‰ø°ÊÅØÂéãÁº©Êàê‰ΩéÁª¥Á®†ÂØÜÂêëÈáèÔºåÊó¢ÂáèÂ∞ë‰∫ÜÂ≠òÂÇ®Á©∫Èó¥Ôºå‰πüÊèêÂçá‰∫ÜËÆ°ÁÆóÂíåÊ£ÄÁ¥¢ÊïàÁéá„ÄÇ

### ‰∏∫‰∏ãÊ∏∏‰ªªÂä°Êèê‰æõÁªü‰∏ÄÁöÑËæìÂÖ•Ê†ºÂºè

Êó†ËÆ∫ÊòØÊñáÊú¨ÂàÜÁ±ª„ÄÅËÅöÁ±ª„ÄÅÊé®ËçêËøòÊòØÁîüÊàêÔºåEmbedding ÈÉΩÊòØÊ∑±Â∫¶Â≠¶‰π†Ê®°ÂûãÁöÑ"ÈÄöÁî®ËæìÂÖ•"„ÄÇÊúâ‰∫ÜÂêëÈáèÂåñÁöÑË°®ËææÔºåÊ®°ÂûãÊâçËÉΩÊõ¥Â•ΩÂú∞"ÁêÜËß£"ÊñáÊú¨ÔºåÂÆûÁé∞Êõ¥Êô∫ËÉΩÁöÑÊé®ÁêÜÂíåÂÜ≥Á≠ñ„ÄÇ

#### ‰∏æ‰∏™ÂÆûÈôÖ‰æãÂ≠êÔºö

ÂÅáÂ¶Ç‰Ω†Êúâ‰∏ÄÂ†Ü FAQ ÈóÆÁ≠îÔºåÁî®Êà∑ËæìÂÖ•"Â¶Ç‰Ωï‰øÆÊîπË¥¶Êà∑ÂØÜÁ†ÅÔºü"Ôºå‰º†ÁªüÊ£ÄÁ¥¢Âè™ËÉΩÊâæ"‰øÆÊîπË¥¶Êà∑ÂØÜÁ†Å"ËøôÂá†‰∏™Â≠óÂÆåÂÖ®ÂåπÈÖçÁöÑÊù°ÁõÆ„ÄÇ‰ΩÜÂ¶ÇÊûúÁî® EmbeddingÔºåÊääÊâÄÊúâÈóÆÈ¢òÂíåÁî®Êà∑ËæìÂÖ•ÈÉΩËΩ¨ÊàêÂêëÈáèÔºåÂ∞±ËÉΩÊâæÂà∞"ÈáçÁΩÆÂØÜÁ†Å""Êõ¥ÊîπÁôªÂΩïÂØÜÁ†Å"Á≠âËØ≠‰πâÁõ∏ËøëÁöÑÈóÆÈ¢òÔºåÂ§ßÂ§ßÊèêÂçá‰∫ÜÊ£ÄÁ¥¢ÁöÑÊô∫ËÉΩÊÄßÂíåÁî®Êà∑‰ΩìÈ™å„ÄÇ

https://cloud.dify.ai/app/194064ed-ee7d-4775-aa3d-648ca03fc909/workflow

### Êú¨Ë¥®

ÂêëÈáèÊú¨Ë¥®Â∞±ÊòØ‰∏Ä‰∏≤Êï∞Â≠óÔºåÊúâÂè™Êúâ 0 Âíå 1 Êï¥Êï∞Ë°®Á§∫ÁöÑÁ®ÄÁñèÂêëÈáèÔºåËøòÊúâÊµÆÁÇπÊï∞Ë°®Á§∫ÁöÑÁ®†ÂØÜÂêëÈáè„ÄÇ

**Á®ÄÁñèÂêëÈáèÔºàSparse VectorÔºâ**

- Â§ßÈÉ®ÂàÜÂÖÉÁ¥†‰∏∫0ÔºåÂè™ÊúâÂ∞ëÊï∞ÈùûÈõ∂ÂÖÉÁ¥†
- ‰æãÂ¶ÇÔºö[0, 0, 1, 0, 0, 0, 1, 0, 0, 0]
- Â≠òÂÇ®Êó∂ÂèØ‰ª•Âè™ËÆ∞ÂΩïÈùûÈõ∂ÂÖÉÁ¥†ÁöÑ‰ΩçÁΩÆÂíåÂÄºÔºåËäÇÁúÅÁ©∫Èó¥

**Á®†ÂØÜÂêëÈáèÔºàDense VectorÔºâ**

- Â§ßÈÉ®ÂàÜÊàñÂÖ®ÈÉ®ÂÖÉÁ¥†ÈÉΩÊòØÈùûÈõ∂ÁöÑÊµÆÁÇπÊï∞
- ‰æãÂ¶ÇÔºö[0.23, -0.15, 0.67, 0.89, -0.34]
- ‰ø°ÊÅØÂàÜÂ∏ÉÂùáÂåÄÔºåÊØè‰∏™Áª¥Â∫¶ÈÉΩÊúâÊÑè‰πâ

Âú®Êú∫Âô®Â≠¶‰π†‰∏≠ÔºåËøô‰∏§ÁßçÂêëÈáèÂΩ¢ÂºèÂêÑÊúâÁî®ÈÄîÔºö

- Á®ÄÁñèÂêëÈáèÂ∏∏Áî®‰∫éË°®Á§∫ÂàÜÁ±ªÁâπÂæÅ„ÄÅÊñáÊú¨ÁöÑËØçÈ¢ëÁªüËÆ°Á≠â
- Á®†ÂØÜÂêëÈáèÂ∏∏Áî®‰∫éÂµåÂÖ•Ë°®Á§∫„ÄÅÁ•ûÁªèÁΩëÁªúÁöÑ‰∏≠Èó¥Â±ÇËæìÂá∫Á≠â

‰∏äÈù¢ÁöÑ OpenAI text-embedding-3-small ËøîÂõûÁöÑÊòØ 1536 Áª¥Â∫¶ÁöÑÂêëÈáèÔºåMilvus ÈÉΩÂèØ‰ª•Â≠òÔºåÂπ∂‰∏îÂêéÁª≠Â¶ÇÊûúÊõ¥Âä†‰ºòÂåñÁöÑÊñπÂºèÔºåÂèØ‰ª•Âà©Áî®Á®ÄÁñèÂêëÈáèÂÖàËøáÊª§ÔºåÂÜçËøõË°åÁ≠õÈÄâÊúÄÁ¨¶ÂêàÁ®ÄÁñèÂêëÈáèÁõ∏ËøëÁ®†ÂØÜÂêëÈáèÁöÑÊñáÊ°£„ÄÇ

ËøáÁ®ãÂ¶Ç‰∏ã
![image.png](https://s2.loli.net/2025/08/08/NLuSY5O1VG26kWx.png)

## Â≠òÂÇ®ÂêëÈáè

Êúâ‰∫Ü Embedding ÂêéÔºåÊàë‰ª¨ÈúÄË¶ÅÂ∞ÜËøô‰∫õÂêëÈáèÂ≠òÂÇ®Ëµ∑Êù•Ôºå‰ª•‰æøÂø´ÈÄüÊ£ÄÁ¥¢„ÄÇÂ∏∏Áî®ÁöÑÂêëÈáèÊï∞ÊçÆÂ∫ìÂåÖÊã¨Ôºö

- **Pinecone**Ôºö‰∫ëÊúçÂä°ÔºåÊòì‰∫é‰ΩøÁî®
- **Weaviate**ÔºöÂºÄÊ∫êÔºåÂäüËÉΩ‰∏∞ÂØå
- **Qdrant**ÔºöÊÄßËÉΩ‰ºòÁßÄÔºåÊîØÊåÅÂ§çÊùÇÊü•ËØ¢
- **Chroma**ÔºöÂÜÖÂ≠òÂêëÈáèÊï∞ÊçÆÂ∫ìÔºå‰ªÖÁî®‰∫éÊºîÁ§∫‰ΩøÁî®
- **Milvus**ÔºöÂºÄÊ∫êÔºå‰ºÅ‰∏öÁ∫ßÂêëÈáèÊï∞ÊçÆÂ∫ì
- OpenGauss
- Elasticsearch
- Redis

ÂêéÈù¢‰∏â‰∏™ÈÉΩËÉΩÁî®Ôºå‰ΩÜÊòØ‰∏çÂ¶Ç Milvus Â•ΩÁî®ÔºåÂÖ∂‰∏≠Á¨¨‰∏Ä‰∏™ÊòØ‰∏∫‰∫ÜÂÆåÂÖ®ÂõΩ‰∫ßÂåñÂáÜÂ§áÁöÑÔºåÂêéÈù¢‰∏§‰∏™ÊòØÂ∑≤Êúâ‰∏Ä‰∫õÂØπÂ∫îÁöÑ‰∏≠Èó¥‰ª∂Ôºå‰∏çÊÉ≥Êñ∞Â¢ûÔºåÊâç‰ºöÂéªÈÄâÊã©„ÄÇ

## Milvus

Milvus ÊòØ‰∏Ä‰∏™ÂºÄÊ∫êÁöÑÂêëÈáèÊï∞ÊçÆÂ∫ìÔºå‰∏ì‰∏∫ AI Â∫îÁî®ËÆæËÆ°„ÄÇÂÆÉÊîØÊåÅÂ§öÁßçË∑ùÁ¶ªÂ∫¶ÈáèÊñπÂºèÔºåËÉΩÂ§üÈ´òÊïàÂ§ÑÁêÜÂ§ßËßÑÊ®°ÂêëÈáèÊï∞ÊçÆ„ÄÇ

### ‰∏∫‰ªÄ‰πàÈÄâÊã© MilvusÔºü

1. **È´òÊÄßËÉΩ**ÔºöÊîØÊåÅÊï∞ÂçÅ‰∫øÁ∫ßÂêëÈáèÊï∞ÊçÆ
2. **ÊòìÊâ©Â±ï**ÔºöÊîØÊåÅÊ∞¥Âπ≥Êâ©Â±ï
3. **Â§öË∑ùÁ¶ªÂ∫¶Èáè**ÔºöÊîØÊåÅ‰ΩôÂº¶Áõ∏‰ººÂ∫¶„ÄÅÊ¨ßÂá†ÈáåÂæóË∑ùÁ¶ªÁ≠â
4. **ÂÆûÊó∂ÊêúÁ¥¢**ÔºöÊØ´ÁßíÁ∫ßÂìçÂ∫îÊó∂Èó¥
5. **ÊîØÊåÅ‰∏çÂêåÁ¥¢Âºï**ÔºöFLAT„ÄÅIVF_FLATÔºàÊúÄÊé®ËçêÔºâ„ÄÅHNSW Á≠âÁ≠âÔºåÊåâÈúÄÈÄâÊã©

ËøòÊúâÊúÄÈáçË¶ÅÁöÑ‰∏ÄÁÇπÔºåCoze Studio ÈªòËÆ§ÈÄâÊã©Ëøô‰∏™„ÄÇ

### Âü∫Êú¨‰ΩøÁî®Á§∫‰æã

Milvus Êúâ‰∏âÁßçÈÉ®ÁΩ≤ÊñπÂºè

1. Milvus-Lite
2. Milvus-StandaloneÔºàÈÄÇÂêà‰∏≠Á≠âÊï∞ÊçÆÈáèÁöÑÈ°πÁõÆÔºåÂ∞±ÈÄÇÂêàËøôÈáåÔºâ
3. Milvus-Cluster

‰ΩøÁî® Milvus-Standalone ‰Ωú‰∏∫ÊºîÁ§∫

docker-compose.yaml Êñá‰ª∂Â¶Ç‰∏ã

```yaml
version: '3.5'

services:
  etcd:
    container_name: milvus-etcd
    image: quay.io/coreos/etcd:v3.5.5
    environment:
      - ETCD_AUTO_COMPACTION_MODE=revision
      - ETCD_AUTO_COMPACTION_RETENTION=1000
      - ETCD_QUOTA_BACKEND_BYTES=4294967296
      - ETCD_SNAPSHOT_COUNT=50000
    volumes:
      - etcd_data:/etcd
    command: etcd -advertise-client-urls=http://127.0.0.1:2379 -listen-client-urls http://0.0.0.0:2379 --data-dir /etcd
    healthcheck:
      test: ["CMD", "etcdctl", "endpoint", "health"]
      interval: 30s
      timeout: 20s
      retries: 3

  minio:
    container_name: milvus-minio
    image: minio/minio:RELEASE.2023-03-20T20-16-18Z
    environment:
      MINIO_ACCESS_KEY: minioadmin
      MINIO_SECRET_KEY: minioadmin
    ports:
      - "9001:9001"
      - "9000:9000"
    volumes:
      - minio_data:/minio_data
    command: minio server /minio_data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

  milvus:
    container_name: milvus-standalone
    image: milvusdb/milvus:v2.3.4
    command: ["milvus", "run", "standalone"]
    environment:
      ETCD_ENDPOINTS: etcd:2379
      MINIO_ADDRESS: minio:9000
    volumes:
      - milvus_data:/var/lib/milvus
      - ./milvus-config/user.yaml:/milvus/configs/user.yaml
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9091/healthz"]
      interval: 30s
      start_period: 90s
      timeout: 20s
      retries: 3
    ports:
      - "19530:19530"
      - "9091:9091"
    depends_on:
      - "etcd"
      - "minio"

  attu:
    container_name: milvus-attu
    image: zilliz/attu:v2.3.4
    environment:
      MILVUS_URL: milvus:19530
    ports:
      - "3000:3000"
    depends_on:
      - "milvus"

volumes:
  etcd_data:
  minio_data:
  milvus_data:

networks:
  default:
    name: milvus
```

‰ΩøÁî® `docker compose up -d` ÂêØÂä®È°πÁõÆÔºåÊØîËæÉËÄÅÁöÑ docker ‰∏≠Èó¥ÈúÄË¶ÅÂä†‰∏™ - Ôºå‰πüÂ∞±ÊòØ `docker-compose up -d` ÂêØÂä®È°πÁõÆ„ÄÇ

ÂêØÂä®ÊàêÂäüÂêéÔºåËÆøÈóÆ docker ÁöÑÂú∞ÂùÄÂä† 3000 Á´ØÂè£ÔºåÂç≥ÂèØÁúãÂà∞‰∏ãÈù¢ÁöÑÂÜÖÂÆπ

![image.png](https://s2.loli.net/2025/08/07/qznyDkW5EQCSY4b.png)
![image.png](https://s2.loli.net/2025/08/07/qwO2r6eCQo4Egad.png)

ÂøÖÈ°ª Python 3.13 ÁâàÊú¨‰ª•‰∏ä

‰æùËµñ
requirements.txt

```plaintext
pymilvus>=2.4.0
sentence-transformers>=2.6.0
numpy>=1.26.0
torch>=2.1.0
transformers>=4.35.0
```

ÂÆâË£Ö‰æùËµñ
WSL Á±ª Linux Á≥ªÁªü‰∏ã

```bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

```python
from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType, utility
import numpy as np
from sentence_transformers import SentenceTransformer

# ‰ΩøÁî®Êõ¥ÈÄÇÂêà‰∏≠ÊñáÁöÑ Embedding Ê®°Âûã
model = SentenceTransformer('shibing624/text2vec-base-chinese')  # ‰∏≠ÊñáÊ®°ÂûãÔºå768Áª¥ÂêëÈáè

def get_embedding(text):
    """‰ΩøÁî® sentence-transformers Ëé∑ÂèñÊñáÊú¨ÂêëÈáè"""
    embedding = model.encode(text)
    return embedding.tolist()

# ËøûÊé• Milvus
connections.connect("default", host="172.27.226.5", port="19530")

# ÂÆö‰πâÈõÜÂêàÁªìÊûÑ
dim = 768  # text2vec-base-chinese ÁöÑÂêëÈáèÁª¥Â∫¶
fields = [
    FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
    FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=65535),
    FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=dim)
]

schema = CollectionSchema(fields=fields, description="ÊñáÊ°£ÂêëÈáèÈõÜÂêà")
collection_name = "documents"

# ÂàõÂª∫ÈõÜÂêà
if utility.has_collection(collection_name):
    utility.drop_collection(collection_name)

collection = Collection(name=collection_name, schema=schema)

# ÂàõÂª∫Á¥¢Âºï
index_params = {
    "metric_type": "COSINE",
    "index_type": "IVF_FLAT",
    "params": {"nlist": 1024}
}
collection.create_index(field_name="embedding", index_params=index_params)

# ÊèíÂÖ•Êï∞ÊçÆ
documents = [
    "AIÂÖ®Áß∞ÊòØ‰∫∫Â∑•Êô∫ËÉΩÔºåÊòØËÆ°ÁÆóÊú∫ÁßëÂ≠¶ÁöÑ‰∏Ä‰∏™ÂàÜÊîØÔºåËÉΩÊ®°Êãü‰∫∫Á±ªÊô∫ËÉΩÔºå‰πüÊòØ‰∏™Á¨ºÁªüÁöÑÊ¶ÇÂøµÔºåÂÖ∂‰∏≠Êú∫Âô®Â≠¶‰π†ÊòØÂÖ∂ÂÆûÁé∞ÁöÑ‰∏ÄÁßçÊâãÊÆµ",
    "‰∫∫Â∑•Êô∫ËÉΩÊòØËÆ°ÁÆóÊú∫ÁßëÂ≠¶ÁöÑ‰∏Ä‰∏™ÂàÜÊîØ",
    "Êú∫Âô®Â≠¶‰π†ÊòØAIÁöÑÈáçË¶ÅÊäÄÊúØ",
    "Ê∑±Â∫¶Â≠¶‰π†ÊòØÊú∫Âô®Â≠¶‰π†ÁöÑ‰∏Ä‰∏™Â≠êÈõÜÔºåÊú∫Âô®Â≠¶‰π†ÊòØAIÁöÑÈáçË¶ÅÊäÄÊúØ",
    "„ÄäÈªëÁ•ûËØùÔºöÊÇüÁ©∫„ÄãÁöÑÂà∂‰Ωú‰∫∫ÊòØÂÜØÈ™•ÔºàÊ∏∏ÊàèÁßëÂ≠¶ËÅîÂêàÂàõÂßã‰∫∫Ôºâ",
    "‰∏≠ÂõΩÁîµÂΩ±2024Âπ¥Á•®ÊàøÂÜ†ÂÜõÊòØÁÉ≠Ëæ£ÊªöÁÉ´"
]

embeddings = [get_embedding(doc) for doc in documents]
texts = documents

# ‰øÆÂ§çÔºöÊåâÁÖßÂ≠óÊÆµÂÆö‰πâÈ°∫Â∫èÊèíÂÖ•Êï∞ÊçÆ (idÊòØËá™Â¢ûÁöÑÔºåÊâÄ‰ª•Âè™ÈúÄË¶ÅtextÂíåembedding)
collection.insert([texts, embeddings])
collection.flush()

# ÊêúÁ¥¢
collection.load()
search_params = {"metric_type": "COSINE", "params": {"nprobe": 10}}

query_embedding = get_embedding("AIÊòØ‰ªÄ‰πàÔºü")
print(f"Êü•ËØ¢ÂêëÈáèÂâç10‰∏™ÂÄº: {query_embedding[:10]}")
print("=" * 50)
results = collection.search(
    data=[query_embedding],
    anns_field="embedding",
    param=search_params,
    limit=6,
    output_fields=["text", "embedding"]
)

for hits in results:
    for hit in hits:
        print(f"Áõ∏‰ººÂ∫¶: {hit.score}, ÊñáÊú¨: {hit.entity.get('text')}")
        # Ëé∑ÂèñÂπ∂ÊâìÂç∞ÂêëÈáèÁöÑÂâç10‰∏™ÂÄº
        embedding = hit.entity.get('embedding')
        if embedding:
            print(f"ÂêëÈáèÂâç10‰∏™ÂÄº: {embedding[:10]}")
        print("-" * 50)
```

ËæìÂá∫ÂÜÖÂÆπ

```plaintext
Êü•ËØ¢ÂêëÈáèÂâç10‰∏™ÂÄº: [1.1496570110321045, -0.3689393997192383, 0.9862505793571472, 0.9357891082763672, 0.6909440755844116, -0.5275141000747681, 1.376283884048462, 0.8557244539260864, -1.6160293817520142, 0.22704903781414032]
==================================================
Áõ∏‰ººÂ∫¶: 0.6506596803665161, ÊñáÊú¨: AIÂÖ®Áß∞ÊòØ‰∫∫Â∑•Êô∫ËÉΩÔºåÊòØËÆ°ÁÆóÊú∫ÁßëÂ≠¶ÁöÑ‰∏Ä‰∏™ÂàÜÊîØÔºåËÉΩÊ®°Êãü‰∫∫Á±ªÊô∫ËÉΩÔºå‰πüÊòØ‰∏™Á¨ºÁªüÁöÑÊ¶ÇÂøµÔºåÂÖ∂‰∏≠Êú∫Âô®Â≠¶‰π†ÊòØÂÖ∂ÂÆûÁé∞ÁöÑ‰∏ÄÁßçÊâãÊÆµ
ÂêëÈáèÂâç10‰∏™ÂÄº: [0.8219285607337952, 0.2677353620529175, 1.1195573806762695, 1.2051314115524292, 0.4739314317703247, -0.6863083839416504, 0.9294951558113098, 0.9983838200569153, -1.1890289783477783, -0.1570766568183899]
--------------------------------------------------
Áõ∏‰ººÂ∫¶: 0.6420454978942871, ÊñáÊú¨: Êú∫Âô®Â≠¶‰π†ÊòØAIÁöÑÈáçË¶ÅÊäÄÊúØ
ÂêëÈáèÂâç10‰∏™ÂÄº: [0.47643378376960754, -0.6565182209014893, 0.4817119836807251, 1.7072904109954834, 0.6420148015022278, -0.5517555475234985, 1.3600889444351196, 1.0196406841278076, -1.330409288406372, -0.6851357817649841]
--------------------------------------------------
Áõ∏‰ººÂ∫¶: 0.6177574992179871, ÊñáÊú¨: ‰∫∫Â∑•Êô∫ËÉΩÊòØËÆ°ÁÆóÊú∫ÁßëÂ≠¶ÁöÑ‰∏Ä‰∏™ÂàÜÊîØ
ÂêëÈáèÂâç10‰∏™ÂÄº: [0.4621504247188568, -0.15476857125759125, 0.8900142908096313, 1.2281856536865234, 0.34598737955093384, -0.4854089021682739, 0.9530060887336731, 1.0955334901809692, -0.9843278527259827, 0.3670949339866638]
--------------------------------------------------
Áõ∏‰ººÂ∫¶: 0.6035197377204895, ÊñáÊú¨: Ê∑±Â∫¶Â≠¶‰π†ÊòØÊú∫Âô®Â≠¶‰π†ÁöÑ‰∏Ä‰∏™Â≠êÈõÜÔºåÊú∫Âô®Â≠¶‰π†ÊòØAIÁöÑÈáçË¶ÅÊäÄÊúØ
ÂêëÈáèÂâç10‰∏™ÂÄº: [0.6659308671951294, -0.4055631756782532, 0.8532114028930664, 1.709717035293579, 0.7424928545951843, -0.919252872467041, 0.6775144934654236, 0.10599350929260254, -1.2651119232177734, -0.6233137249946594]
--------------------------------------------------
Áõ∏‰ººÂ∫¶: 0.32994917035102844, ÊñáÊú¨: ÈªëÁ•ûËØùÊÇüÁ©∫ÁöÑÂàõÂßã‰∫∫ÊòØÂÜØÂÜÄ
ÂêëÈáèÂâç10‰∏™ÂÄº: [-0.13918161392211914, -1.3258603811264038, 0.7236999869346619, 0.12215479463338852, 0.6712068915367126, 0.2972608208656311, 1.4430207014083862, -0.38402822613716125, -1.4714456796646118, 0.08675938844680786]
--------------------------------------------------
Áõ∏‰ººÂ∫¶: 0.22542385756969452, ÊñáÊú¨: ‰∏≠ÂõΩÁîµÂΩ±2024Âπ¥Á•®ÊàøÂÜ†ÂÜõÊòØÁÉ≠Ëæ£ÊªöÁÉ´
ÂêëÈáèÂâç10‰∏™ÂÄº: [0.01335122063755989, 0.918669581413269, -0.899476170539856, 1.026759147644043, 0.9375036954879761, -1.1757415533065796, 0.6524897813796997, 0.8495270609855652, -0.9792198538780212, 0.5388347506523132]
--------------------------------------------------
```

## RAG ÂÆåÊï¥ÊµÅÁ®ã

Áé∞Âú®ËÆ©Êàë‰ª¨Áúã‰∏Ä‰∏™ÂÆåÊï¥ÁöÑ RAG ÂÆûÁé∞Ôºö

Ëøô‰∏™Âè™ÊòØÂÅö‰∏™Â±ïÁ§∫Ôºå‰∏çÊâßË°åÔºåÊú¨Âú∞Êó†Ê≥ïÊâßË°åÔºåÈúÄË¶Å OpenAI ÁöÑ ApiKey„ÄÇ

```python
import openai
from typing import List, Dict
import numpy as np

class RAGSystem:
    def __init__(self, vector_db):
        self.vector_db = vector_db
        self.client = openai.OpenAI()
    
    def add_documents(self, documents: List[str]):
        """Ê∑ªÂä†ÊñáÊ°£Âà∞Áü•ËØÜÂ∫ì"""
        embeddings = []
        for doc in documents:
            embedding = self.get_embedding(doc)
            embeddings.append(embedding)
        
        # Â≠òÂÇ®Âà∞ÂêëÈáèÊï∞ÊçÆÂ∫ì
        self.vector_db.insert(documents, embeddings)
    
    def get_embedding(self, text: str):
        """Ëé∑ÂèñÊñáÊú¨ÁöÑ Embedding"""
        response = self.client.embeddings.create(
            input=text,
            model="text-embedding-ada-002"
        )
        return response.data[0].embedding
    
    def retrieve(self, query: str, top_k: int = 3) -> List[str]:
        """Ê£ÄÁ¥¢Áõ∏ÂÖ≥ÊñáÊ°£"""
        query_embedding = self.get_embedding(query)
        results = self.vector_db.search(query_embedding, top_k)
        return [result['text'] for result in results]
    
    def generate_answer(self, query: str, context: List[str]) -> str:
        """Âü∫‰∫éÊ£ÄÁ¥¢ÁªìÊûúÁîüÊàêÁ≠îÊ°à"""
        context_text = "\n".join(context)
        
        prompt = f"""Âü∫‰∫é‰ª•‰∏ã‰ø°ÊÅØÂõûÁ≠îÈóÆÈ¢òÔºö

‰ø°ÊÅØÔºö
{context_text}

ÈóÆÈ¢òÔºö{query}

ËØ∑Âü∫‰∫é‰∏äËø∞‰ø°ÊÅØÂõûÁ≠îÔºåÂ¶ÇÊûú‰ø°ÊÅØ‰∏≠Ê≤°ÊúâÁõ∏ÂÖ≥ÂÜÖÂÆπÔºåËØ∑ËØ¥ÊòéÊó†Ê≥ïÂõûÁ≠î„ÄÇ"""

        response = self.client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0
        )
        
        return response.choices[0].message.content
    
    def answer(self, query: str) -> str:
        """ÂÆåÊï¥ÁöÑ RAG ÊµÅÁ®ã"""
        # 1. Ê£ÄÁ¥¢Áõ∏ÂÖ≥ÊñáÊ°£
        relevant_docs = self.retrieve(query)
        
        # 2. ÁîüÊàêÁ≠îÊ°à
        answer = self.generate_answer(query, relevant_docs)
        
        return answer

# ‰ΩøÁî®Á§∫‰æã
rag = RAGSystem(vector_db)  # ÂÅáËÆæÂ∑≤ÁªèÂàùÂßãÂåñ‰∫ÜÂêëÈáèÊï∞ÊçÆÂ∫ì

# Ê∑ªÂä†Áü•ËØÜÂ∫ì
documents = [
    "Êàë‰ª¨ÂÖ¨Âè∏‰∏ªË¶ÅÂÅöÈáèÂåñ‰∫§ÊòìÔºåÊèê‰æõÈ´òÈ¢ë‰∫§ÊòìÁ≠ñÁï•",
    "Êàë‰ª¨ÁöÑ‰∫ßÂìÅÂåÖÊã¨ËÇ°Á•®„ÄÅÊúüË¥ß„ÄÅÊúüÊùÉÁ≠âÂ§öÁßçÈáëËûçÂ∑•ÂÖ∑",
    "ÂÖ¨Âè∏ÊàêÁ´ã‰∫é2020Âπ¥ÔºåÊÄªÈÉ®‰Ωç‰∫éÊù≠Â∑û"
]

rag.add_documents(documents)

# ÊèêÈóÆ
answer = rag.answer("‰Ω†‰ª¨ÂÖ¨Âè∏ÊòØÂÅö‰ªÄ‰πàÁöÑÔºü")
print(answer)
```

## RAG ÁöÑ‰ºòÂäø‰∏éÊåëÊàò

### ‰ºòÂäø

1. **ÂáÜÁ°ÆÊÄß**ÔºöÂü∫‰∫éÁúüÂÆû‰ø°ÊÅØÂõûÁ≠îÔºåÂáèÂ∞ëÂπªËßâ
2. **Êó∂ÊïàÊÄß**ÔºöÂèØ‰ª•ÈöèÊó∂Êõ¥Êñ∞Áü•ËØÜÂ∫ì
3. **ÂèØËß£ÈáäÊÄß**ÔºöÂèØ‰ª•ËøΩÊ∫ØÂà∞ÂÖ∑‰ΩìÁöÑÂèÇËÄÉÊñáÊ°£
4. **ÊàêÊú¨ÊïàÁõä**ÔºöÊØîÈáçÊñ∞ËÆ≠ÁªÉÊ®°ÂûãÊõ¥ÁªèÊµé

### ÊåëÊàò

1. **Ê£ÄÁ¥¢Ë¥®Èáè**ÔºöÊ£ÄÁ¥¢‰∏çÂà∞Áõ∏ÂÖ≥ÂÜÖÂÆπÊó∂ÔºåÁ≠îÊ°àË¥®Èáè‰∏ãÈôç
2. **‰∏ä‰∏ãÊñáÈïøÂ∫¶**ÔºöÊ£ÄÁ¥¢Âà∞ÁöÑÊñáÊ°£ÂèØËÉΩË∂ÖÂá∫Ê®°Âûã‰∏ä‰∏ãÊñáÈôêÂà∂
3. **ÂÆûÊó∂ÊÄß**ÔºöÁü•ËØÜÂ∫ìÊõ¥Êñ∞ÈúÄË¶ÅÊó∂Èó¥
4. **ÊàêÊú¨**ÔºöÈúÄË¶ÅÈ¢ùÂ§ñÁöÑÂ≠òÂÇ®ÂíåËÆ°ÁÆóËµÑÊ∫ê

RAG ÊäÄÊúØÊ≠£Âú®Âø´ÈÄüÂèëÂ±ïÔºåÂ∑≤ÁªèÊàê‰∏∫ÊûÑÂª∫ÂèØÈù† AI Â∫îÁî®ÁöÑÈáçË¶ÅÂ∑•ÂÖ∑„ÄÇÈÄöËøáÂêàÁêÜÁöÑËÆæËÆ°Âíå‰ºòÂåñÔºåRAG ËÉΩÂ§üÊòæËëóÊèêÂçáÂ§ßÊ®°ÂûãÂú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑË°®Áé∞„ÄÇ

# Fine-Tuning

Â∏ÇÈù¢‰∏äÂ§ßÊ®°Âûã‰∏ÄËà¨ÈÉΩÊòØÈÄöÁî®ÁöÑÔºåÂ¶ÇÊûúÈúÄË¶ÅÂú®Êüê‰∏™Ë°å‰∏ö‰ΩøÁî®ÔºåÁΩë‰∏äÊêú‰∏çÂà∞Áõ∏ÂÖ≥ÁöÑÂÜÖÂÆπÁöÑÔºåÈúÄË¶ÅÂõûÂ§çÁâπÂÆöÂÜÖÂÆπÁöÑÔºåÈÉΩÈúÄË¶ÅËøõË°åÂæÆË∞ÉÔºàFine-TuningÔºâÔºåÈÄöËøáËßÑËåÉÂåñÊï∞ÊçÆÈõÜÔºåËøõË°åÂæÆË∞É„ÄÇÂ¶ÇÊûú‰ΩøÁî®ÁöÑÊòØ OpenAIÔºåÂÆÉ‰ª¨Êèê‰æõ‰∫ÜÈùûÂ∏∏ÁÆÄÂçïÁöÑÂæÆË∞ÉÊñπÂºèÔºåÂè™ÈúÄË¶ÅÊèê‰æõÁ±ª‰ºº‰∏ãÈù¢ÁöÑ josnl Êñá‰ª∂Âç≥ÂèØ„ÄÇ

```json
{
  "messages": [
    {
      "role": "user",
      "content": "What is the weather in Minneapolis?"
    },
    {
      "role": "assistant",
      "tool_calls": [
        {
          "id": "call_id",
          "type": "function",
          "function": {
            "name": "get_current_weather",
            "arguments": "{\"location\": \"Minneapolis, USA\", \"format\": \"celsius\"}"
          }
        }
      ]
    }
  ],
  "parallel_tool_calls": false,
  "tools": [
    {
      "type": "function",
      "function": {
        "name": "get_current_weather",
        "description": "Get the current weather",
        "parameters": {
          "type": "object",
          "properties": {
            "location": {
              "type": "string",
              "description": "The city and country, eg. Minneapolis, USA"
            },
            "format": {
              "type": "string",
              "enum": [
                "celsius",
                "fahrenheit"
              ]
            }
          },
          "required": [
            "location",
            "format"
          ]
        }
      }
    }
  ]
}
```

## Supervised fine-tuning (SFT) 

https://platform.openai.com/docs/guides/supervised-fine-tuning

Ëøô‰∏™ÊòØÁõëÁù£ÂæÆË∞ÉÔºå‰πüÂ∞±ÊòØ‰Ω†Êèê‰æõ‰∫ÜËæìÂÖ•‰ª•ÂèäËæìÂá∫ËØ•ÊòØ‰ªÄ‰πà„ÄÇÂΩìÁÑ∂Ëøô‰∏™Èô§‰∫ÜË∞ÉÁî® OpenAI ÁöÑÊé•Âè£ËøõË°åÂæÆË∞ÉÔºåÁÑ∂ÂêéËæìÂá∫ÂæÆË∞ÉÂêéÁöÑÊ®°Âûã ID ËøõË°åË∞ÉÁî®ÔºåËøòÂèØ‰ª•ÈÄöËøáÁºñÂÜôÂØπÂ∫îÁöÑ Python ‰ª£Á†ÅÔºåËøõË°å„ÄÇ

ÂÖ∂ÂÆûÂ∞±ÊòØÊú∫Âô®Â≠¶‰π†ÔºåÂáÜÂ§áÂ•ΩÊï∞ÊçÆÈõÜÔºå‰∏ÄÈÉ®ÂàÜÁî®Êù•ËÆ≠ÁªÉ‰∏ÄÈÉ®ÂàÜÁî®Êù•ÊµãËØïÔºåÂÖ∑‰ΩìÁöÑÊìç‰ΩúÊµÅÁ®ãÂú®[[#ËøõÈò∂Á∫ßËµÑÊ∫ê]]‰∏≠ÊúâÂ¶Ç‰ΩïÊìç‰Ωú„ÄÇ

# ÂÖ∂‰ªñÂ∑•ÂÖ∑Â±ïÁ§∫

Â§ßÊ®°ÂûãÁü•ËØÜÊèê‰æõÂ∫ïÂ±ÇÁöÑÂü∫Á°ÄËÉΩÂäõÔºåÈÄöËøáËæìÂÖ•ÊèêÁ§∫ËØçÔºåËøîÂõûÁõ∏Â∫îÁöÑÂÜÖÂÆπ„ÄÇÂ¶ÇÊûúÊÉ≥Ë¶ÅËß£ÂÜ≥Â§çÊùÇÁöÑÈóÆÈ¢òÔºåÈúÄË¶ÅÂíåÂ§ñÈÉ®ËøõË°å‰∫§‰∫íÁöÑÔºåÂøÖÈ°ªË¶ÅÊúâÂØπÂ∫îÁöÑ Agent Ê°ÜÊû∂ÊàñËÄÖÂ∑•ÂÖ∑ËøõË°åÊîØÊíëÔºåÈÇ£‰πà‰∏ãÈù¢ÁöÑ‰∏Ä‰∫õÂ∑•ÂÖ∑ÊàñËÄÖËØ¥Ëß£ÂÜ≥ÊñπÊ°àÔºåÈÉΩÊòØÊòØÁõÆÂâç‰∏öÁïå‰∏ªÊµÅÈÄâÊã©„ÄÇ

## ‰∏ÄÁ´ôÂºèËß£ÂÜ≥ÊñπÊ°à - Dify

https://cloud.dify.ai/apps

ÂèØ‰ª•Âà©Áî® Dify Êù•ÊûÑÂª∫Ëá™Â∑±ÁöÑÊÉ≥Ë¶ÅÁöÑ AgentÔºå‰æãÂ¶Ç‰∏ãÈù¢ÁöÑÔºåÊ≤°Êúâ Tool ÁöÑÔºåÂè™ÊòØÂä†‰∫Ü RAG ÁöÑËÅäÂ§©Êú∫Âô®‰∫∫Ôºå‰ºöÈÄöËøáÂ∑≤ÊúâÁöÑÁü•ËØÜÂÜÖÂÆπÂõûÁ≠îÔºåËÄå‰∏çÊòØËÉ°Áºñ‰π±ÈÄ†„ÄÇ

![image.png](https://s2.loli.net/2025/08/08/H5K8JqBFoye7ibU.png)

## Coze Âπ≥Âè∞/ÂºÄÊ∫êÈ°πÁõÆ

[ÁΩëÂùÄ](https://www.coze.cn/)ÔºåËøôÊòØÂõΩÂÜÖÁâàÔºåÂõΩÂ§ñÁâà‰πüÂ∑Æ‰∏çÂ§öÔºåÂõΩÂ§ñÁâàËÉΩÁî® Claude Âíå ChatGPT Ëøô‰∫õÂ§ßÊ®°Âûã„ÄÇÈÄâÊã©ÂºÄÂèëÂπ≥Âè∞ÔºåÂø´ÈÄüÂºÄÂßãÔºåÊàë‰ª¨ÂèØ‰ª•ÁúãÂà∞‰∏ãÂõæÊâÄÁ§∫ÂÜÖÂÆπ„ÄÇÊúâËá™Â∑±ÁöÑÂ∑•‰ΩúÁ©∫Èó¥ÔºåÂíå Dify ÂÖ∂ÂÆûÊòØÁ±ª‰ººÁöÑÔºåÈÉΩÊòØÂà©Áî®Â∑•‰ΩúÊµÅÊûÑÂª∫ AgentÔºåÈáåÈù¢ËøòÊúâÂêÑÁßçÂêÑÊ†∑ÁöÑÂäüËÉΩ„ÄÇÁÇπÂáªÂ∑¶‰æßÊ®°ÊùøËøòÂèØ‰ª•ÂèÇËÄÉÂà´‰∫∫ÊûÑÂª∫ÁöÑÊô∫ËÉΩ‰ΩìÔºå‰∏ç‰ªÖËÉΩÂú®ÁΩëÈ°µ‰∏äË∞ÉÁî®ÔºåËøòËÉΩÈÄöËøá API Ë∞ÉÁî®„ÄÇËøôÁßç‰∏ÄÁ´ôÂºèÁöÑÂºÄÂèëÔºåÂá†‰πé‰∏çÈúÄË¶ÅÂÜô‰ª£Á†ÅÁöÑÊñπÂºèÔºåÊòØÊØîËæÉÂ•ΩÁöÑÈÄâÊã©ÔºåËÆ©ÈùûÁ®ãÂ∫èÂëòÊàêÂëòÈÉΩËÉΩÂèÇ‰∏é‰∏ÄËµ∑ÊûÑÂª∫ Agent„ÄÇ

ÂΩìÁÑ∂Ëøô‰∏™‰πüÊúâÂºÄÊ∫êÁâàÔºåÂú® 2025 Âπ¥ 7 Êúà‰ªΩÂºÄÊ∫êÔºå‰πüÂ∞±ÊòØÂàöÂºÄÊ∫ê‰∏ç‰πÖÔºåÈ°πÁõÆÊú¨Ë∫´Áî®ÁöÑÊòØ TypeScript Âíå Golang ÂÜôÁöÑÔºåÊúâ Java SDK ÂèØ‰ª•Ë∞ÉÁî® [Coze Studio](https://github.com/coze-dev/coze-studio)„ÄÇ

![image.png](https://s2.loli.net/2025/08/08/3jw2YSuDMyaotnb.png)

Coze ÂÆòÊñπ‰ΩøÁî®ÊñáÊ°£[Âú®Ëøô](https://www.coze.cn/open/docs/guides/welcome)„ÄÇ

Spring-AI-Alibaba ‰πüÊèê‰æõ‰∫ÜÁ±ª‰ºº Coze Studio ÁöÑÂäüËÉΩÔºåÂè™‰∏çËøáÁõÆÂâçÔºà2025 Âπ¥ 8 Êúà8 Êó•ÔºâÊ≠£Âú®ÂÆåÂñÑ„ÄÇ

## IDE Plugin - Cline

ÁõÆÂâç‰∏ªË¶Å‰ª• VS Code Êâ©Â±ïÁöÑÂΩ¢Âºè‰ΩøÁî®ÔºåÂêåÊó∂‰πüÂèØÂú® Cursor„ÄÅWindsurf ‰∏≠‰ΩøÁî®ÔºõÈúÄË¶ÅËá™Â§á‰∏çÂêåÂ§ßÊ®°ÂûãÁöÑ API Key„ÄÇÊîØÊåÅ DeepSeek„ÄÅOpenAI„ÄÅClaude Á≠âÁ≠â„ÄÇ

‰∏é‰πãÁõ∏ÂØπÂ∫îÔºåÂ¶ÇÊõ¥Ê∑±Â∫¶ÈõÜÊàê IDE ÁöÑ Copilot„ÄÅÁ±ª‰ºº‰∫ßÂìÅÁöÑ Roo Code„ÄÅContinue ÈÉΩÂ∑Æ‰∏çÂ§ö„ÄÇÂÄºÂæó‰∏ÄÊèêÁöÑÊòØÔºåÂÆÉ‰ª¨ÈÉΩÊîØÊåÅ MCP„ÄÇÂèØ‰ª•Âà©Áî®Ëøô‰∏™ÔºåÊù•ÂÆûÁé∞Ëá™Â∑±‰∏Ä‰∫õÊú¨Âú∞ÁöÑË∞ÉÁî®Ôºå‰æãÂ¶Ç‰∏ã‰∏Ä‰∏™ JDBC ÁöÑ MCPÔºåÂéªÊü•ËØ¢Êüê‰∏™Ë°®ÁöÑÊï∞ÊçÆÔºåÈÉΩÊòØÂèØ‰ª•ÁöÑ„ÄÇ

## AI IDE - Cursor

Cursor ÊòØÂü∫‰∫é VS Code ‰∫åÊ¨°ÂºÄÂèëÁöÑ AI IDEÔºåÂÆÉÁöÑÁ´ûÂìÅÊúâ Windsurf„ÄÅTraeÔºàÂ≠óËäÇÂºÄÂèëÔºâÂíåÂëΩ‰ª§Ë°åÁöÑ Claude Code„ÄÅOpenAI Codex Á≠âÁ≠â„ÄÇ

‰∏ç‰ªÖÂèØ‰ª•Áî® Cursor Êù•ÂÜô‰ª£Á†ÅÔºåÂÆÉ‰πüÊòØ‰Ω†ÁöÑÊñáÊú¨ÁºñËæëÁöÑÊúÄÂº∫ÂäõÁöÑÂä©Êâã„ÄÇÂÖ≥‰∫éÂ¶Ç‰Ωï‰ΩøÁî®ÔºåÂú®ÂÆÉÁöÑÂÆòÊñπÁΩëÁ´ôÊúâÂÜôÔºåËøôÈáåÂè™‰ºöÊèêÊúÄÁÆÄÂçïÔºåÊúÄÂ∏∏Áî®ÁöÑÂäüËÉΩ„ÄÇ

1. Tab Ëá™Âä®Ë°•ÂÖ®ÔºåÂè™Ë¶Å‰Ω†Êõ¥Êîπ‰∫Ü‰∏ÄÈÉ®ÂàÜ‰ª£Á†ÅÔºåCursor ‰ºöËá™Âä®Ê†πÊçÆ‰∏ä‰∏ãÊñáËá™Âä®Ë°•ÂÖ®ÔºåÊàñËÄÖÁü•ÈÅì‰Ω†‰∏ã‰∏ÄÊ≠•Âç≥Â∞ÜË¶ÅÂÅö‰ªÄ‰πàÔºåÂâçÊèêÊòØ‰∏çË¶ÅÊâìÂºÄÂ§™Â§öÁöÑÊ†áÁ≠æÈ°µÂπ≤Êâ∞‰∏ä‰∏ãÊñá„ÄÇ
2. Ctrl + I ÊâìÂºÄÂØπËØùÔºåÂ∞Ü‰Ω†ÁöÑÈóÆÈ¢òÔºå‰ª•ÂèäË¶ÅÊ∂âÂèäÂà∞ÁöÑ‰∏ä‰∏ãÊñáÈÄöËøá @file ÁöÑÂΩ¢ÂºèËøõË°åÊ∑ªÂä†ÔºåÈÄöËøáÂâçÈù¢Êàë‰ª¨Áü•ÈÅìÂ§ßÊ®°Âûã‰∏ä‰∏ãÊñáÊòØÊúâÈôêÂà∂ÁöÑÔºåÂ¶ÇÊûúË∂ÖËøáÂ§ßÊ®°Âûã‰∏ä‰∏ãÊñáÔºåÂ§ßÊ®°ÂûãÂ∞Ü‰ºöËàçÂºÉ‰Ω†ÊúÄÂâçÈù¢ÁöÑ‰∏ä‰∏ãÊñáÔºåÊâÄ‰ª•ÈúÄË¶Å‰Ω†Ëá™Â∑±ÊéßÂà∂Ôºå‰∏Ä‰ª∂‰∫ãÊÉÖÊâìÂºÄ‰∏Ä‰∏™ tab ËÄå‰∏çÊòØÊâÄÊúâÈóÆÈ¢òÈÉΩÊîæÂà∞‰∏Ä‰∏™ tab ‰πãÂÜÖ„ÄÇ
3. ÈÄâ‰∏≠‰ªªÊÑèÊñáÊú¨ÔºåCtrl + K Â∞èËåÉÂõ¥ÊñáÊú¨ÂÜÖÂÆπ‰øÆÂ§çÔºåÊúâÊó∂ÂÄô‰∏çÈúÄË¶ÅÈÇ£‰πàÂ§ßÁöÑ‰∏ä‰∏ãÊñáËøõË°åÂØπËØùÔºåÂ∞±ÂèØ‰ª•Áî®Ëøô‰∏™„ÄÇ
4. ÂÜô‰ª£Á†Å‰ºòÂÖàÊé®Ëçê Claude ÊúÄÊñ∞Ê®°ÂûãÔºåÂÖ∂Ê¨°ÊòØ GPT Á≥ªÂàó„ÄÇ

## Á∫¢ÊûÅ‰∏ÄÊó∂ÁöÑÂ§ö Agent Manus

https://manus.im/app

Ëøô‰∏™ÊòØÂ§ö‰∏™ AgentÔºåÊØè‰∏™ Agent ÊúâÁùÄ‰∏çÂêåÁöÑ‰∏ä‰∏ãÊñáÔºå‰∏çÂêåÁöÑ system prompt„ÄÇ‰æãÂ¶ÇÊûÑÂª∫‰ªªÂä°Ê∏ÖÂçïÁöÑ AgentÔºåÊâßË°å‰∏çÂêå‰ªªÂä°ÁöÑ AgentÔºåAgent Âíå Agent ‰πãÈó¥ÈÄöËøáÁâπÂÆöÁöÑÊñáÊú¨ËøõË°åÊ≤üÈÄöÔºå‰æãÂ¶Ç JSONÔºåÊàñËÄÖ Markdown Ê†ºÂºèÁöÑÊñáÊú¨„ÄÇ

Á±ª‰ººÁöÑÔºåÁÆÄÂåñÁâàÊú¨ÁöÑ[Â§ö Agent Ê†∑‰æã](https://github.com/LYiHub/Cyber-Zen-Master)„ÄÇ

## Â§çÂàªÁâàÊú¨Â§ö Agent JManus

Áî± Alibaba ÂºÄÊ∫êÔºåÊòØ Spring-AI-Alibaba È°πÁõÆ‰∏≠ÁöÑ‰∏Ä‰∏™[Â≠êÈ°πÁõÆ](https://github.com/alibaba/spring-ai-alibaba/tree/main/spring-ai-alibaba-jmanus)ÔºåÂêéÁ´ØÁî± Java ÂÆûÁé∞ÔºåÂâçÁ´ØÊòØ Vue+TypeScript ÂÆûÁé∞„ÄÇ

ÂÖ∂ÂÆû‰πüÊòØÂÖàËÆ°ÂàíÔºåÂÜçÊâßË°åÔºåÂ∞ÜÂ§ß‰ªªÂä°ÊãÜËß£ÊàêÂ≠ê‰ªªÂä°ÔºåÈÄê‰∏™ÊâßË°å„ÄÇ

# Â≠¶‰π†ËµÑÊ∫êÊé®Ëçê

Èô§‰∫ÜÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºåËøòÊúâ Diffusion Model Êâ©Êï£Ê®°ÂûãÔºåÊòØÂΩìÂâçÊâÄÊúâÊµÅË°åÁöÑÊñáÁîüÂõæÔºåÊñáÁîüËßÜÈ¢ëÁöÑÂü∫Á°ÄÊäÄÊúØ„ÄÇÂåÖÊã¨‰∫Ü Stable Difussion„ÄÅDALL-E„ÄÅMidjourney„ÄÅÈòøÈáåÁöÑÈÄö‰πâ‰∏áÁõ∏Á≠âÁ≠â„ÄÇËøô‰∏™Âú® HuggingFace ‰∏äÊúâ‰∏ìÈó®ÁöÑËØæÁ®ãÊïôËøô‰∏™ÔºåÂéüÁêÜÊòØ‰ªÄ‰πàÔºå‰∏ãÈù¢Êé®ËçêÁöÑ AI Â§ßÊ®°Âûã‰πãÁæéÈáå‰πü‰ºöÊèêÂà∞„ÄÇ

‰∏ãÈù¢ËµÑÊ∫êÊòØÂ§ßËØ≠Ë®ÄÊ®°Âûã„ÄÅÊú∫Âô®Â≠¶‰π†„ÄÅNLP Áõ∏ÂÖ≥ÁöÑÂÜÖÂÆπ„ÄÇ

## ÂÖ•Èó®Á∫ßËµÑÊ∫ê

1. [Â¶Ç‰ΩïÂÜôÂ•ΩÊèêÁ§∫ËØçÔºàÂê¥ÊÅ©ËææËØæÁ®ãÔºâ](https://bilibili.com/video/BV1Bo4y1A7FU)
2. [AI Â§ßÊ®°Âûã‰πãÁæé](https://time.geekbang.org/column/intro/100541001?tab=catalog)

## ËøõÈò∂Á∫ßËµÑÊ∫ê

1. [Deep Dive into LLMs like ChatGPT](https://www.youtube.com/watch?v=7xTGNNLPyMI)
2. [AI AgentËØæÁ®ã](https://huggingface.co/learn/agents-course/en/unit0/introduction)
3. [‰øùÂßÜÁ∫ßÂ§ßÊ®°ÂûãÂæÆË∞ÉÂÆûÊàòÔºàÂê¥ÊÅ©ËææÔºâ](https://huggingface.co/learn/agents-course/en/unit0/introduction)
4. [Âê¥ÊÅ©Ëææ-Êú∫Âô®Â≠¶‰π†](https://www.bilibili.com/video/BV164411b7dx/)
5. [Âä®ÊâãÂ≠¶Ê∑±Â∫¶Â≠¶‰π†](https://zh.d2l.ai/)

Âê¥ÊÅ©Ëææ-Êú∫Âô®Â≠¶‰π†ÔºåËÆ≤‰∫Ü‰ªÄ‰πàÊòØÊú∫Âô®Â≠¶‰π†ÔºåÊ¢ØÂ∫¶‰∏ãÈôçÊòØ‰ªÄ‰πàÔºåÁ∫øÊÄßÂõûÂΩíÔºåÂèçÂêë‰º†Êí≠Á≠âÁ≠âÔºåÊòØÈùûÂ∏∏ÁÆÄÂçïÊòìÊáÇÁöÑÂÖ•Èó®ËØæÁ®ã„ÄÇ

## ‰π¶Á±çÊé®Ëçê

1. „Ää[ËøôÂ∞±ÊòØ ChatGPT](https://book.douban.com/subject/36449803/)„Äã
2. „ÄäËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÂÆûÊàò„Äã
3. „ÄäÊ∑±Â∫¶Â≠¶‰π†„Äã

## ÂÆûË∑µÂπ≥Âè∞

1. [Dify](https://dify.ai) - ÊãñÊãΩÂºèAIÂ∫îÁî®Êê≠Âª∫
2. [Hugging Face](https://huggingface.co) - AIÊ®°ÂûãÂíåÂ∑•ÂÖ∑
3. [OpenAI Playground](https://platform.openai.com/playground) - ‰ΩìÈ™åÂêÑÁßçAIÊ®°Âûã
