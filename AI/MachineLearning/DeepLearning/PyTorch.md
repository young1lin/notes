# 安装

首先你得有显卡，如果是笔记本，买个外置的显卡坞用雷电三的线接到你的笔记本，当然你的笔记本必须支持雷电三协议，USB4.0 也是支持的。最好是新显卡，二手显卡不太可靠。

安装列表
1. Python 3.8+
3. [Pytorch](https://pytorch.org/get-started/previous-versions/) 我装的是 torch==2.0.1+cu118
4. [CUDA Toolkit](https://developer.nvidia.com/cuda-toolkit-archive) 确定好 Pytorch 版本，下载安装对应的 CUDA 版本，上面的是 11.8
5. cuDNN v8.6.0（选择是否安装，如果不用 PaddlePaddle 相关的可以不装）

## 检查安装是否正常
### 检查 CUDA 是否安装正常
Terminal 输入

```shell
nvcc --version
```

输出

```log
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2022 NVIDIA Corporation
Built on Wed_Sep_21_10:41:10_Pacific_Daylight_Time_2022
Cuda compilation tools, release 11.8, V11.8.89
Build cuda_11.8.r11.8/compiler.31833905_0
```
### 检查是否显卡正常

Terminal 输入

```shell
nvidia-smi
```

输出

```log
Wed Oct 18 00:22:04 2023
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 537.42                 Driver Version: 537.42       CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 4070 Ti   WDDM  | 00000000:06:00.0 Off |                  N/A |
|  0%   32C    P8               5W / 285W |      0MiB / 12282MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+

+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
```
### 检查 PyTorch 版本

```python
import torch

print(f"PyTorch version: {torch.__version__}")
```
输出
```log
PyTorch version: 2.0.1+cu118
```
### 检查 Pytorch 是否能用 CUDA

```python
import torch

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print('Using device:', device)

# 创建一个Tensor并在GPU上运行
if device.type == 'cuda':
	x = torch.Tensor(1, 2, 3, 4, 5).to(device)
	print(x)
```

输出

```log

Using device: cuda
tensor([[[[[ 1.0841e+37,  2.6886e+36,  2.7101e+36,  2.4155e-38,  9.7725e+21],
           [ 2.5417e+30,  5.1848e-44,  2.0501e-35,  4.4383e+27,  1.0763e+31],
           [ 7.1449e+31,  1.9918e-36,  1.4509e-41,  7.2959e-39,  8.0081e-38],
           [ 6.5843e+32,  1.1280e-41,  2.8878e-39,  2.0498e-19,  2.5353e+30]],

          [[ 7.8473e-44,  1.2191e-43,  2.3135e-42,  1.5908e-30,  6.6206e+35],
           [ 2.7886e+29,  7.1561e+22,  1.7697e+31,  7.7154e+31,  1.6534e+19],
           [ 2.1932e-40,  0.0000e+00,  0.0000e+00,  2.7551e-40,  4.5918e-40],
           [ 6.1530e-39,  9.2697e-04,  2.6585e+36,  1.5642e+26,  2.8339e+36]],

          [[ 1.5763e+26,  4.4509e+31, -3.8612e-37,  2.6898e+36,  6.7130e+32],
           [ 4.6727e+31, -9.4416e-38,  2.7094e+36,  2.6893e+36,  9.6966e+21],
           [ 1.0929e+37,  5.6043e+11,  5.6271e+08,  4.7668e+33, -1.6287e+16],
           [ 2.8525e+20,  3.1596e+35,  2.0280e-19,  4.4658e+30,  3.5849e-14]]],


         [[[ 5.0918e-39,  2.3633e-01,  2.8422e-14,  2.2056e+03,  2.8397e+29],
           [ 1.8524e+28,  6.1183e+31,  1.0766e+21,  3.6713e+03,  4.7427e+30],
           [ 6.2582e-42,  5.8265e-39,  4.9665e-37,  1.4509e-41,  1.5778e+20],
           [ 1.8759e+28, -1.6145e+16,  1.8179e+31,  4.8413e+30,  4.3440e-44]],

          [[ 1.1280e-41,  2.9796e-39,  8.3971e-32,  6.8289e+22,  7.7447e+31],
           [ 6.2874e+16,  1.0141e+31,  1.6816e-44,  2.4980e-38,  2.4613e-38],
           [ 2.4245e-38,  2.2491e+20,  4.8617e+30,  1.6082e+19,  2.8177e+20],
           [ 1.7471e+19,  2.1932e-40,  0.0000e+00,  0.0000e+00,  1.8367e-40]],

          [[ 4.5918e-40,  6.1530e-39,  4.7923e-29,  4.0565e+31,  2.6685e+36],
           [ 3.8832e+25, -3.9872e-31,  2.8494e-14,  2.3663e-01,  2.8422e-14],
           [ 1.6939e-39,  9.4531e-01,  2.8422e-14,  3.7143e-39,  1.2813e-36],
           [ 4.9398e+30,  4.3440e-44,  1.1280e-41,  2.9796e-39,  8.3971e-32]]]]],
       device='cuda:0')
       
```